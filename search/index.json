[{"content":"官方文档 SearXNG\n介绍 SearXNG是一个基于Python的开源互联网元搜索引擎，它致力于聚合来自不同搜索服务和数据库的结果，为用户提供全面的信息获取渠道。此项目的独特之处在于对用户隐私的重视，它确保了在提供强大搜索能力的同时，既不追踪用户行为也不建立用户画像。\n功能特点 隐私保护：SearXNG 通过多种方式保护用户隐私，包括： 删除搜索请求中的私人数据。 阻止第三方服务（如广告）的传输。 隐藏搜索结果页面中的查询词和重定向链接。 多源聚合：SearXNG 聚合了来自超过 70 个搜索服务和数据库的结果，支持多种搜索引擎，如 Google、DuckDuckGo、Bing 等。 API支持：SearXNG提供API接口，支持联网搜索功能，可以与其他应用程序集成，实现更复杂的数据处理和分析。 多语言支持：SearXNG支持多种语言，用户可以根据需要选择不同的语言进行搜索。 高度可定制：用户可以根据自己的需求自定义搜索结果，例如只从特定的搜索引擎获取信息，或者对搜索结果进行过滤和排序。 开源与社区支持：SearXNG 是一个开源项目，所有源代码均可查看，用户可以自行修改和扩展功能。社区提供了详细的文档和教程，鼓励开发者贡献代码和翻译。 核心功能亮点： SearXNG的核心功能集中于其作为元搜索引擎的角色上，能够整合如Google、Bing、DuckDuckGo等多种搜索引擎的搜索结果，给予用户更广泛的信息来源。更重要的是，它坚持“无追踪”的原则，保障用户的网络搜索隐私，让用户在不受监控的状态下自由探索互联网。\nSearXNG支持以下具体的搜索引擎：\nGoogle DuckDuckGo Bing Yahoo Wikipedia StartPage Brave Search Qwant Arxiv 以及其他超过70种公开的搜索服务和数据库 技术实现\n架构与部署：SearXNG 支持多种部署方式，包括 Docker 镜像、安装脚本和手动安装。Docker 镜像支持 ARM64 和 ARM/v7 架构，方便在不同硬件平台上运行。 界面与用户体验：SearXNG 提供简洁直观的用户界面，支持桌面、平板和手机大屏幕显示，并提供浅色和深色主题选项。界面支持从右到左的语言，适应不同文化背景的用户。 扩展性：SearXNG 支持代理和在线 Tor 搜索，进一步增强了用户的匿名性。 使用场景 1.个人隐私保护：用户可以在本地部署 SearXNG，避免在公共网络中被追踪或分析。\n2.企业内部应用：企业可以搭建自己的搜索服务，确保数据安全。\n3.开发者工具：开发者可以利用 SearXNG 构建定制化的搜索功能，例如在 AI 应用中集成搜索插件。\n部署（Dokcer方式） 注意事项：尽量不要使用国内的服务器进行搭建，否则可能因为服务器无法访问国外某些服务，尽量放在外网、\n配置修改 修改searxng/setting.yml 文件 将secret_key为自己的秘钥，可以自己随机生成即可，修改limiter为false，增加search扩展数据返回格式 docker compose配置文件修改 ① 80端口如果被占用的话需要改端口，该部署方式是用Caddy替代了nginx，也是占用80端口 ② 首次启动注释掉所有的cap_drop，下次启动则不需要注释 ③ 删去127.0.0.1 ，允许外部访问 ④ 进入 /opt/searxng/searxng-docker 目录 ，执行 docker compose up -d 构建即可 API接口 官方文档：https://docs.searxng.org/dev/search_api.html\n响应结果官方文档：https://docs.searxng.org/dev/result_types/index.html\n引擎配置文档：https://docs.searxng.org/user/configured_engines.html#configured-engines\n接口地址 http://ip:8080/search 请求方式：GET / POST 部分参数如下 请求示例 请求示例：http://ip:8080/search?q=DeepSeek\u0026amp;format=json\u0026amp;engines=baidu\n响应结果示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 { \u0026#34;query\u0026#34;: \u0026#34;DeepSeek\u0026#34;, \u0026#34;number_of_results\u0026#34;: 0, \u0026#34;results\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;DeepSeek | 深度求索\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://www.deepseek.com\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;深度求索(DeepSeek),成立于2023年,专注于研究世界领先的通用人工智能底层模型与技术,挑战人工智能前沿性难题。基于自研训练框架、自建智算集群和万卡算力等资源,深度求索团队仅用半年时间便已发布并开源多个百亿级参数大模型,如DeepSeek-LLM通用大语言模型、DeepSeek\u0026#34;, \u0026#34;publishedDate\u0026#34;: \u0026#34;2025-03-28T01:57:32\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;baidu\u0026#34;, \u0026#34;template\u0026#34;: \u0026#34;default.html\u0026#34;, \u0026#34;parsed_url\u0026#34;: [ \u0026#34;https\u0026#34;, \u0026#34;www.deepseek.com\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34; ], \u0026#34;img_src\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;thumbnail\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engines\u0026#34;: [ \u0026#34;baidu\u0026#34; ], \u0026#34;positions\u0026#34;: [ 1 ], \u0026#34;score\u0026#34;: 1, \u0026#34;category\u0026#34;: \u0026#34;general\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;DeepSeek(杭州深度求索人工智能基础技术研究有限公司推出的AI助手)_百 ...\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://baike.baidu.com/item/DeepSeek/65368136\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;随着数字经济的蓬勃发展以及各行业对高效、智能解决方案的迫切需求,以及数据量呈指数级增长,信息传播速度加快,人工智能(AI)技术成为推动行业革新的关键力量 [85],2024年12月,视觉模型DeepSeek-VL2、模型DeepSeek-V3首个版本相继发布并同步开源。2025年1月15日,DeepSeek官方App正式上线。 [4] 发展历程 播报 编辑 20...\u0026#34;, \u0026#34;publishedDate\u0026#34;: \u0026#34;2025-03-31T06:27:13\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;baidu\u0026#34;, \u0026#34;template\u0026#34;: \u0026#34;default.html\u0026#34;, \u0026#34;parsed_url\u0026#34;: [ \u0026#34;https\u0026#34;, \u0026#34;baike.baidu.com\u0026#34;, \u0026#34;/item/DeepSeek/65368136\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34; ], \u0026#34;img_src\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;thumbnail\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engines\u0026#34;: [ \u0026#34;baidu\u0026#34; ], \u0026#34;positions\u0026#34;: [ 2 ], \u0026#34;score\u0026#34;: 0.5, \u0026#34;category\u0026#34;: \u0026#34;general\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;90%的人都不知道的DeepSeek高效使用技巧\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://mp.weixin.qq.com/s?__biz=MjM5OTc1MDA2MQ==\u0026amp;mid=2652093947\u0026amp;idx=1\u0026amp;sn=2d8704d12fb99b5cb3e0eea3faccb8a6\u0026amp;chksm=bd4312eab812ac64a4fdc3e98f50c76f1a16ba4d628f2a8e677baf779007823c58d46960047d\u0026amp;scene=27\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;这样我就可以把自己私人的信息喂给deepseek,让它为我量身定做答案,也不用担心信息的泄密。 而且deepseek在回答我问题的时候,还会给我展示它的推理过程。 比如我想给8岁女儿推荐动画片,deepseek就会给我显示它的推理过程,也就是说AI是怎么思考这个问题的,而这个...\u0026#34;, \u0026#34;publishedDate\u0026#34;: \u0026#34;2025-02-06T23:31:00\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;baidu\u0026#34;, \u0026#34;template\u0026#34;: \u0026#34;default.html\u0026#34;, \u0026#34;parsed_url\u0026#34;: [ \u0026#34;https\u0026#34;, \u0026#34;mp.weixin.qq.com\u0026#34;, \u0026#34;/s\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;__biz=MjM5OTc1MDA2MQ==\u0026amp;mid=2652093947\u0026amp;idx=1\u0026amp;sn=2d8704d12fb99b5cb3e0eea3faccb8a6\u0026amp;chksm=bd4312eab812ac64a4fdc3e98f50c76f1a16ba4d628f2a8e677baf779007823c58d46960047d\u0026amp;scene=27\u0026#34;, \u0026#34;\u0026#34; ], \u0026#34;img_src\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;thumbnail\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engines\u0026#34;: [ \u0026#34;baidu\u0026#34; ], \u0026#34;positions\u0026#34;: [ 3 ], \u0026#34;score\u0026#34;: 0.3333333333333333, \u0026#34;category\u0026#34;: \u0026#34;general\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;DeepSeek新手必看!全功能详解与实操指南,带你逆袭成AI大神\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://baijiahao.baidu.com/s?id=1822666430369643282\u0026amp;wfr=spider\u0026amp;for=pc\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;一、DeepSeek是什么 DeepSeek是一款多模态AI工具，融合了文本生成、图像创作等多种功能，致力于为用户提供无缝的创作体验。它由中国对冲基金高毅资产旗下团队打造，于2023年成立，虽然诞生时间不长，但发展迅猛，在AI领域迅速崭露头角。与传统AI应用不同，DeepSeek采用深度学习和高效的神经网络技术，极大地提升了回应...\u0026#34;, \u0026#34;publishedDate\u0026#34;: \u0026#34;2025-01-30T10:05:39\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;baidu\u0026#34;, \u0026#34;template\u0026#34;: \u0026#34;default.html\u0026#34;, \u0026#34;parsed_url\u0026#34;: [ \u0026#34;https\u0026#34;, \u0026#34;baijiahao.baidu.com\u0026#34;, \u0026#34;/s\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;id=1822666430369643282\u0026amp;wfr=spider\u0026amp;for=pc\u0026#34;, \u0026#34;\u0026#34; ], \u0026#34;img_src\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;thumbnail\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engines\u0026#34;: [ \u0026#34;baidu\u0026#34; ], \u0026#34;positions\u0026#34;: [ 4 ], \u0026#34;score\u0026#34;: 0.25, \u0026#34;category\u0026#34;: \u0026#34;general\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;DeepSeek中文读音怎么读_哔哩哔哩_bilibili\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://www.bilibili.com/video/BV1mJNAesE5Q\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;DeepSeek是什么? 章夏Sean 8.9万 206 【雪梨老师】普通家庭怎么用deepseek 高效学英语?最新保姆级教程来了!【建议收藏】 英语雪梨老师 4.0万 13 过年回家就是陪伴和团圆 李文凉 855 0 一分钟用人话讲明白DeepSeek为何轰动全世界! 李三金Alex看世界 50.8万 380 ...\u0026#34;, \u0026#34;publishedDate\u0026#34;: \u0026#34;2025-02-04T10:50:46\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;baidu\u0026#34;, \u0026#34;template\u0026#34;: \u0026#34;default.html\u0026#34;, \u0026#34;parsed_url\u0026#34;: [ \u0026#34;https\u0026#34;, \u0026#34;www.bilibili.com\u0026#34;, \u0026#34;/video/BV1mJNAesE5Q\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34; ], \u0026#34;img_src\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;thumbnail\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engines\u0026#34;: [ \u0026#34;baidu\u0026#34; ], \u0026#34;positions\u0026#34;: [ 5 ], \u0026#34;score\u0026#34;: 0.2, \u0026#34;category\u0026#34;: \u0026#34;general\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;接入DeepSeek之后,企业什么样?|算法|智能化|deepseek|世界人工智能...\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://www.163.com/dy/article/JS1T4SEA0550TYQ0.html\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;“DeepSeek为道岔制造注入‘智慧基因’,实用性很强。”最近,中铁宝桥南京公司的信息化团队成功将DeepSeek-R1模型和千问大模型Qwen2.5接入ERP系统,开发了道岔智能助手。这个智能化制造新体系实现了订单管理、工艺执行、质量管控的全流程数字化升级。 “钼光大模型”“道岔智能助手”只是企业接入DeepSeek进行数字化升级的一...\u0026#34;, \u0026#34;publishedDate\u0026#34;: \u0026#34;2025-03-31T23:32:03\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;baidu\u0026#34;, \u0026#34;template\u0026#34;: \u0026#34;default.html\u0026#34;, \u0026#34;parsed_url\u0026#34;: [ \u0026#34;https\u0026#34;, \u0026#34;www.163.com\u0026#34;, \u0026#34;/dy/article/JS1T4SEA0550TYQ0.html\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34; ], \u0026#34;img_src\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;thumbnail\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engines\u0026#34;: [ \u0026#34;baidu\u0026#34; ], \u0026#34;positions\u0026#34;: [ 6 ], \u0026#34;score\u0026#34;: 0.16666666666666666, \u0026#34;category\u0026#34;: \u0026#34;general\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;“DeepSeek”是怎么回答“DeepSeek”怎么念的?\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://baijiahao.baidu.com/s?id=1822566627381536789\u0026amp;wfr=spider\u0026amp;for=pc\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;“DeepSeek”作为专有名词，其发音遵循英语拼读规则。该词由“deep”与“seek”组合而成，标准英语发音为/diːp siːk/。具体发音分解如下：首音节“deep”发长音/iː/，舌尖抵下齿，双唇向两侧伸展，与单词“keep”中“ee”发音相同;辅音/p/发音时双唇闭合后突然张开，声带不振动。次音节“seek”中“see...\u0026#34;, \u0026#34;publishedDate\u0026#34;: \u0026#34;2025-01-29T07:16:22\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;baidu\u0026#34;, \u0026#34;template\u0026#34;: \u0026#34;default.html\u0026#34;, \u0026#34;parsed_url\u0026#34;: [ \u0026#34;https\u0026#34;, \u0026#34;baijiahao.baidu.com\u0026#34;, \u0026#34;/s\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;id=1822566627381536789\u0026amp;wfr=spider\u0026amp;for=pc\u0026#34;, \u0026#34;\u0026#34; ], \u0026#34;img_src\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;thumbnail\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engines\u0026#34;: [ \u0026#34;baidu\u0026#34; ], \u0026#34;positions\u0026#34;: [ 7 ], \u0026#34;score\u0026#34;: 0.14285714285714285, \u0026#34;category\u0026#34;: \u0026#34;general\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;deep seek什么意思\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://localsite.baidu.com/site/wjzsorv8/8cd47d9a-7797-42f3-9306-b902ded71161?qaId=5095242\u0026amp;categoryLv1=%E6%95%99%E8%82%B2%E5%9F%B9%E8%AE%AD\u0026amp;efs=1\u0026amp;ch=54\u0026amp;srcid=10014\u0026amp;source=natural\u0026amp;category=%E5%B0%8F%E5%AD%A6%E8%8B%B1%E8%AF%AD\u0026amp;eduFrom=136\u0026amp;botSourceType=46\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;“DeepSeek”对应的中文释义为“深度求索”,该词汇既包含对字面含义的技术性解读,也承载着探索未知、追求创新的精神内核。其核心价值体现在方法论与价值观的双重维度,以下从三个层面展开说明: 一、字面含义的技术解析 从构词法来看,“Deep”代表对事物本质的深度挖掘,体现系统性研究...\u0026#34;, \u0026#34;publishedDate\u0026#34;: \u0026#34;2025-01-07T18:02:45\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;baidu\u0026#34;, \u0026#34;template\u0026#34;: \u0026#34;default.html\u0026#34;, \u0026#34;parsed_url\u0026#34;: [ \u0026#34;https\u0026#34;, \u0026#34;localsite.baidu.com\u0026#34;, \u0026#34;/site/wjzsorv8/8cd47d9a-7797-42f3-9306-b902ded71161\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;qaId=5095242\u0026amp;categoryLv1=%E6%95%99%E8%82%B2%E5%9F%B9%E8%AE%AD\u0026amp;efs=1\u0026amp;ch=54\u0026amp;srcid=10014\u0026amp;source=natural\u0026amp;category=%E5%B0%8F%E5%AD%A6%E8%8B%B1%E8%AF%AD\u0026amp;eduFrom=136\u0026amp;botSourceType=46\u0026#34;, \u0026#34;\u0026#34; ], \u0026#34;img_src\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;thumbnail\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;engines\u0026#34;: [ \u0026#34;baidu\u0026#34; ], \u0026#34;positions\u0026#34;: [ 8 ], \u0026#34;score\u0026#34;: 0.125, \u0026#34;category\u0026#34;: \u0026#34;general\u0026#34; } ], \u0026#34;answers\u0026#34;: [], \u0026#34;corrections\u0026#34;: [], \u0026#34;infoboxes\u0026#34;: [], \u0026#34;suggestions\u0026#34;: [], \u0026#34;unresponsive_engines\u0026#34;: [] } 注意：在UI界面的配置只会影响UI的搜索功能，并不会影响API的搜索配置，如果要对API的搜索配置进行修改，需要修改配置文件 /searxng/settings.yml\n如下，我禁用掉了startpage和qwant这两个引擎的搜索，这样搜索API在搜索时就不会调用这两个引擎的检索\nUI界面使用 快捷搜索\n!bang 这一列表示引擎的快捷搜素，当在搜索词前输入对应的快捷搜索词，就只会搜索对应的引擎，如 !go 就表示使用google进行搜索，这样就不会有其他引擎的搜索结果\n","date":"2025-04-05T15:20:04+08:00","permalink":"https://h-yx-blog.github.io/p/%E8%81%94%E7%BD%91%E6%A3%80%E7%B4%A2searxng%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/","title":"联网检索SearXNG本地部署"},{"content":"背景 为了降本，决定不再续费原来使用的阿里云的Quick BI，寻找开源免费的替代品， 国内DataEase 的权限控制是收费，不符合需求；MetaBase的开发语言是Clojure ，目前公司没有人会该语言，有学习成本，固也不做考虑。最后选择了Superset\n介绍 Superset 是一个现代数据探索和数据可视化平台。Superset 可以替代或增强许多团队的专有商业智能工具。Superset 与各种数据源很好地集成。\nSuperset提供：\n用于快速构建图表的无代码界面 一个强大的、基于 Web 的 SQL 编辑器，用于高级查询 用于快速定义自定义维度和指标的轻量级语义层 对几乎任何 SQL 数据库或数据引擎的开箱即用支持 各种精美的可视化效果来展示您的数据，从简单的条形图到地理空间可视化效果 轻量级、可配置的缓存层，有助于减轻数据库负载 高度可扩展的安全角色和身份验证选项 用于编程自定义的 API 专为扩展而设计的云原生架构 Superset没有对windows的官方支持，建议在linux或macos下进行部署，如下图 支持的数据库 Dokcker方式部署 这里我使用的是4.1.1的rc版本，可以从github上下载源码 测试环境下部署如下 一. 修改docker-compose 配置文件\ndocker-compose-non-dev.yml 主要用于从本地分支构建一组不可变镜像，即一旦启动，本地分支无论怎么改都不会影响（本地分支如果修改了代码，则需要把镜像先停止然后删除掉镜像，最后再重新构建） 我这里让dev配置的该文件也实现了交互式开发的效果，在该文件下我多加了一行挂载，让python程序改变后可以挂载到docker容器中，这样可以实时生效 docker-compose.yml文件用于交互式开发，即本地分支代码一修改就能立即响应到容器中 构建镜像并启动：\n1 docker compose -f docker-compose-non-dev.yml up 等待镜像构建部署，如果要使用后台启动的方式，可以在docker命令的结尾加上 -d 参数\n个性化配置 修改数据源为本地数据源，不使用镜像 进入 docker目录下，找到 .env文件，修改.env文件中关于数据库连接的配置\n1 cd /opt/superset/superset-4.1.1rc1/docker 修改相关数据库连接配置 注意点：在.env文件中还有一个重要的配置如下，这里是在指定配置文件的位置，当你修改superset/config.py 配置文件无效时，可以试试修改pythonpath_dev/superset_config.py 文件，这里的配置会覆盖下的配置 superset/config.py\n1 PYTHONPATH=/app/pythonpath:/app/docker/pythonpath_dev 环境配置 当年启动了superset后，可能会发现右上角出现的是 Development的环境，如下 在 superset/config.py中，以下配置可以定义Superset首页右上角的环境显示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ENVIRONMENT_TAG_CONFIG = { \u0026#34;variable\u0026#34;: \u0026#34;SUPERSET_ENV\u0026#34;, \u0026#34;values\u0026#34;: { \u0026#34;debug\u0026#34;: { \u0026#34;color\u0026#34;: \u0026#34;error.base\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;flask-debug\u0026#34;, }, \u0026#34;development\u0026#34;: { \u0026#34;color\u0026#34;: \u0026#34;error.base\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;Development\u0026#34;, }, \u0026#34;production\u0026#34;: { \u0026#34;color\u0026#34;: \u0026#34;warning.base\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;Production\u0026#34;, }, }, } 然后在 superset/docker/.env文件中可以配置激活的环境 开启允许导入CSV功能 Superset默认不允许导入csv，在我使用过程中，发现导入csv的前提是你要先连接上数据库，且后续这个csv创建的表是会创建在你的数据库中的，所以要想上传csv，必须先连接上你的数据库，其次还需要修改如下配置。 点击Database，编辑，勾选下放 的Allow 选项来开启csv导入\n开启定时邮件任务 修改以下配置为False\n1 ALERT_REPORTS_NOTIFICATION_DRY_RUN = False 一开始我修改 superset/config.py配置文件，无论怎么改都不生效，在发送定时报表时候会出现以下错误：ALERT_REPORTS_NOTIFICATION_DRY_RUN is enabled,set it to False to send notification\n与上文中提到的一样，在.env文件中，有一行指定了 pythonpath，且在pythonpath_dev目录下还有一个 superset_config.py的配置文件，该配置文件的配置会覆盖 config.py的配置。 其次还要修改 /opt/superset/superset-4.1.1rc1/superset/config.py 下的邮箱配置 首页图标变更 二开的情况下，免不了把icon等图标都修改为自己的logo 修改 superset-frontend/src/assets/images 文件夹下图中的三个文件 权限 默认的角色权限解释如下\nAdmin：管理员拥有所有可能的权限，包括授予或撤销其他用户的权限，以及更改其他用户的切片和仪表板； Alpha：Alpha用户可以访问所有数据源，但不能授予或撤消其他用户的访问权限。它们也仅限于改变它们所拥有的对象。Alpha用户可以添加和更改数据源。 Gamma：Gamma用户的访问权限有限。他们只能使用来自通过另一个补充角色访问的数据源的数据。他们只能查看由他们可以访问的数据源制作的切片和仪表板。目前Gamma用户无法更改或添加数据源。我们假设他们主要是内容消费者，尽管他们可以创建切片和仪表盘。另请注意，当Gamma用户查看仪表板和切片列表视图时，他们将只看到他们有权访问的对象。 sql_lab：sql_lab角色授予对sql lab的访问权限。请注意，虽然管理员用户在默认情况下可以访问所有数据库，但Alpha和Gamma用户都需要在每个数据库的基础上获得访问权限。 public：要允许注销的用户访问某些超集功能，需要自己配置权限，并将其分配给另一个角色，您希望将其权限传递给该角色。 “Gamma”拥有大部分基础的权限，但是必须结合其他能访问数据源的角色才能访问数据。所以，可以给用户分配“Gamma”角色和针对部门分别创建的数据源角色来进行控制。\n使用案例：https://zhuanlan.zhihu.com/p/641920400\n开启Dashboards权限控制 官方文档：https://superset.hacker-linner.com/security/ 在docker/pythonpath_dev中的 superset_config.py中 ，添加属性\n1 FEATURE_FLAGS = {\u0026#34;DASHBOARD_RBAC\u0026#34;: True} 然后在Dashboard会出现以下选项，可以配置允许哪些角色访问 开启Tag 在 pythonpath_dev/superset_config.py中添加属性TAGGING_SYSTEM并设置为True \u0026ldquo;TAGGING_SYSTEM\u0026rdquo;: True\n以下是完整的配置\n1 FEATURE_FLAGS = {\u0026#34;ALERT_REPORTS\u0026#34;: True,\u0026#34;DASHBOARD_RBAC\u0026#34;: True,\u0026#34;TAGGING_SYSTEM\u0026#34;: True} 效果如下\n汉化 参考：https://blog.csdn.net/netbloomy/article/details/60965012\n在 docker/pythonpath_dev/superset_config.py文件添加如下配置\n1 2 3 4 5 6 7 8 9 10 11 # Setup default language BABEL_DEFAULT_LOCALE = \u0026#34;zh\u0026#34; # Your application default translation path BABEL_DEFAULT_FOLDER = \u0026#34;superset/translations\u0026#34; # The allowed translation for your app LANGUAGES = { \u0026#34;en\u0026#34;: {\u0026#34;flag\u0026#34;: \u0026#34;us\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;English\u0026#34;}, \u0026#34;zh\u0026#34;: {\u0026#34;flag\u0026#34;: \u0026#34;cn\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Chinese\u0026#34;}, \u0026#34;zh_TW\u0026#34;: {\u0026#34;flag\u0026#34;: \u0026#34;tw\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Traditional Chinese\u0026#34;}, } 缺点：汉化效果不彻底，还是有较大部分为英文 解决：自己翻译补全\nsuperset/translations/zh/LC_MESSAGES/messages.po文件中找相应字符串，看是否已经国际化过，若没有，则在文件的尾部添加\nmsgid \u0026ldquo;Column\u0026rdquo; msgstr \u0026ldquo;列\u0026rdquo; msgid就是要国际化的字符串，而msgstr则是要翻译成的语言\n编译messages.po文件为messages.mo 在终端中将目录切换到superset/目录下，执行如下命令,最后重启superset pybabel compile -d translations\n修改项目名称 修改 /opt/superset/superset-4.1.1rc1/superset/config.py 修改 APP_NAME ，改为你自己的项目名称即可】\nSuperset的开放API路径 Superset开放的 API地址路径：http://你自己的ip:你自己的端口/swagger/v1\n配置文件最佳实践 在这里，一般都是需要新建一个自己的配置文件去覆盖原有config.py文件中的一些配置参数，而不是直接在原config.py文件中修改，官方推荐的文件名：superset_config.py\n上面的我配置已经是将错就错，直接修改了原配置文件\n图表操作中的数字格式化 superset中的数字格式化采用 D3 format ，一个超过百万的数字，如果不想以科学计数的方式显示，用 , .0f 则可显示为原值\nD3 format 单位如下\ny - yocto, 10⁻²⁴ z - zepto, 10⁻²¹ a - atto, 10⁻¹⁸ f - femto, 10⁻¹⁵ p - pico, 10⁻¹² n - nano, 10⁻⁹ µ - micro, 10⁻⁶ m - milli, 10⁻³ ​- (none) - 10⁰ k - kilo, 10³ M - mega, 10⁶ G - giga, 10⁹ T - tera, 10¹² P - peta, 10¹⁵ E - exa, 10¹⁸ Z - zetta, 10²¹ Y - yotta, 10²⁴ 用于小数点的位数 :(常用) f 浮点型 、 % 百分比 精确到前n位： e g r s p 精确到前n位： b o d x 等 ","date":"2025-04-05T10:36:24+08:00","permalink":"https://h-yx-blog.github.io/p/%E5%BC%80%E6%BA%90bi%E9%A1%B9%E7%9B%AE-superset%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/","title":"开源BI项目 Superset本地部署教程"},{"content":"Docker私服搭建步骤 首先你须已经安装了docker，这里网上教程很多，不做赘述\n1.关闭防火墙\n1 2 3 4 5 6 # 查看防火墙状态 [root@localhost ~]# systemctl status firewalld.service # 暂停防火墙 [root@localhost ~]# systemctl stop firewalld.service # 永久关闭防火墙 [root@localhost ~]# systemctl disable firewalld.service 启动docker相关服务 1 2 3 4 [root@localhost ~]# systemctl daemon-reload [root@localhost ~]# systemctl enable docker.service [root@localhost ~]# systemctl start docker [root@localhost ~]# systemctl status docker 安装registry私有仓库 1 2 3 4 5 6 7 8 9 # 拉取私有镜像仓库到本地 [root@localhost ~]# docker pull registry # 测试上传镜像 # 打标签 [root@localhost ~]# docker tag redis:latest 你自己的服务器ip地址:5000/myredis # 上传镜像 [root@localhost ~]# docker push 你自己的服务器ip地址:5000/myredis # 启动私有镜像仓库 [root@localhost ~]# docker run -d -p 5000:5000 --restart always --name registry registry:lastest 过程中如遇到以下报错，尝试重启守护进程daemon 以及docker\n1 2 [root@iZwz9a6jcmkx7svbn14023Z ~]# systemctl daemon-reload [root@iZwz9a6jcmkx7svbn14023Z ~]# systemctl enable docker.service 重新上传后报错如下\n1 2 3 4 [root@iZwz9a6jcmkx7svbn14023Z ~]# docker run -d -p 5000:5000 --restart always registry ba2fe2525ba4791b4a51454b3d5d81fa5d9dccf15fe1382c1b19beef3c62f803 [root@iZwz9a6jcmkx7svbn14023Z ~]# docker tag nginx:latest 你的ip信息:5000/mynginx Error response from daemon: No such image: nginx:latest 这个错误是因为 Docker 默认要求使用 HTTPS 连接 Registry，而不允许HTTP 解决措施：修改/etc/docker/daemon.json vim /etc/docker/daemon.json 增加以下配置\n1 2 3 { \u0026#34;insecure-registries\u0026#34;: [\u0026#34;你的ip:5000\u0026#34;] } 再次重启守护进程daemon 以及docker\n1 2 [root@iZwz9a6jcmkx7svbn14023Z ~]# systemctl daemon-reload [root@iZwz9a6jcmkx7svbn14023Z ~]# systemctl enable docker.service 重新推送，可以发现推送成功了\n验证 浏览器访问：http://你的ip:5000/v2/_catalog 可以看到如下信息 搭建可视化WEB界面 klausmeyer/docker-registry-browser 是一个用于浏览和管理 Docker Registry 的 Web 界面工具。\n1 2 3 4 5 6 7 [root@iZwz9a6jcmkx7svbn14023Z ~]# docker pull klausmeyer/docker-registry-browser [root@iZwz9a6jcmkx7svbn14023Z ~]# SECRET_KEY=$(openssl rand -hex 64) [root@iZwz9a6jcmkx7svbn14023Z ~]# docker run --name registry-browser -p 8080:8080 --restart=always \\ \u0026gt; -e DOCKER_REGISTRY_URL=http://你的服务器ip地址:5000/v2 \\ \u0026gt; -e SECRET_KEY_BASE=$SECRET_KEY \\ \u0026gt; -e ENABLE_DELETE_IMAGES=true \u0026gt; -d klausmeyer/docker-registry-browser 然后浏览器访问 你的ip地址:8080查看仓库\n","date":"2025-04-04T10:30:20+08:00","permalink":"https://h-yx-blog.github.io/p/docker%E7%A7%81%E6%9C%8D%E6%90%AD%E5%BB%BA/","title":"Docker私服搭建"},{"content":"背景 controller 的接口多处使用 @RequestHeader 从请求头中获取 token信息，然后在代码中进行解析\n弊端：\n代码冗余 如果User信息实体发生变化，需要修改多处代码 解决措施 利用自定义的 HandlerMethodArgumentResolver获取系统的用户信息，替代 @RequestHeader\n作用：\n如果我们想要的信息不完全是来自消息体等地方，比如说一部分是消息体，一部分是消息头，甚至一部分从配置中获取。这个时候我们又希望在方法入参进来就将这些信息组装好。\n或者说是需要从消息头里面去进行token解析认证的时候。\n① 顶层接口说明\nHandlerMethodArgumentResolver接口定义了 两个方法\n1 2 3 4 boolean supportsParameter(MethodParameter parameter); @Nullable Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception; boolean supportsParameter(MethodParameter parameter)：判断解析器是否支持给定的方法参数，当返回true时则会进行解析 Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception：解析给定的方法参数，并返回实际的参数值。 ②实现步骤\n创建一个实现HandlerMethodArgumentResolver接口的类，并重写方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Component public class UserLoginInfoArgumentResolver implements HandlerMethodArgumentResolver { private final AiInternalUserService aiInternalUserService; public UserLoginInfoArgumentResolver(AiInternalUserService aiInternalUserService) { this.aiInternalUserService = aiInternalUserService; } @Override public boolean supportsParameter(MethodParameter parameter) { //处理UserLoginInfo类型的参数 return parameter.getParameterType().equals(UserLoginInfo.class); } @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception { // 从请求头中获取 Authorization String loginToken = webRequest.getHeader(\u0026#34;Authorization\u0026#34;); if (loginToken == null || loginToken.isEmpty()) { throw new IllegalArgumentException(\u0026#34;Authorization header is missing\u0026#34;); } // 调用服务获取 UserLoginInfo 对象 return aiInternalUserService.getUserLoginInfoByLoginToken(loginToken); } } 注册解析器，将解析器注册到WebMvcConfigurer\n过实现WebMvcConfigurer接口，并重写addArgumentResolvers方法，在该方法中添加自定义解析器。\n1 2 3 4 5 6 7 8 9 10 11 12 @Configuration public class InterceptorConfig implements WebMvcConfigurer { private final UserLoginInfoArgumentResolver userLoginInfoArgumentResolver; public InterceptorConfig(UserLoginInfoArgumentResolver userLoginInfoArgumentResolver) { this.userLoginInfoArgumentResolver = userLoginInfoArgumentResolver; } @Override public void addArgumentResolvers(List\u0026lt;HandlerMethodArgumentResolver\u0026gt; resolvers) { resolvers.add(userLoginInfoArgumentResolver); } } 改造后的controller写法 1 2 3 4 @RequestMapping(\u0026#34;/getWindowId\u0026#34;) public RMap getWindowId(@RequestBody JSONObject jsonObject, UserLoginInfo userLoginInfo) { //业务逻辑... } 其他思路 设置登录拦截器，解析token后把信息放入ThreadLocal\n","date":"2025-04-03T16:42:15+08:00","permalink":"https://h-yx-blog.github.io/p/springboot%E8%87%AA%E5%AE%9A%E4%B9%89handlermethodargumentresolver%E8%A7%A3%E6%9E%90%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0/","title":"SpringBoot自定义HandlerMethodArgumentResolver解析方法参数"},{"content":"一.介绍 Janus 是一种新颖的自回归框架，它统一了多模态理解和生成。它通过将视觉编码解耦为单独的路径来解决以前方法的局限性，同时仍然使用单一、统一的 transformer 架构进行处理。解耦不仅缓解了视觉编码器在理解和生成中的角色冲突，还增强了框架的灵活性。Janus 超越了以前的统一模型，并达到或超过特定于任务的模型的性能。Janus 的简单性、高度灵活性和有效性使其成为下一代统一多模态模型的有力候选者。\n二.关键技术 Janus-Pro 是 DeepSeek 的 Janus 多模态模型的高级版本，设计用于出色地理解和生成涉及文本和图像的内容，可以同时进行多模态理解和图像生成任务。\nJanus-Pro 仍然保持了 Janus 首创的解耦视觉编码这一核心架构原则。这种将不同任务的视觉处理方法分离开来的做法，对于提高模型的整体性能至关重要。\n优化训练策略 ：Janus-Pro 采用更有效的训练策略，注重更好地利用数据和资源。 扩展的训练数据集：该模型结合了真实数据源和合成数据，增强了其稳健性和适应性。 更大的模型规模：Janus-Pro 的参数规模从 10 亿 (1B) 到 70 亿 (7B)，性能和稳定性都得到了提高，尤其是在文本到图像生成和多模态理解等任务中。 三.创新 核心创新是将多模态理解和生成，使用两种不同的任务解耦编码器来完成理解和生成任务。让这两种任务可以在同一模型中高效完成。\n解耦视觉编码器： Janus-Pro 架构的核心是解耦视觉编码的理念，即根据手头的任务使用不同的编码方法处理图像。 这种多任务处理的效果，主要源于 Janus 系列针对不同任务使用的两个视觉编码器：\n理解编码器：用于提取图像中的语义特征，以便进行图像理解任务（如图像问答、视觉分类等）。\n生成编码器：将图像转换为离散表示（例如，使用 VQ 编码器），用于文本到图像生成任务。\n文生图对比\n特性 Janus Pro Flux 训练成本 相对较低的预算 未明确说明，可能更高 社区支持 开源，在 Hugging Face 上可用 拥有强大的社区支持和优化 性能 擅长指令执行，多模态任务 高质量图像且生成速度快 图像分辨率 输入：384 x 384 像素，输出：最高 768 x 768 可生成高达 1024 x 1024 像素 主要关注点 多模态任务，文本-图像交互 高质量图像生成 四.评估结果 ①在 GenEval 中，Janus-Pro-7B 的得分为 0.80，超过了 DALL-E 3 和 Stable Diffusion 3 Medium 等模型。\n②在 DPG-Bench 上，Janus-Pro 获得了 84.19 分，再次超过了 DALL-E 3 和 Stable Diffusion 3 Medium 等竞争对手。 五.局限性 分辨率限制：该模型的输入分辨率上限为 384x384，这可能会妨碍需要精细细节的任务（如光学字符识别 (OCR)）的性能。\n图像质量：同样的分辨率限制和 VQ tokenizer 使用的压缩技术会导致图像缺乏精细度，尤其是面部小区域。\n六. 本地部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #创建conda环境 conda create -n deepseek-janus python=3.10 -y #激活conda环境 conda activate deepseek-janus #克隆Janus项目 git clone https://github.com/deepseek-ai/Janus.git #进入janus目录 cd Janus #安装Janus依赖 pip install -e . #安装Gradio （UI界面） pip install gradio #启动 （代码中默认是Janus pro 7B的模型，可以手动修改） python demo/app_januspro.py 看到以下界面即已经成功部署 测试结果 ①文生图测试如下 文生图功能似乎对中文理解似乎不行，只能使用英文 （使用中文提问时，无论怎么提问，总是生成如下图片） 英文提问如下 ②图片理解测试如下 ","date":"2025-02-09T10:08:24+08:00","permalink":"https://h-yx-blog.github.io/p/deepseek-janus-pro/","title":"DeepSeek Janus Pro"},{"content":"一. 介绍 1.1 DeepSeek-R1 通过强化学习（Reinforcement Learning：简称RL）提升大型语言模型（LLM）的推理能力。这项研究在如何仅依靠强化学习而不是过分依赖监督式微调的情况下，增强LLM解决复杂问题的能力上，取得了重要进展。\n1.2 DeepSeek-R1系列包含两大核心成员：\n①DeepSeek-R1-Zero\n参数规模：6710亿（MoE架构，每个token激活370亿参数） 训练特点：完全基于强化学习的端到端训练 核心优势：展现出自我验证、长链推理等涌现能力 典型表现：AIME 2024基准测试71%准确率 ②DeepSeek-R1\n参数规模：与Zero版保持相同体量 训练创新：多阶段混合训练策略 核心改进：监督微调冷启动 + 强化学习优化 性能提升：AIME 2024准确率提升至79.8% 1.3 对比R1 Zero和R1\n① R1 Zero和R1的主要区别\nDeepSeek-R1-Zero是团队初步尝试仅用纯强化学习而不进行任何监督式微调的实验。他们从基础模型出发，直接运用强化学习，让模型通过不断试错来发展其推理能力。这种方法虽然取得了较好的成果（在 AIME 2024 测试中达到了 71% 的准确率），但在可读性和语言连贯性上存在明显不足。该模型拥有 6710 亿个参数，使用了混合专家（MoE）架构，其中每个词触发的参数约为 370 亿。此模型展现了一些新兴的推理行为，例如自我核查、反思和长链推理（CoT）。\n与之对比，DeepSeek-R1采用了更复杂的多阶段训练方法。它不仅仅采用强化学习，而是先在一小组精心挑选的示例（称为“冷启动数据”）上进行监督式微调，然后再应用强化学习。这种方法克服了 DeepSeek-R1-Zero 的局限，同时取得了更优的表现。这个模型同样维持了 6710 亿的参数数量，但在回答的可读性和条理性上有所提高。\n② R1 Zero和R1的共同点 DeepSeek-R1-Zero 和 DeepSeek-R1 基于 DeepSeek-V3-Base 进行训练。\nModel Total Params Activated Params Context Length DeepSeek-R1-Zero 671B 37B 128K DeepSeek-R1 671B 37B 128K 训练方法概述：\n强化学习 ：不同于传统依赖监督学习的模型，DeepSeek-R1 大规模采用了强化学习。此训练方法利用群体相对策略优化（GRPO），重点提升精度和格式化奖励，以增强推理能力，无需依赖大量标注数据。 蒸馏技术 ：为普及高效能模型，DeepSeek 也推出了 R1 的蒸馏版本，参数规模从15亿到700亿不等。这些模型采用了如Qwen和Llama等架构，表明即使是较小和更高效的模型也能包含复杂的推理能力。蒸馏过程通过使用 DeepSeek-R1 生成的合成推理数据对这些小型模型进行微调，以较低的计算成本保持高性能。 二.优点 性能与 OpenAI-o1 相当 完全开源的模型和技术报告 MIT 许可：自由蒸馏和商业化！ 从 DeepSeek-R1 提炼出来，6 个小模型完全开源（32B \u0026amp; 70B 型号与 OpenAI-o1-mini 相当） 三. 技术亮点 以最少的标记数据显著提高性能 组相对策略优化（GRPO）：兼顾格式与准确性的奖励机制 知识蒸馏技术：支持从1.5B到70B的参数规模适配 多架构兼容：基于Qwen/Llama等主流架构的轻量化版本 四.API 成本优势：缓存命中时输入token成本$0.14/M，较同类产品降低30%\n模型 上下文长度 最大输出长度 输入价格（缓存命中） 输入价格（缓存未命中） 输出价格 deepseek-reasoner（即deppseek R1） 64K 8K 0.14 美元/百万tokens 0.55 美元/百万tokens 2.19 美元/百万tokens 五.本地部署 推荐配置：NVIDIA GPU（推荐使用具有大量视频内存（VRAM）的 GPU，如：RTX 3090或更高） + 32GB内存 + 50GB存储空间 最低配置：CPU（支持AVX2指令集） + 8GB内存 + 12GB存储 （能耗注意：32B+ 模型需高功率电源（1000W+）和散热系统。） 建议在使用 DeepSeek-R1 系列模型时遵循以下配置 ①将temperature 设置在 0.5-0.7 （推荐 0.6） 的范围内，以防止无休止的重复或不连贯的输出。\n②避免添加系统提示符;所有说明都应包含在用户提示符中。\n③对于数学问题，建议在提示中包含一条指令，例如：“请逐步推理，并将您的最终答案放在 \\boxed{} 中。\n④在评估模型性能时，建议进行多次测试并平均结果。\n六. DeepSeek-R1评估结果 DeepSeek-R1各方面的评估结果如下\nDeepSeek-R1在数学、代码和推理任务，性能可与 OpenAI-o1 相媲美 蒸馏小模型32B 和 70B 模型在多项能力上实现了对标 OpenAI o1-mini 的效果。 七.局限性及未来发展 若干改进领域：\n模型在处理需要特定输出格式的任务时偶尔会遇到困难。 软件工程相关任务的性能还有提升空间。 在多语言环境下，语言混合带来了挑战。 少样本提示通常会导致性能下降。 未来的研究将致力于解决这些问题，并拓展模型在函数调用、多轮交互和复杂角色扮演场景等领域的能力。 ","date":"2025-02-09T10:08:24+08:00","permalink":"https://h-yx-blog.github.io/p/deepseek-r1/","title":"DeepSeek R1"},{"content":"一. 简介 1.1 介绍：DeepSeek 是一家专注于人工智能技术研发的公司，致力于打造高性能、低成本的 AI 模型。它的目标是让 AI 技术更加普惠，让更多人能够用上强大的 AI 工具。\n1.2 为什么DeepSeek-V3重要\n开源精神：DeepSeek-V3 不仅开源了模型权重，还提供了本地部署的支持，让开发者可以自由定制和优化模型。 普惠 AI：DeepSeek-V3 的价格非常亲民，相比国外模型（如 GPT-4o），它的使用成本更低，适合中小企业和个人开发者。 二. 收费情况 2.1 API收费情况 1.如未指定 max_tokens，默认最大输出长度为 4K。请调整 max_tokens 以支持更长的输出。\n2.表格中展示了优惠前与优惠后的价格。即日起至北京时间 2025-02-08 24:00，所有用户均可享受 DeepSeek-V3 API 的价格优惠。 在此之后，模型价格将恢复至原价。\n在大模型 API 的使用场景中，用户的输入有相当比例是重复的。举例说，用户的 prompt 往往有一些重复引用的部分；再举例说，多轮对话中，每一轮都要将前几轮的内容重复输入。\n为此，DeepSeek 启用上下文硬盘缓存技术，把预计未来会重复使用的内容，缓存在分布式的硬盘阵列中。如果输入存在重复，则重复的部分只需要从缓存读取，无需计算。该技术不仅降低服务的延迟，还大幅削减最终的使用成本。 缓存命中的部分，DeepSeek 收费 0.1元 每百万 tokens。至此，大模型的价格再降低一个数量级\nToken 是模型用来表示自然语言文本的基本单位，也是我们的计费单元，可以直观的理解为“字”或“词”；通常 1 个中文词语、1 个英文单词、1 个数字或 1 个符号计为 1 个 token。\n一般情况下模型中 token 和字数的换算比例大致如下：\n1 个英文字符 ≈ 0.3 个 token。 1 个中文字符 ≈ 0.6 个 token。 2.2 并发\nDeepSeek API 不限制用户并发量\n但请注意，当DeepSeek服务器承受高流量压力时，您的请求发出后，可能需要等待一段时间才能获取服务器的响应。在这段时间里，您的 HTTP 请求会保持连接，并持续收到如下格式的返回内容：\n非流式请求：持续返回空行 流式请求：持续返回 SSE keep-alive 注释（: keep-alive）\n这些内容不影响 OpenAI SDK 对响应的 JSON body 的解析。如果使用者自己解析 HTTP 响应，请注意处理这些空行或注释。\n三. 接入方式 3.1 API接入\n对话API ：https://api.deepseek.com/chat/completions\n请求头 Authorization ： Bearer 请求体， messages参数和model参数是必填的，参数示例如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 { \u0026#34;messages\u0026#34;: [ { \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;帮我翻译我是一个机器人，你是一个真人\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; } ], \u0026#34;model\u0026#34;: \u0026#34;deepseek-chat\u0026#34; } 请求参数详情 响应示例 ①非流式 ②流式 3.2 错误码 3.3 与其他大模型的对比 四.对比 知识类任务：MMLU，MMLU-Pro， GPQA, SimpleQA\n长文本：DROP，FRAMES ，LongBench v2\n代码：算法类（Codeforces），工程类（SWE-Bench Verified）\n数学：AIME 2024, MATH DeepSeek-V3 多项评测成绩超越了 Qwen2.5-72B 和 Llama-3.1-405B 等其他开源模型，并在性能上和世界顶尖的闭源模型 GPT-4o 以及 Claude-3.5-Sonnet 不分伯仲。\n百科知识： DeepSeek-V3 在知识类任务的水平接近当前表现最好的模型 Claude-3.5-Sonnet-1022。 长文本： 在长文本测评中，DeepSeek-V3 平均表现超越其他模型。 代码： DeepSeek-V3 在算法类代码场景远远领先于市面上已有的全部非 o1 类模型；并在工程类代码场景（SWE-Bench Verified）逼近 Claude-3.5-Sonnet-1022。 数学： 在美国数学竞赛和全国高中数学联赛上，DeepSeek-V3 大幅超过了所有开源闭源模型。 中文能力： DeepSeek-V3 与 Qwen2.5-72B 在教育类测评 C-Eval 和代词消歧等评测集上表现相近，但在事实知识 C-SimpleQA 上更为领先。 DeepSeek-V3支持本地部署，GPT-4o和Kimi均不支持本地部署 五. 创新点 使用上下文硬盘缓存技术，将预计未来会重复使用的内容进行缓存，如果输入存在重复，则重复的部分只需要从缓存读取，无需计算。该技术不仅降低服务的延迟，还大幅削减最终的使用成本。\n注意，只有当两个请求的前缀内容相同时（从第 0 个 token 开始相同），才算重复。中间开始的重复不能被缓存命中。\n使用场景：\n具有长预设提示词的问答助手类应用\n具有长角色设定与多轮对话的角色扮演类应用\n针对固定文本集合进行频繁询问的数据分析类应用\n代码仓库级别的代码分析与排障工具\n通过 Few-shot 提升模型输出效果 注意：\n缓存系统以 64 tokens 为一个存储单元，不足 64 tokens 的内容不会被缓存\n缓存系统是“尽力而为”，不保证 100% 缓存命中\n缓存不再使用后会自动被清空，时间一般为几个小时到几天\n六. 总结 DeepSeek-V3 是一款性能强大、价格亲民、开源支持的国产 AI 模型。它在知识问答、长文本处理、代码生成、数学能力等方面都展现出了与国际顶尖模型（如 GPT-4o）不相上下的实力。同时，它的低成本和开源特性让它成为普惠 AI 的典范。 未来，随着 DeepSeek-V3 的不断优化和功能扩展，它有望在更多领域发挥重要作用，成为国产 AI 技术的标杆。无论是企业还是个人开发者，都可以通过 DeepSeek-V3 享受到高性能、低成本的 AI 服务。 未来发展方向\n多模态支持 ：DeepSeek 计划在未来为 V3 模型添加多模态功能（如图像、音频处理），进一步提升模型的实用性。 深度思考能力 ：DeepSeek 将继续优化模型的推理和思考能力，使其能够处理更复杂的任务。 ","date":"2025-02-09T09:55:44+08:00","permalink":"https://h-yx-blog.github.io/p/deepseek%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94%E5%8F%8Aapi%E6%8E%A5%E5%85%A5/","title":"DeepSeek技术调研及api接入"},{"content":"本文主要针对Java新应用开发时，数据库设计及使用的一些共识规范，用于团队数据库设计的统一规划和管理。\n以MySQL作为示例介绍，内容分四个方面进行规范描述：建表，索引使用，SQL语句设计，以及ORM对象关系映射。\n一、建表规范 （1）表名、字段名必须使用小写字母或数字，除非数字本身具有共识含义，否则不建议使用，尤其禁止出现数字开头。\n（2）表达是与否的字段，数据类型应设定：unsigned tinyint，即非负数的短字节整型，其中1表示是，0表示否。\n（3）注意禁止使用数据库的保留字段是共识，比如asc,desc,select,match，定义好字段后，应该设置虚拟数据尝试常规的增删改查。\n（4）小数类型为 decimal，当数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储，禁止使用 float 和 double，因为其存在精度丢失的问题。\n（5）字段设置索引时，表示方式应遵循以下命名，主键索引为 pk_字段名，唯一索引为 uk_字段名，普通索引则为 idx_字段名\n（6）表的命名应该富有含义，且呈现分类分层，如factory_produce_order，factory_produce_device\n（7）如果存储的字符串长度确定且相等，可以使用 char 定长字符串类型，而不使用varchar\n（8）表应必备创建时间create_time和更新时间update_time，数据为datetime类型，用来表达数据初次创建和最近更新的时间。\n（9）varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。\n（10）当单表行数超过 500 万行或者单表内容超过 2GB，就应该要考虑业务分表。\n二、索引使用规范 （1）唯一索引的设置，业务上具有唯一特性的字段或多个字段的组合，必须建成唯一索引。在应用层做了非常完善的校验控制，只要没有唯一索引，长久必然有脏数据产生。\n（2）多表关联查询时，需要 join 字段的数据类型必须绝对一致，保证被关联的字段需要有索引。\n（3）在 varchar 字段上建立索引时，当业务没必要对全字段建立索引，可以指定索引长度，根据实际文本区分度决定索引长度即可。\n（4）如果有 order by 的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，例：where a=? and b=? order by c; 索引：a_b_c\n（5）建组合索引的时候，区分度最高的在最左边。例：如果 where a=? and b=? ，a 列的几乎接近于唯一值，那么只需要单建 idx_a 索引即可。\n存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where a\u0026gt;?and b=? 那么即使 a 的区分度更高，也必须把 b 放在索引的最前列。\n三、SQL语句规范 （1）不要使用 count(列名)或 count(常量)来替代 count()，count()是 SQL92 定义的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。\n（2）count(distinct col) 计算该列除 NULL 之外的不重复行数，注意 count(distinctcol1, col2) 如果其中一列全为 NULL，那么即使另一列有不同的值，也返回为 0\n（3）进行数据项的删除和修改时，要先 查询，避免出现误操作，确认无误才能执行更新语句。\n（4）不得使用外键与级联，一切外键概念必须在应用层解决，外键与级联更新适用于单机低并发，不适合分布式、高并发集群，因为级联更新是强阻塞，外键则严重影响数据库的插入速度\n（5）in 业务操作要尽量避免，当要使用时应控制 in 后边的集合元素数量，在 1000 个之内\n四、ORM对象关系映射 （1）在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明\n（2）xml 配置参数使用：#{}，#param# 不要使用${} 此种方式容易出现 SQL 注入\n（3）减少对整个pojo类目标更新，应该只更新改动的字段，若都进行全字段的更新（update table set c1=value1,c2=value2,c3=value3），会容易出错、效率低、增加 binlog 存储\n","date":"2025-01-24T10:59:15+08:00","permalink":"https://h-yx-blog.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/","title":"数据库设计规范"},{"content":"一、PPOCRLabel安装 介绍：PPOCRLabel是一款适用于OCR领域的半自动化图形标注工具，内置PP-OCR模型对数据自动标注和重新识别。使用Python3和PyQT5编写，支持矩形框标注、表格标注、不规则文本标注、关键信息标注模式，导出格式可直接用于PaddleOCR检测和识别模型的训练。\n工具：PPOCRLabel 官方文档：https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.5/PPOCRLabel/README_ch.md\n安装：pip install PPOCRLabel\n启动：\n1 2 3 # 选择标签模式来启动 PPOCRLabel --lang ch # 启动【普通模式】，用于打【检测+识别】场景的标签 PPOCRLabel --lang ch --kie True # 启动 【KIE 模式】，用于打【检测+识别+关键字提取】场景的标签 二、数据标注 将需要进行标注的图片存放在一个文件夹下，在ppocrlabel工具进行导入\n1.打开图片文件夹 2.选择自动标注点击ok等待自动标注完成 3.然后从第一张开始检查，打标文字错误的，点击方框，在右边修改 4.全部打标完成后，点击文件选择导出标记结果、以及导出识别结果\n完成后再文件夹多出四个文件fileState，Label，rec_gt, crop_img。其中crop_img中的图片用来训练文字识别模型，fileState记录图片的打标完成与否，Label为训练文字检测模型的标签，rec_gt为训练文字识别模型的标签。\n5.新建文件夹train_data及子目录drivingData （根据自己需求命名），将上面的数据放于drivingData下 6.打开终端进入PPOCRLabel的文件夹下，输入一下命令进行数据集划分 (注意最后的 ../train_data/drivingData 是我们上面的数据集路径。这里我是拷贝到了 PPOCRLabel所在位置的同级目录)\n1 python gen_ocr_train_val_test.py --trainValTestRatio 6:2:2 --datasetRootPath ../train_data/drivingData 输入指令之后，在train_data文件夹下会出现以下文件，其中det是用来训练文字检测的数据集，rec是用来训练文字识别的数据集。此时可以删去drivingData。 此时文字检测和文字识别的数据集就都制作好了。\n三、数据训练 官方文档：https://github.com/PaddlePaddle/PaddleOCR/blob/bb77fcef6fdfc029f92d7876b714554389053699/doc/doc_ch/recognition.md\n前置步骤：拉取官方PaddleOCR源码到本\n3.1 检测模型训练 前置步骤：拉取官方PaddleOCR源码到本地 步骤一：下载官方模型训练文件（注意：是下载训练模型，而不是推理模型） 此处可根据个人需求选择不同的训练模型\n步骤二：修改paddleocr检测模型配置文件 进入PaddleOcr源码，此处我选择的是ch_det_res18_db_v2.0.yml该配置文件进行修改 修改配置文件，此处我是cpu方式进行的训练，所以use_gpu参数要改为false， pretrained_model的值改为第一步下载好的训练模型的目录下的 best_acuracy所在的位置 继续修改配置文件，修改如下配置，改为上面制作好的数据集所在的位置 以下是我的完整配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 Global: use_gpu: false epoch_num: 200 log_smooth_window: 20 print_batch_step: 2 save_model_dir: ./output/ch_db_res18/ save_epoch_step: 100 # evaluation is run every 5000 iterations after the 4000th iteration eval_batch_step: [3000, 2000] cal_metric_during_train: False # pretrained_model: ./pretrain_models/ch_PP-OCRv4_det_train/best_accuracy pretrained_model: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\pretrain_models\\ch_ppocr_server_v2.0_det_train\\ch_ppocr_server_v2.0_det_train\\best_accuracy #pretrained_model: ./pretrain_models/ResNet18_vd_pretrained checkpoints: save_inference_dir: use_visualdl: False infer_img: doc/imgs_en/img_10.jpg save_res_path: ./output/det_db/predicts_db.txt Architecture: model_type: det algorithm: DB Transform: Backbone: name: ResNet_vd layers: 18 disable_se: True Neck: name: DBFPN out_channels: 256 Head: name: DBHead k: 50 Loss: name: DBLoss balance_loss: true main_loss_type: DiceLoss alpha: 5 beta: 10 ohem_ratio: 3 Optimizer: name: Adam beta1: 0.9 beta2: 0.999 lr: name: Cosine learning_rate: 0.001 warmup_epoch: 2 regularizer: name: \u0026#39;L2\u0026#39; factor: 0 PostProcess: name: DBPostProcess thresh: 0.3 box_thresh: 0.6 max_candidates: 1000 unclip_ratio: 1.5 Metric: name: DetMetric main_indicator: hmean Train: dataset: name: SimpleDataSet data_dir: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data label_file_list: # - ./train_data/det/train.txt - D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data\\det\\train.txt ratio_list: [1.0] transforms: - DecodeImage: # load image img_mode: BGR channel_first: False - DetLabelEncode: # Class handling label - IaaAugment: augmenter_args: - { \u0026#39;type\u0026#39;: Fliplr, \u0026#39;args\u0026#39;: { \u0026#39;p\u0026#39;: 0.5 } } - { \u0026#39;type\u0026#39;: Affine, \u0026#39;args\u0026#39;: { \u0026#39;rotate\u0026#39;: [-10, 10] } } - { \u0026#39;type\u0026#39;: Resize, \u0026#39;args\u0026#39;: { \u0026#39;size\u0026#39;: [0.5, 3] } } - EastRandomCropData: size: [960, 960] max_tries: 50 keep_ratio: true - MakeBorderMap: shrink_ratio: 0.4 thresh_min: 0.3 thresh_max: 0.7 - MakeShrinkMap: shrink_ratio: 0.4 min_text_size: 8 - NormalizeImage: scale: 1./255. mean: [0.485, 0.456, 0.406] std: [0.229, 0.224, 0.225] order: \u0026#39;hwc\u0026#39; - ToCHWImage: - KeepKeys: keep_keys: [\u0026#39;image\u0026#39;, \u0026#39;threshold_map\u0026#39;, \u0026#39;threshold_mask\u0026#39;, \u0026#39;shrink_map\u0026#39;, \u0026#39;shrink_mask\u0026#39;] # the order of the dataloader list loader: shuffle: True drop_last: False batch_size_per_card: 8 num_workers: 4 Eval: dataset: name: SimpleDataSet data_dir: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data label_file_list: # - ./train_data/det/val.txt - D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data\\det\\val.txt transforms: - DecodeImage: # load image img_mode: BGR channel_first: False - DetLabelEncode: # Class handling label - DetResizeForTest: # image_shape: [736, 1280] - NormalizeImage: scale: 1./255. mean: [0.485, 0.456, 0.406] std: [0.229, 0.224, 0.225] order: \u0026#39;hwc\u0026#39; - ToCHWImage: - KeepKeys: keep_keys: [\u0026#39;image\u0026#39;, \u0026#39;shape\u0026#39;, \u0026#39;polys\u0026#39;, \u0026#39;ignore_tags\u0026#39;] loader: shuffle: False drop_last: False batch_size_per_card: 1 # must be 1 num_workers: 2 步骤三：开始训练模型\n进入PaddleOCR源码根目录，打开cmd，输入以下命令,开始训练\n1 python tools/train.py -c configs/det/ch_ppocr_v2.0/ch_det_res18_db_v2.0.yml 如遇报错，可能是需要先安装pyyaml库 pip install pyyaml 训练结果如下 使用best_accuracy.pdparams进行我们的模型测试，没有该文件则说明训练次数少，用latest.pdparams模型测试 步骤四：测试训练模型\n1 2 # pretrained_model参数值为刚刚训练好的模型所在的位置， infre_img为所需要检测的文件（也可以是文件夹） python tools/infer_det.py -c configs/det/ch_ppocr_v2.0/ch_det_res18_db_v2.0.yml -o Global.pretrained_model=output/ch_db_res18/latest.pdparams Global.infer_img=\u0026#34;C:\\Users\\lenovo\\Desktop\\paddle-ocr-data\\demo.png\u0026#34; 文字检测结果如下 3.2 识别模型训练 步骤一：下载官方模型训练文件 此处我选择的是 ch_PP-OCRv3_rec 步骤二：修改padleocr识别模型配置文件 在configs /rec/PP-OCRv3 /找到 ch_PP-OCRv3_rec.yml 配置文件\n识别模型的配置文件有个注意的配置参数为：batch_size_per_card，数据集的图片数量不能小于以下配置的数值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 Global: debug: false #此处我使用的是cpu模式，下面参数需要改为false use_gpu: false epoch_num: 50 log_smooth_window: 20 print_batch_step: 2 #模型训练输出目录 save_model_dir: ./output/rec_ppocr_v3 save_epoch_step: 25 eval_batch_step: [0, 2000] cal_metric_during_train: true #预训练模型所在位置 pretrained_model: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\pretrain_models\\ch_PP-OCRv4_rec_train\\ch_PP-OCRv4_rec_train\\student.pdparams checkpoints: save_inference_dir: use_visualdl: false infer_img: doc/imgs_words/ch/word_1.jpg character_dict_path: ppocr/utils/ppocr_keys_v1.txt max_text_length: \u0026amp;max_text_length 25 infer_mode: false use_space_char: true distributed: true #识别结果输出目录 save_res_path: ./output/rec/predicts_ppocrv3.txt Optimizer: name: Adam beta1: 0.9 beta2: 0.999 lr: name: Cosine learning_rate: 0.001 warmup_epoch: 5 regularizer: name: L2 factor: 3.0e-05 Architecture: model_type: rec algorithm: SVTR_LCNet Transform: Backbone: name: MobileNetV1Enhance scale: 0.5 last_conv_stride: [1, 2] last_pool_type: avg last_pool_kernel_size: [2, 2] Head: name: MultiHead head_list: - CTCHead: Neck: name: svtr dims: 64 depth: 2 hidden_dims: 120 use_guide: True Head: fc_decay: 0.00001 - SARHead: enc_dim: 512 max_text_length: *max_text_length Loss: name: MultiLoss loss_config_list: - CTCLoss: - SARLoss: PostProcess: name: CTCLabelDecode Metric: name: RecMetric main_indicator: acc ignore_space: False Train: dataset: name: SimpleDataSet #修改为训练数据集所在的目录 data_dir: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data ext_op_transform_idx: 1 label_file_list: #修改为训练数据集所在的位置 - D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data\\rec\\train.txt transforms: - DecodeImage: img_mode: BGR channel_first: false - RecConAug: prob: 0.5 ext_data_num: 2 image_shape: [48, 320, 3] max_text_length: *max_text_length - RecAug: - MultiLabelEncode: - RecResizeImg: image_shape: [3, 48, 320] - KeepKeys: keep_keys: - image - label_ctc - label_sar - length - valid_ratio loader: shuffle: true #以下配置记得修改，数据集的图片数量不能小于以下配置的数值 batch_size_per_card: 4 drop_last: true num_workers: 4 Eval: dataset: name: SimpleDataSet #修改为训练数据集所在的目录 data_dir: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data label_file_list: #修改为训练数据集所在的位置 - D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data\\rec\\val.txt transforms: - DecodeImage: img_mode: BGR channel_first: false - MultiLabelEncode: - RecResizeImg: image_shape: [3, 48, 320] - KeepKeys: keep_keys: - image - label_ctc - label_sar - length - valid_ratio loader: shuffle: false drop_last: false #以下配置记得修改，数据集的图片数量不能小于以下配置的数值 batch_size_per_card: 4 num_workers: 4 步骤三：开始训练模型\n进入paddleOCR源码的根目录，打开cmd，输入以下命令\n1 python tools/train.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml 训练结果 步骤四：模型测试\n1 python tools/infer_rec.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml -o Global.pretrained_model=output/rec_ppocr_v3/latest.pdparams Global.infer_img=\u0026#34;C:\\Users\\lenovo\\Desktop\\paddle-ocr-data\\test\\res1.png\u0026#34; 识别结果（由于训练的图片数量较少且训练次数少，以下的识别结果并不好） 识别为了 0E0E，但原图却是很长一串 原图 四、配置文件参详解 参考教程：\nhttps://blog.csdn.net/qq_52852432/article/details/131817619 https://blog.csdn.net/m0_60657960/article/details/144725182 https://blog.csdn.net/m0_60657960/article/details/137072289\nhttps://blog.csdn.net/weixin_41819299/article/details/127914305\nhttps://blog.csdn.net/qq_43479628/article/details/141400126\nhttps://cloud.baidu.com/article/3360301\n可能遇到的问题\nhttps://github.com/PaddlePaddle/PaddleOCR/issues/13437\nhttps://github.com/PaddlePaddle/PaddleOCR/issues/6684\nhttps://github.com/PaddlePaddle/PaddleOCR/issues/2470\n","date":"2025-01-10T15:19:17+08:00","permalink":"https://h-yx-blog.github.io/p/paddleocr%E8%AE%AD%E7%BB%83%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE/","title":"PaddleOcr训练自定义数据"},{"content":" # 一、ocr识别函数\n注意 1. 如果角度分类器未初始化 （use_angle_cls=False），则在正向过程中不会使用它。 2. 对于 PDF 文件，如果输入是图像列表并且指定了 page_num，则只会处理前 page_num 张图像。 3. 源码中preprocess_image 函数用于通过应用 Alpha 颜色替换、反转和二值化（如果指定）来预处理输入图像。如下为preprocess_image函数\n形参: 参数名\t含义\nimg：OCR 图像。它可以是一个 ndarray、img_path 或 ndarray 列表。\ndet：是否使用文本检测。如果为 False，则仅执行文本识别。默认值为 True。\nrec：使用文本识别与否。如果为 False，则仅执行文本检测。默认值为 True。\ncls：是否使用角度分类器。默认值为 True。如果为 True，则可以识别旋转 180 度的文本。如果没有文本旋转 180 度，请使用 cls=False 以获得更好的性能。\nbin：将图像二值化为黑白。默认值为 False。\ninv：反转图像颜色。默认值为 False\nalpha_color：设置 RGB 颜色元组以进行透明零件更换。默认值为纯白色。\nslice：\t对大图像使用滑动窗口推理。det 和 rec 都必须为 True。需要 slice[“horizontal_stride”]、slice[“vertical_stride”]、slice[“merge_x_thres”]、slice[“merge_y_thres”] 的 int 值（参见 doc/ doc_en/ slice_en. md）。默认值为 {}。\n返回值: 如果 det 和 rec 均为 True，则返回每个图像的 OCR 结果列表。每个 OCR 结果都是每个检测到的文本区域的边界框和已识别文本的列表。 如果 det 为 True 且 rec 为 False，则返回每个图像检测到的边界框列表。 如果 det 为 False 且 rec 为 True，则返回每个图像的已识别文本列表。 如果 det 和 rec 均为 False，则返回每个图像的角度分类结果列表。 异常: AssertionError – 如果输入图像不是 ndarray、list、str 或 bytes 类型。 SystemExit – 如果 det 为 True，并且输入是图像列表\n二、PaddleOCR构造函数 PaddleOCR继承的父类如下 PaddleOCR构造函数可传入的参数详情见：https://paddlepaddle.github.io/PaddleOCR/latest/ppocr/blog/inference_args.html\n主要有以下类型的参数，每一种类型都有若干参数\n全局信息 预测引擎相关 文本检测模型相关 文本识别模型相关 端到端文本检测与识别模型相关 方向分类器模型相关 算法相关 ","date":"2025-01-06T16:50:51+08:00","permalink":"https://h-yx-blog.github.io/p/paddleocr%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/","title":"PaddleOCR参数详解"},{"content":"","date":"2025-01-05T21:31:55+08:00","permalink":"https://h-yx-blog.github.io/p/kafka%E5%85%A5%E9%97%A8%E5%8F%8A%E5%BA%94%E7%94%A8/","title":"Kafka入门及应用"},{"content":"一、基本概念 大数据生态系统里很多组件的命名都是某种动物，例如Hadoop是🐘，hive是🐝，zookeeper就是动物园管理者，是管理大数据生态系统各组件的管理员。\nzookeeper是经典的分布式数据一致性解决方案，致力于为分布式应用提供一个高性能，高可用，且具有严格顺序访问控制能力的分布式协调存储服务。\n1.1 应用场景 维护配置信息 Java编程经常会遇到配置项，例如数据库的user、password等，通常配置信息会放在配置文件中，再把配置文件放在服务器上。当需要修改配置信息时，要去服务器上修改对应的配置文件，但在分布式系统中很多服务器都需要使用该配置文件，因此必须保证该配置服务的高可用性和各台服务器上配置的一致性。通常会将配置文件部署在一个集群上，但一个集群涉及的服务器数量是很庞大的，如果一台台服务器逐个修改配置文件是效率很低且危险的，因此需要一种服务可以高效快速且可靠地完成配置项的更改工作。 zookeeper就可以提供这种服务，使用Zab一致性协议保证一致性。hbase中客户端就是连接zookeeper获得必要的hbase集群的配置信息才可以进一步操作。在开源消息队列Kafka中，也使用zookeeper来维护broker的信息。在dubbo中也广泛使用zookeeper管理一些配置来实现服务治理。\n分布式锁服务 一个集群是一个分布式系统，由多台服务器组成。为了提高并发度和可靠性，在多台服务器运行着同一种服务。当多个服务在运行时就需要协调各服务的进度，有时候需要保证当某个服务在进行某个操作时，其他的服务都不能进行该操作，即对该操作进行加锁，如果当前机器故障，释放锁并fall over到其他机器继续执行。\n集群管理 zookeeper会将服务器加入/移除的情况通知给集群中其他正常工作的服务器，以及即使调整存储和计算等任务的分配和执行等，此外zookeeper还会对故障的服务器做出诊断并尝试修复。\n生成分布式唯一ID 在过去的单库单表系统中，通常使用数据库字段自带的auto_increment熟悉自动为每条记录生成一个唯一的id。但分库分表后就无法依靠该属性来标识一个唯一的记录。此时可以使用zookeeper在分布式环境下生成全局唯一性id。每次要生成一个新id时，创建一个持久顺序结点，创建操作返回的结点序号，即为新id，然后把比自己结点小的删除。\n1.2 设计目标 高性能 将数据存储在内存中，直接服务于客户端的所有非事务请求，尤其适合读为主的应用场景 高可用 一般以集群方式对外提供服务，每台机器都会在内存中维护当前的服务状态，每台机器之间都保持通信。只要集群中超过一半机器都能正常工作，那么整个集群就能够正常对外服务。 严格顺序访问 对于客户端的每个更新请求，zookeeper都会生成全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序。 1.3 数据结构 zookeeper的数据结点可以视为树状结构（或者目录），树中各节点成为znode，一个znode可以有多个子结点。zookeeper结点在结构上表现为树状，使用路径来定位某个znode。 znode兼具文件和目录两种特点，既像文件一样维护着数据、元信息、ACL、时间戳等数据结构，又像目录一样可以作为路径标识的一部分。\nznode大体上分为三部分（使用get命令查看）\n结点的数据 结点的子结点 结点的状态 结点类型（在创建时被确定且不能更改）\n临时结点：生命周期依赖于创建它的会话，会话结束结点将被自动删除。临时结点不允许拥有子结点。 持久化结点：生命周期不依赖于会话，只有在客户端显式执行删除操作时才被删除。 1.4 ACL权限控制 此处暂作了解，可参考：https://blog.csdn.net/qq_41112238/article/details/105240421\n二、基本命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #1.连接zooker服务端 ip和port记得换为具体的ip和端口，zk默认端口是2181 ./zkCli.sh –server ip:port #2.断开连接 quit #3.查看命令帮助 help #4.显示指定目录下节点 ls 目录 #5.创建节点 create /节点具体路径 value #6.获取节点的值 get /节点具体路径 #7.设置节点的值 set /节点具体路径 value #8.删除单个节点 delete /节点具体路径 #9.删除带有子节点的节点 deleteall /节点具体路径 #10.创建临时节点 create -e /节点具体路径 value #11.创建顺序节点 create -s /节点具体路径 value #12.查询节点详细信息 ls –s /节点具体路径 节点信息：\nczxid：节点被创建的事务ID ctime: 创建时间 mzxid: 最后一次被更新的事务ID mtime: 修改时间 pzxid：子节点列表最后一次被更新的事务ID cversion：子节点的版本号 dataversion：数据版本号 aclversion：权限版本号 ephemeralOwner：用于临时节点，代表临时节点的事务ID，如果为持久节点则为0 dataLength：节点存储的数据的长度 numChildren：当前节点的子节点个数 三、SpringBoot集成zk客户端 常见的ZooKeeper Java API ：\n原生Java API ZkClient Curator 下面以Curator来进行集成 引入依赖\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-framework\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3.1 创建、修改、查询、删除节点操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.framework.api.BackgroundCallback; import org.apache.curator.framework.api.CuratorEvent; import org.apache.curator.retry.ExponentialBackoffRetry; import org.apache.zookeeper.CreateMode; import org.apache.zookeeper.data.Stat; import org.junit.After; import org.junit.Before; import org.junit.Test; import java.util.List; public class CuratorTest { private CuratorFramework client; /** * 建立连接 */ @Before public void testConnect() { /* * * @param connectString 连接字符串。zk server 地址和端口 \u0026#34;192.168.149.135:2181,192.168.149.136:2181\u0026#34; * @param sessionTimeoutMs 会话超时时间 单位ms * @param connectionTimeoutMs 连接超时时间 单位ms * @param retryPolicy 重试策略 */ /* //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000,10); //1.第一种方式 CuratorFramework client = CuratorFrameworkFactory.newClient(\u0026#34;192.168.149.135:2181\u0026#34;, 60 * 1000, 15 * 1000, retryPolicy);*/ //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000, 10); //2.第二种方式 //CuratorFrameworkFactory.builder(); client = CuratorFrameworkFactory.builder() .connectString(\u0026#34;ip地址:2181\u0026#34;) //此处一定要修改为具体的zookeeper所在的服务器ip .sessionTimeoutMs(60 * 1000) .connectionTimeoutMs(15 * 1000) .retryPolicy(retryPolicy) .namespace(\u0026#34;mydemo\u0026#34;) .build(); //开启连接 client.start(); } //==============================create============================================================================= /** * 创建节点：create 持久 临时 顺序 数据 * 1. 基本创建 ：create().forPath(\u0026#34;\u0026#34;) * 2. 创建节点 带有数据:create().forPath(\u0026#34;\u0026#34;,data) * 3. 设置节点的类型：create().withMode().forPath(\u0026#34;\u0026#34;,data) * 4. 创建多级节点 /app1/p1 ：create().creatingParentsIfNeeded().forPath(\u0026#34;\u0026#34;,data) */ @Test public void testCreate() throws Exception { //2. 创建节点 带有数据 //如果创建节点，没有指定数据，则默认将当前客户端的ip作为数据存储 String path = client.create().forPath(\u0026#34;/app2\u0026#34;, \u0026#34;hehe\u0026#34;.getBytes()); System.out.println(path); } @Test public void testCreate2() throws Exception { //1. 基本创建 //如果创建节点，没有指定数据，则默认将当前客户端的ip作为数据存储 String path = client.create().forPath(\u0026#34;/app1\u0026#34;); System.out.println(path); } @Test public void testCreate3() throws Exception { //3. 设置节点的类型 //默认类型：持久化 String path = client.create().withMode(CreateMode.EPHEMERAL).forPath(\u0026#34;/app3\u0026#34;); System.out.println(path); } @Test public void testCreate4() throws Exception { //4. 创建多级节点 /app1/p1 //creatingParentsIfNeeded():如果父节点不存在，则创建父节点 String path = client.create().creatingParentsIfNeeded().forPath(\u0026#34;/app4/p1\u0026#34;); System.out.println(path); } //===========================get================================================================================ /** * 查询节点： * 1. 查询数据：get: getData().forPath() * 2. 查询子节点： ls: getChildren().forPath() * 3. 查询节点状态信息：ls -s:getData().storingStatIn(状态对象).forPath() */ @Test public void testGet1() throws Exception { //1. 查询数据：get byte[] data = client.getData().forPath(\u0026#34;/app1\u0026#34;); System.out.println(new String(data)); } @Test public void testGet2() throws Exception { // 2. 查询子节点： ls List\u0026lt;String\u0026gt; path = client.getChildren().forPath(\u0026#34;/\u0026#34;); System.out.println(path); } @Test public void testGet3() throws Exception { Stat status = new Stat(); System.out.println(status); //3. 查询节点状态信息：ls -s client.getData().storingStatIn(status).forPath(\u0026#34;/app1\u0026#34;); System.out.println(status); } //===========================set================================================================================ /** * 修改数据 * 1. 基本修改数据：setData().forPath() * 2. 根据版本修改: setData().withVersion().forPath() * * version 是通过查询出来的。目的就是为了让其他客户端或者线程不干扰我。 * * @throws Exception */ @Test public void testSet() throws Exception { client.setData().forPath(\u0026#34;/app1\u0026#34;, \u0026#34;itcast\u0026#34;.getBytes()); } @Test public void testSetForVersion() throws Exception { Stat status = new Stat(); //3. 查询节点状态信息：ls -s client.getData().storingStatIn(status).forPath(\u0026#34;/app1\u0026#34;); int version = status.getVersion();//查询出来的 3 System.out.println(version); client.setData().withVersion(version).forPath(\u0026#34;/app1\u0026#34;, \u0026#34;hehe\u0026#34;.getBytes()); } //===========================delete================================================================================ /** * 删除节点： delete deleteall * 1. 删除单个节点:delete().forPath(\u0026#34;/app1\u0026#34;); * 2. 删除带有子节点的节点:delete().deletingChildrenIfNeeded().forPath(\u0026#34;/app1\u0026#34;); * 3. 必须成功的删除:为了防止网络抖动。本质就是重试。 client.delete().guaranteed().forPath(\u0026#34;/app2\u0026#34;); * 4. 回调：inBackground * @throws Exception */ @Test public void testDelete() throws Exception { // 1. 删除单个节点 client.delete().forPath(\u0026#34;/app1\u0026#34;); } @Test public void testDelete2() throws Exception { //2. 删除带有子节点的节点 client.delete().deletingChildrenIfNeeded().forPath(\u0026#34;/app4\u0026#34;); } @Test public void testDelete3() throws Exception { //3. 必须成功的删除 client.delete().guaranteed().forPath(\u0026#34;/app2\u0026#34;); } @Test public void testDelete4() throws Exception { //4. 回调 client.delete().guaranteed().inBackground(new BackgroundCallback(){ @Override public void processResult(CuratorFramework client, CuratorEvent event) throws Exception { System.out.println(\u0026#34;我被删除了~\u0026#34;); System.out.println(event); } }).forPath(\u0026#34;/app1\u0026#34;); } @After public void close() { if (client != null) { client.close(); } } } 3.2 监听器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 package com.itheima.curator; import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.framework.api.BackgroundCallback; import org.apache.curator.framework.api.CuratorEvent; import org.apache.curator.framework.recipes.cache.*; import org.apache.curator.retry.ExponentialBackoffRetry; import org.apache.zookeeper.CreateMode; import org.apache.zookeeper.data.Stat; import org.junit.After; import org.junit.Before; import org.junit.Test; import java.util.List; public class CuratorWatcherTest { private CuratorFramework client; /** * 建立连接 */ @Before public void testConnect() { /* * * @param connectString 连接字符串。zk server 地址和端口 \u0026#34;192.168.149.135:2181,192.168.149.136:2181\u0026#34; * @param sessionTimeoutMs 会话超时时间 单位ms * @param connectionTimeoutMs 连接超时时间 单位ms * @param retryPolicy 重试策略 */ /* //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000,10); //1.第一种方式 CuratorFramework client = CuratorFrameworkFactory.newClient(\u0026#34;192.168.149.135:2181\u0026#34;, 60 * 1000, 15 * 1000, retryPolicy);*/ //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000, 10); //2.第二种方式 //CuratorFrameworkFactory.builder(); client = CuratorFrameworkFactory.builder() .connectString(\u0026#34;ip地址:2181\u0026#34;) //此处ip地址修改为zk所在服务器的ip .sessionTimeoutMs(60 * 1000) .connectionTimeoutMs(15 * 1000) .retryPolicy(retryPolicy) //在这种策略下，如何itheima这个节点下没有子节点了，过一会就会自动把itheima这个节点删除了 .namespace(\u0026#34;itheima\u0026#34;) .build(); //开启连接 client.start(); } @After public void close() { if (client != null) { client.close(); } } /** * 演示 NodeCache：给指定一个节点注册监听器 */ @Test public void testNodeCache() throws Exception { //1. 创建NodeCache对象 final NodeCache nodeCache = new NodeCache(client,\u0026#34;/app1\u0026#34;); //2. 注册监听 nodeCache.getListenable().addListener(new NodeCacheListener() { @Override public void nodeChanged() throws Exception { System.out.println(\u0026#34;节点变化了~\u0026#34;); //获取修改节点后的数据 byte[] data = nodeCache.getCurrentData().getData(); System.out.println(new String(data)); } }); //3. 开启监听.如果设置为true，则开启监听是，加载缓冲数据 nodeCache.start(true); while (true){ } } /** * 演示 PathChildrenCache：监听某个节点的所有子节点们 */ @Test public void testPathChildrenCache() throws Exception { //1.创建监听对象 PathChildrenCache pathChildrenCache = new PathChildrenCache(client,\u0026#34;/app2\u0026#34;,true); //2. 绑定监听器 pathChildrenCache.getListenable().addListener(new PathChildrenCacheListener() { @Override public void childEvent(CuratorFramework client, PathChildrenCacheEvent event) throws Exception { System.out.println(\u0026#34;子节点变化了~\u0026#34;); System.out.println(event); //监听子节点的数据变更，并且拿到变更后的数据 //1.获取类型 PathChildrenCacheEvent.Type type = event.getType(); //2.判断类型是否是update if(type.equals(PathChildrenCacheEvent.Type.CHILD_UPDATED)){ System.out.println(\u0026#34;数据变了！！！\u0026#34;); byte[] data = event.getData().getData(); System.out.println(new String(data)); } } }); //3. 开启 pathChildrenCache.start(); while (true){ } } /** * 演示 TreeCache：监听某个节点自己和所有子节点们 */ @Test public void testTreeCache() throws Exception { //1. 创建监听器 TreeCache treeCache = new TreeCache(client,\u0026#34;/app2\u0026#34;); //2. 注册监听 treeCache.getListenable().addListener(new TreeCacheListener() { @Override public void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception { System.out.println(\u0026#34;节点变化了\u0026#34;); System.out.println(event); } }); //3. 开启 treeCache.start(); while (true){ } } } 参考文章 https://blog.csdn.net/qq_41112238/article/details/105240421\n","date":"2025-01-04T21:10:52+08:00","permalink":"https://h-yx-blog.github.io/p/zookeeper%E5%85%A5%E9%97%A8/","title":"Zookeeper入门"},{"content":"1.1 下载安装 1、环境准备\nZooKeeper服务器是用Java创建的，它运行在JVM之上。需要安装JDK 7或更高版本。\n2、上传\n将下载的ZooKeeper放到/opt/ZooKeeper目录下\n1 2 3 4 5 6 7 8 #上传zookeeper alt+p put f:/setup/apache-zookeeper-3.5.6-bin.tar.gz #打开 opt目录 cd /opt #创建zooKeeper目录 mkdir zooKeeper #将zookeeper安装包移动到 /opt/zooKeeper mv apache-zookeeper-3.5.6-bin.tar.gz /opt/zookeeper/ 3、解压\n将tar包解压到/opt/zookeeper目录下\n1 tar -zxvf apache-ZooKeeper-3.5.6-bin.tar.gz 1.2 配置启动 1、配置zoo.cfg\n进入到conf目录拷贝一个zoo_sample.cfg并完成配置\n1 2 3 4 #进入到conf目录 cd /opt/zooKeeper/apache-zooKeeper-3.5.6-bin/conf/ #拷贝 cp zoo_sample.cfg zoo.cfg 修改zoo.cfg\n1 2 3 4 5 6 #打开目录 cd /opt/zooKeeper/ #创建zooKeeper存储目录 mkdir zkdata #修改zoo.cfg vim /opt/zooKeeper/apache-zooKeeper-3.5.6-bin/conf/zoo.cfg 修改存储目录：dataDir=/opt/zookeeper/zkdata\n2、启动ZooKeeper\n1 2 3 cd /opt/zooKeeper/apache-zooKeeper-3.5.6-bin/bin/ #启动 ./zkServer.sh start 看到上图表示ZooKeeper成功启动\n3、查看ZooKeeper状态\n1 ./zkServer.sh status zookeeper启动成功。standalone代表zk没有搭建集群，现在是单节点\nzookeeper没有启动\n","date":"2025-01-04T13:28:19+08:00","permalink":"https://h-yx-blog.github.io/p/zookeeper%E6%90%AD%E5%BB%BA/","title":"Zookeeper搭建"},{"content":"一、概念 1. 大数据处理流程 上图是一个简化的大数据处理流程图，大数据处理的主要流程包括数据收集、数据存储、数据处理、数据应用等主要环节。下面我们逐一对各个环节所需要的技术栈进行讲解：\n1.1 数据收集 大数据处理的第一步，第一种是通过 Sqoop 或者 Cannal 等工具进行定时抽取或者实时同步；第二种是各种埋点日志，通过 Flume 进行实时收集。\n大数据处理的第一步是数据的收集。现在的中大型项目通常采用微服务架构进行分布式部署，所以数据的采集需要在多台服务器上进行，且采集过程不能影响正常业务的开展。基于这种需求，就衍生了多种日志收集工具，如 Flume 、Logstash、Kibana 等，它们都能通过简单的配置完成复杂的数据收集和数据聚合。\n1.2 数据存储 大数据处理的第二步，将数据存储到 HDFS 中，实时日志流情况下通过 Kafka 输出给后面的流式计算引擎。\n收集到数据后，下一个问题就是：数据该如何进行存储？通常最为熟知是 MySQL、Oracle 等传统的关系型数据库，它们的优点是能够快速存储结构化的数据，并支持随机访问。但大数据的数据结构通常是半结构化（如日志数据）、甚至是非结构化的（如视频、音频数据），为了解决海量半结构化和非结构化数据的存储，衍生了 Hadoop HDFS 、KFS、GFS 等分布式文件系统，它们都能够支持结构化、半结构和非结构化数据的存储，并可以通过增加机器进行横向扩展。\n分布式文件系统完美地解决了海量数据存储的问题，但是一个优秀的数据存储系统需要同时考虑数据存储和访问两方面的问题，比如你希望能够对数据进行随机访问，这是传统的关系型数据库所擅长的，但却不是分布式文件系统所擅长的，那么有没有一种存储方案能够同时兼具分布式文件系统和关系型数据库的优点，基于这种需求，就产生了 HBase、MongoDB。\n1.3 数据分析 大数据的核心环节，包括离线处理和流处理两种方式，对应的计算引擎包括 MapReduce、Spark、Flink 等，处理完的结果会保存到已经提前设计好的数据仓库中，或者 HBase、Redis、RDBMS 等各种存储系统上。\n大数据处理最重要的环节就是数据分析，数据分析通常分为两种：批处理和流处理。\n批处理：对一段时间内海量的离线数据进行统一的处理，对应的处理框架有 Hadoop MapReduce、Spark、Flink 等； 流处理：对运动中的数据进行处理，即在接收数据的同时就对其进行处理，对应的处理框架有 Storm、Spark Streaming、Flink Streaming 等。 批处理和流处理各有其适用的场景，时间不敏感或者硬件资源有限，可以采用批处理；时间敏感和及时性要求高就可以采用流处理。随着服务器硬件的价格越来越低和大家对及时性的要求越来越高，流处理越来越普遍，如股票价格预测和电商运营数据分析等。\n上面的框架都是需要通过编程来进行数据分析，那么如果你不是一个后台工程师，是不是就不能进行数据的分析了？当然不是，大数据是一个非常完善的生态圈，有需求就有解决方案。为了能够让熟悉 SQL 的人员也能够进行数据的分析，查询分析框架应运而生，常用的有 Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix 等。这些框架都能够使用标准的 SQL 或者 类 SQL 语法灵活地进行数据的查询分析。这些 SQL 经过解析优化后转换为对应的作业程序来运行，如 Hive 本质上就是将 SQL 转换为 MapReduce 作业，Spark SQL 将 SQL 转换为一系列的 RDDs 和转换关系（transformations），Phoenix 将 SQL 查询转换为一个或多个 HBase Scan。\n1.4 数据应用 应用场景：数据可视化、业务决策、推荐算法优化、机器学习\u0026hellip;\n数据分析完成后，接下来就是数据应用的范畴，这取决于你实际的业务需求。比如你可以将数据进行可视化展现，或者将数据用于优化你的推荐算法，这种运用现在很普遍，比如短视频个性化推荐、电商商品推荐、头条新闻推荐等。当然你也可以将数据用于训练你的机器学习模型，这些都属于其他领域的范畴，都有着对应的框架和技术栈进行处理，这里就不一一赘述。\n1.5 其他框架 上面是一个标准的大数据处理流程所用到的技术框架。但是实际的大数据处理流程比上面复杂很多，针对大数据处理中的各种复杂问题分别衍生了各类框架：\n单机的处理能力都是存在瓶颈的，所以大数据框架都是采用集群模式进行部署，为了更方便的进行集群的部署、监控和管理，衍生了 Ambari、Cloudera Manager 等集群管理工具； 想要保证集群高可用，需要用到 ZooKeeper ，ZooKeeper 是最常用的分布式协调服务，它能够解决大多数集群问题，包括首领选举、失败恢复、元数据存储及其一致性保证。同时针对集群资源管理的需求，又衍生了 Hadoop YARN ; 复杂大数据处理的另外一个显著的问题是，如何调度多个复杂的并且彼此之间存在依赖关系的作业？基于这种需求，产生了 Azkaban 和 Oozie 等工作流调度框架； 大数据流处理中使用的比较多的另外一个框架是 Kafka，它可以用于消峰，避免在秒杀等场景下并发数据对流处理程序造成冲击； 另一个常用的框架是 Sqoop ，主要是解决了数据迁移的问题，它能够通过简单的命令将关系型数据库中的数据导入到 HDFS 、Hive 或 HBase 中，或者从 HDFS 、Hive 导出到关系型数据库上。\n1.6 框架分类 日志收集框架：Flume、Logstash、Filebeat\n分布式文件存储系统：Hadoop HDFS\n数据库系统：Mongodb、HBase\n分布式计算框架：\n批处理框架：Hadoop MapReduce 流处理框架：Storm 混合处理框架：Spark、Flink 查询分析框架：Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix\n集群资源管理器：Hadoop YARN\n分布式协调服务：Zookeeper\n数据迁移工具：Sqoop\n任务调度框架：Azkaban、Oozie\n集群部署和监控：Ambari、Cloudera Manager\n2. 数据仓库 2.1 什么是数据仓库？ 在计算中，数据仓库（DW或DWH）也称为企业数据仓库（EDW），是用于报告和数据分析的系统，被视为商业智能的核心组件。DWs从一个或多个不同源的综合数据的中央储存库。他们将当前和历史数据存储在一个地方，用于为整个企业的工作人员创建分析报告。\n3. OLTP与OLAP的区别 OLTP与OLAP是数据仓库的两种操作方式。 当今的数据处理大致可分为两大类，联机事务处理OLTP（on-line transaction processing） 和联机分析处理OLAP（on-line analytical processing)。\nOLTP是传统关系型数据库的主要应用，用来执行一些基本的、日常的事务处理，比如数据库记录的增、删、改、查等等。而OLAP则是分布式数据库的主要应用，它对实时性要求不高，但处理的数据量大，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果，通常应用于复杂的动态报表系统上。\n4. ETL与DM的区别 ETL/Extraction-Transformation-Loading——用于完成DB到DW的数据转存，它将DB中的某一个时间点的状态，“抽取”出来，根据DW的存储模型要求，“转换”一下数据格式，然后再“加载”到DW的一个过程，这里需要强调的是，DB的模型是ER模型，遵从范式化设计原则，而DW的数据模型是雪花型结构或者星型结构，用的是面向主题，面向问题的设计思路，所以DB和DW的模型结构不同，需要进行转换。\nDM/Data Mining/数据挖掘——这个挖掘，不是简单的统计了，他是根据概率论的或者其他的统计学原理，将DW中的大数据量进行分析，找出我们不能直观发现的规律。\n5. 行式存储与列式存储 列式存储是指一列中的数据在存储介质中是连续存储的；\n行式存储是指一行中的数据在存储介质中是连续存储的。 什么时候使用列式存储，什么时候使用行式存储？\n如果一个OLPA类型查询，在海量数据行中，只关心几列数据，效率就比较低了。这种情况列存储就有很大优势。同样如果每次查询设计的数据量较小，或者大部分查询都需要整行数据，行存储就有优势。\n如果需要关注整张表或者大部分数据，不是单独几列而且关注内容不需要聚集运算，推荐行式存储；\n如果主要关注大量数据中某几列内容，或者要频繁聚集，然后对聚集后数据进行数据分析，推荐列式存储。\n6. HDFS（分布式文件系统） HDFS(Hadoop Distribute File System)，是适用于大的数据集的支持高吞吐和高容错的运行在通用机器上的分布式系统。Hapoop就是使用HDFS来存储海量数据，使用MapReduce来处理数据。但是hdfs主要是实现批量数据的处理，并且通过顺序方式访问数据，如果要查找数据必须搜索整个数据集，如果要随机读取数据，效率很低。\n7. MapReduce 上文多次提出，以MapReduce提供计算能力。MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集\nMapReduce擅长处理大数据。MapReduce的思想就是“分而治之”。Mapper负责“分”，即把复杂的任务分解为若干个“简单的任务”来处理。“简单的任务”包含三层含义：一是数据或计算的规模相对原任务要大大缩小；二是就近计算原则，即任务会分配到存放着所需数据的节点上进行计算；三是这些小任务可以并行计算，彼此间几乎没有依赖关系。Reducer负责对map阶段的结果进行汇总。\n二、特点 大数据特点\n①Volume：数据量大，包括采集、存储和计算的量都非常大。大数据的起始计量单位至少是P（1000个T）、E（100万个T）或Z（10亿个T）。\n②Variety：种类和来源多样化。包括结构化、半结构化和非结构化数据，具体表现为网络日志、音频、视频、图片、地理位置信息等等，多类型的数据对数据的处理能力提出了更高的要求。\n③Value：数据价值密度相对较低，或者说是浪里淘沙却又弥足珍贵。随着互联网以及物联网的广泛应用，信息感知无处不在，信息海量，但价值密度较低，如何结合业务逻辑并通过强大的机器算法来挖掘数据价值，是大数据时代最需要解决的问题。\n④Velocity：数据增长速度快，处理速度也快，时效性要求高。比如搜索引擎要求几分钟前的新闻能够被用户查询到，个性化推荐算法尽可能要求实时完成推荐。这是大数据区别于传统数据挖掘的显著特征。\n⑤Veracity：数据的准确性和可信赖度，即数据的质量。\n参考：\nhttps://github.com/heibaiying https://javabetter.cn/xuexiluxian/bigdata.html#%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE\n","date":"2025-01-01T11:17:11+08:00","permalink":"https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/","title":"大数据基础"},{"content":"Anaconda是一个环境管理工具，每一个环境可以理解为一个房间，每个环境存放着不同的包，互不干扰\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 创建环境：conda create -n 环境名字 python=3.10 复制虚拟环境：conda create -n 副本虚拟环境名 --clone 虚拟环境名 进入环境：activate 环境名字 （Linux环境下要用：conda activate 环境名字） 查看有哪些环境： conda env list 查看conda信息：conda info -v 安装包：conda install django=2.0 最后django=2.0是指包名和版本号 查看都有哪些包 conda list 更新包：conda update 包名 删除包：conda remove 包名 搜索包：conda search package-name，可以模糊搜索 环境切换： activate 环境名 删除环境：conda remove -n 环境名 --all 最后表示把环境里面的包也一起删除 ","date":"2024-12-28T11:20:54+08:00","permalink":"https://h-yx-blog.github.io/p/anaconda%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/","title":"Anaconda基础使用"},{"content":"Hugo语法 1、本地启动Hugo博客 进入博客根目录 比如我的是：D:\\blog\\hugo_extended_withdeploy_0.140.1_windows-amd64\\yuta-blog\n1 hugo server -D 2、创建文章 同样进入 D:\\blog\\hugo_extended_withdeploy_0.140.1_windows-amd64\\yuta-blog\n1 hugo new content post/文件名称/index.md 文件名称后面就是博客的文章名称，最后一定是要 index.md\n3、提交代码 同样 进入 D:\\blog\\hugo_extended_withdeploy_0.140.1_windows-amd64\\yuta-blog\n1 2 3 git add . git commit -m \u0026#34;本次提交的变更\u0026#34; git push ","date":"2024-12-27T17:16:55+08:00","permalink":"https://h-yx-blog.github.io/p/hugo-grammar/","title":"Hugo Grammar"},{"content":" 1 netstat -nlpt #查看运行的进程及其占用的端口 ","date":"2024-12-27T02:04:07+08:00","permalink":"https://h-yx-blog.github.io/p/linux/","title":"Linux"},{"content":"","date":"2024-12-27T01:50:08+08:00","permalink":"https://h-yx-blog.github.io/p/java/","title":"Java"},{"content":"Python入门语法 一、数据类型 常见数据类型 类型 描述 说明 数字（Number） 支持 •整数（int） •浮点数（float） •复数（complex） •布尔（bool） 整数（int），如：10、-10 浮点数（float），如：13.14、-13.14 复数（complex），如：4+3j，以j结尾表示复 数\n布尔（bool）表达现实生活中的逻辑，即真和假，True表示真，False表示假。 True本质上是一个数字记作1，False记作0 字符串（String） 描述文本的一种数据类型 字符串（string）由任意数量的字符组成 列表（List） 有序的可变序列 Python中使用最频繁的数据类型，可有序记录一堆数据 元组（Tuple） 有序的不可变序列 可有序记录一堆不可变的Python数据集合 集合（Set） 无序不重复集合 可无序记录一堆不重复的Python数据集合 字典（Dictionary） 无序Key-Value集合 可无序记录一堆Key-Value型的Python数据集合 type() 使用type()方法可以查看当前变量的数据类型\n数据类型转换 语句(函数) 说明 int(x) 将x转换为一个整数 float(x) 将x转换为一个浮点数 str(x) 将对象 x 转换为字符串 注意：浮点数转整数会丢失精度，即会丢失小数部分\n命名规范 见名知意 下划线命名法 （由于历史原因，python更推荐使用下划线命名） 英文字母全小写 在命名时不允许与关键字相同，python关键字如下\n运算符 运算符 描述 实例 + 加 两个对象相加 a + b 输出结果 30 - 减 得到负数或是一个数减去另一个数 a - b 输出结果 -10 * 乘 两个数相乘或是返回一个被重复若干次的字符串 a * b 输出结果 200 / 除 b / a 输出结果 2 // 取整除 返回商的整数部分 9//2 输出结果 4 , 9.0//2.0 输出结果 4.0 % 取余 返回除法的余数 b % a 输出结果 0 * * 指数 a * *b 为10的20次方， 输出结果 100000000000000000000 常见数据类型的格式化 格式符号 转化 %s 将内容转换成字符串，放入占位位置 %d 将内容转换成整数，放入占位位置 %f 将内容转换成浮点型，放入占位位置 格式化的精度控制\n可以使用辅助符号\u0026quot;m.n\u0026quot;来控制数据的宽度和精度\nm，控制宽度，要求是数字（很少使用）,设置的宽度小于数字自身，不生效 .n，控制小数点精度，要求是数字，会进行小数的四舍五入 示例：\n%5d：表示将整数的宽度控制在5位，如数字11，被设置为5d，就会变成：[空格][空格][空格]11，用三个空格补足宽度。 %5.2f：表示将宽度控制为5，将小数点精度设置为2 小数点和小数部分也算入宽度计算。如，对11.345设置了%7.2f 后，结果是：[空格][空格]11.35。2个空格补足宽度，小数部分限制2位精度后，四舍五入为 .35\n%.2f：表示不限制宽度，只设置小数点精度为2，如11.345设置%.2f后，结果是11.35 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 name = \u0026#34;黄永禧\u0026#34; setup_year = 2024 stock_price = 19.99 message = \u0026#34;%s，成立于：%d，我今天的股价是：%f\u0026#34; % (name, setup_year, stock_price) print(message) num1 = 11 num2 = 11.345 print(\u0026#34;数字11宽度限制5，结果是：%5d\u0026#34; % num1) print(\u0026#34;数字11宽度限制1，结果是：%1d\u0026#34; % num1) print(\u0026#34;数字11.345宽度限制7，小数精度2，结果是：%7.2f\u0026#34; % num2) print(\u0026#34;数字11.345不限制，小数精度2，结果是：%.2f\u0026#34; % num2) 字符串格式化常用的方法：**f\u0026#34;{占位}\u0026#34;** name = \u0026#34;黄永禧\u0026#34; set_up_year = 2024 stock_price = 19.99 print(f\u0026#34;我是{name}，我成立于：{set_up_year}年，我今天的股价是：{stock_price}\u0026#34;) 二、判断语句 1.写法 if 条件1:\n条件1满足应做的事情\n条件1满足应做的事情\nelif 条件2:\n条件2满足应做的事情\n条件2满足应做的事情\nelif 条件N:\n条件N满足应做的事情\n条件N满足应做的事情\nelse:\n所有条件都不满足应做的事情\n所有条件都不满足应做的事情\n注意：① if elif else的结尾都要有分号 : 来结尾\n② python是使用缩进来控制代码块的归属\n③elif可以写多个\n④if语句可以嵌套，嵌套时注意缩进来表示代码块的归属\n三、循环语句 1.while循环 while 条件:\n条件满足时，执行的逻辑1\n条件满足时，执行的逻辑2\n条件满足时，执行的逻辑N\n2.for循环 for 临时变量 in 待处理数据集:\n满足循环条件时进行的逻辑处理\n3.range语句 range(num) # 获取一个从0开始，到num结束的数字序列（不含num本身）。如range(5)取得的数据是：[0, 1, 2, 3, 4]\nrange(num1,num2) # 获得一个从num1开始，到num2结束的数字序列（不含num2本身）。如，range(5, 10)取得的数据是：[5, 6, 7, 8, 9]\nrange(num1,num2,step) # 获得一个从num1开始，到num2结束的数字序列（不含num2本身），数字之间的步长，以step为准（step默认为1）。如，range(5, 10, 2)取得的数据是：[5, 7, 9]\n4.变量作用域 第二个print语句中，是可以访问到i变量的。但是：出于规范，不建议这样访问\n1 2 3 4 5 6 for i in range(5) print(i) print(i) 5.continue 和break python在循环中与java一样，可以使用continue跳过当次循环，或使用break跳出整个循环\n四.Python函数 1.函数定义 def 函数名(传入参数1,传入参数2):\n函数体\nreturn 返回值\n注意：\n① 参数如不需要，可以省略\n② 返回值如不需要，可以省略\n③ 函数必须先定义后使用\n如果函数没有返回值，其实是返回None类型\n在if判断中，None等同于False\n2.函数说明文档 当要对函数做注释说明时，一般规范如下\ndef add(x, y):\n\u0026quot;\u0026quot;\u0026quot;\nadd函数可以接收2个参数，进行2数相加的功能\n:param x: 形参x表示相加的其中一个数字\n:param y: 形参y表示相加的另一个数字\n:return: 返回值是2数相加的结果\n\u0026quot;\u0026quot;\u0026quot;\nresult = x + y\nprint(f\u0026quot;2数相加的结果是：{result}\u0026quot;)\nreturn result\n3.函数多个返回值 返回多个返回值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def test_return(): return 1, \u0026#34;hello\u0026#34;, True mylist = test_return() print(mylist) x, y, z = test_return() print(x) print(y) print(z) 注意：\n① 按照返回值的顺序，写对应顺序的多个变量接收即可\n② 变量之间用逗号隔开\n③ 支持不同类型的数据return\n4.函数多种传参方式 4.1 位置参数 1 2 3 4 5 6 7 8 9 10 11 调用函数时根据函数定义的参数位置来传递参数。传递的参数和定义的参数的顺序及个数必须一致 def user_info(name, age, gender): print(f\u0026#34;姓名是:{name}, 年龄是:{age}, 性别是:{gender}\u0026#34;) # 位置参数 - 默认使用形式 user_info(\u0026#39;小明\u0026#39;, 20, \u0026#39;男\u0026#39;) 4.2 关键字参数 函数调用时通过“键=值”形式传递参数，可以让函数更加清晰、容易使用，同时也清除了参数的顺序需求.\n函数调用时，如果有位置参数时，位置参数必须在关键字参数的前面，但关键字参数之间不存在先后顺序\n1 2 3 4 5 6 7 8 9 10 def user_info(name, age, gender): print(f\u0026#34;姓名是:{name}, 年龄是:{age}, 性别是:{gender}\u0026#34;) user_info(name=\u0026#39;小王\u0026#39;, age=11, gender=\u0026#39;女\u0026#39;) user_info(age=10, gender=\u0026#39;女\u0026#39;, name=\u0026#39;肖肖\u0026#39;) # 可以不按照参数的定义顺序传参 user_info(\u0026#39;甜甜\u0026#39;, gender=\u0026#39;女\u0026#39;, age=9) 4.3 不定长参数 不定长参数也叫可变参数. 用于不确定调用的时候会传递多少个参数(不传参也可以)的场景.\n类型一：位置传递\n如下代码，传进的所有参数都会被args变量收集，它会根据传进参数的位置合并为一个元组(tuple)，args是元组类型，这就是位置传递\n1 2 3 4 5 6 7 8 9 10 # 不定长 - 位置不定长, *号 # 不定长定义的形式参数会作为元组存在，接收不定长数量的参数传入 def user_info( *args): print(f\u0026#34;args参数的类型是：{type(args)}，内容是:{args}\u0026#34;) user_info(1, 2, 3, \u0026#39;小明\u0026#39;, \u0026#39;男孩\u0026#39;) 类型二：关键字传递\n参数是“键=值”形式的情况下, 所有的“键=值”都会被kwargs接受, 同时会根据“键=值”组成字典.\n1 2 3 4 5 6 7 8 # 不定长 - 关键字不定长, * *号 ，可理解为字典的不定长 def user_info( * *kwargs): print(f\u0026#34;args参数的类型是：{type(kwargs)}，内容是:{kwargs}\u0026#34;) user_info(name=\u0026#39;小王\u0026#39;, age=11, gender=\u0026#39;男孩\u0026#39;) 4.4. 缺省参数 缺省参数也叫默认参数，用于定义函数，为参数提供默认值，调用函数时可不传该默认参数的值（注意：所有位置参数必须出现在默认参数前，包括函数定义和调用）.\n函数调用时，如果为缺省参数传值则修改默认参数值, 否则使用这个默认值\n1 2 3 4 5 6 7 8 def user_info(name, age, gender=\u0026#39;女\u0026#39;): print(f\u0026#34;姓名是:{name}, 年龄是:{age}, 性别是:{gender}\u0026#34;) user_info(\u0026#39;小天\u0026#39;, 13) user_info(\u0026#39;小天\u0026#39;, 13, \u0026#39;男\u0026#39;) 5.global关键字 如下所示， testB 函数内部的 num = 200 是定义了一个局部变量，并没有真正修改到全局变量num的值，所以最好的print语句结果为200\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 num = 200 def test_a(): print(f\u0026#34;test_a: {num}\u0026#34;) def test_b(): num = 500 # 局部变量 print(f\u0026#34;test_b: {num}\u0026#34;) test_a() # 结果为200 test_b() # 结果为500 print(num) #结果为200 如果想修改全局变量num的值，可以用global关键字来声明 num = 200 def test_a(): print(f\u0026#34;test_a: {num}\u0026#34;) def test_b(): global num # 设置内部定义的变量为全局变量 num = 500 print(f\u0026#34;test_b: {num}\u0026#34;) test_a() #结果为200 test_b() #结果为500 print(num) #结果为500 6.匿名函数 6.1 函数作为参数传递\n定义一个函数，接收另一个函数作为传入参数 1 2 3 4 5 6 7 8 def test_func(compute): result = compute(1, 2) # 确定compute是函数 print(f\u0026#34;compute参数的类型是:{type(compute)}\u0026#34;) print(f\u0026#34;计算结果：{result}\u0026#34;) 定义一个函数，准备作为参数传入另一个函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def compute(x, y): return x + y # 调用，并传入函数 test_func(compute) 6.2 lambda匿名函数 定义语法 lambda 传入参数 : 函数体 # 定义一个函数，接受其它函数输入 def test_func(compute): result = compute(1, 2) print(f\u0026#34;结果是:{result}\u0026#34;) # 通过lambda匿名函数的形式，将匿名函数作为参数传入 def add(x, y): return x + y test_func(add) test_func(lambda x, y: x + y) 五、数据容器 5.1 list列表 5.1.1 列表的定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 普通列表 my_list = [\u0026#34;我是字符串\u0026#34;, 666, True] # 嵌套列表 my_list = [ [1, 2, 3], [4, 5, 6]] #空列表 my_list = [] my_list = list() 5.1.2 列表的下标索引\n用下标进行元素索引\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 my_list = [\u0026#34;Tom\u0026#34;, \u0026#34;Lily\u0026#34;, \u0026#34;Rose\u0026#34;] # 列表[下标索引], 从前向后从0开始，每次+1， 从后向前从-1开始，每次-1 print(my_list[0]) print(my_list[1]) print(my_list[2]) # 取出嵌套列表的元素 my_list = [ [1, 2, 3], [4, 5, 6]] print(my_list[1][1]) 5.1.3 list常用操作\n编号 使用方式 作用 1 列表.append(元素) 向列表中追加一个元素 2 列表.extend(容器) 将数据容器的内容依次取出，追加到列表尾部 3 列表.insert(下标, 元素) 在指定下标处，插入指定的元素 4 del 列表[下标] 删除列表指定下标元素 5 列表.pop(下标) 删除列表指定下标元素 6 列表.remove(元素) 从前向后，删除此元素第一个匹配项 7 列表.clear() 清空列表 8 列表.count(元素) 统计此元素在列表中出现的次数 9 列表.index(元素) 查找指定元素在列表的下标 找不到报错ValueError 10 len(列表) 统计容器内有多少元素 5.1.4 列表的特点\n可以容纳多个元素（上限为2 * *63-1、9223372036854775807个） 可以容纳不同类型的元素（混装） 数据是有序存储的（有下标序号） 允许重复数据存在 可以修改（增加或删除元素等） 5.2 tuple元祖 元组一旦定义完成，就不可修改；当元组只有一个数据，这个数据后面要添加逗号 如 ： my_tuple = (\u0026lsquo;hello\u0026rsquo;, )\n元组可以如下三种定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 t1 = (1, \u0026#34;Hello\u0026#34;, True) t2 = () t3 = tuple() # 定义单个元素的元素 t4 = (\u0026#34;hello\u0026#34;, ) # 元组的嵌套 t5 = ( (1, 2, 3), (4, 5, 6) ) # 下标索引去取出内容 num = t5[1][2] # 元组的操作：index查找方法 t6 = (\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;Python\u0026#34;) index = t6.index(\u0026#34;茂佳程序员\u0026#34;) print(f\u0026#34;在元组t6中查找茂佳程序员，的下标是：{index}\u0026#34;) # 元组的操作：count统计方法 t7 = (\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;Python\u0026#34;) num = t7.count(\u0026#34;茂佳程序员\u0026#34;) print(f\u0026#34;在元组t7中统计茂佳程序员的数量有：{num}个\u0026#34;) # 元组的操作：len函数统计元组元素数量 t8 = (\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;Python\u0026#34;) num = len(t8) print(f\u0026#34;t8元组中的元素有：{num}个\u0026#34;) # 元组的遍历：while index = 0 while index \u0026lt; len(t8): print(f\u0026#34;元组的元素有：{t8[index]}\u0026#34;) # 至关重要 index += 1 # 元组的遍历：for for element in t8: print(f\u0026#34;2元组的元素有：{element}\u0026#34;) # 定义一个元组,里面有list元素，list元素是可以修改的 t9 = (1, 2, [\u0026#34;itmoka\u0026#34;, \u0026#34;itcast\u0026#34;]) print(f\u0026#34;t9的内容是：{t9}\u0026#34;) t9[2][0] = \u0026#34;茂佳程序员\u0026#34; t9[2][1] = \u0026#34;茂佳科技\u0026#34; print(f\u0026#34;t9的内容是：{t9}\u0026#34;) 元祖操作\n编号 方法 作用 1 index() 查找某个数据，如果数据存在返回对应的下标，否则报错 2 count() 统计某个数据在当前元组出现的次数 3 len(元组) 统计元组内的元素个数 元祖的特点\n可以容纳多个数据 可以容纳不同类型的数据（混装） 数据是有序存储的（下标索引） 允许重复数据存在 不可以修改（增加或删除元素等） 支持for循环 5.3 str 字符串 5.3.1 字符串操作\n编号 操作 说明 1 字符串[下标] 根据下标索引取出特定位置字符 2 字符串.index(字符串） 查找给定字符的第一个匹配项的下标 3 字符串.replace(字符串1, 字符串2) 将字符串内的全部字符串1，替换为字符串2 不会修改原字符串，而是得到一个新的 4 字符串.split(字符串) 按照给定字符串，对字符串进行分隔 不会修改原字符串，而是得到一个新的列表 5 字符串.strip() 字符串.strip(字符串) 移除首尾的空格和换行符或指定字符串 6 字符串.count(字符串) 统计字符串内某字符串的出现次数 7 len(字符串) 统计字符串的字符个数 5.3.2 示例代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 my_str = \u0026#34;itmoka and itcast\u0026#34; # 通过下标索引取值 value = my_str[2] value2 = my_str[-16] print(f\u0026#34;从字符串{my_str}取下标为2的元素，值是：{value},取下标为-16的元素。值是：{value2}\u0026#34;) # 不允许修改 # my_str[2] = \u0026#34;H\u0026#34; # index方法 value = my_str.index(\u0026#34;and\u0026#34;) print(f\u0026#34;在字符串{my_str}中查找and，其起始下标是：{value}\u0026#34;) # replace方法，得到的是个新的字符串，老的字符串还是没变的 new_my_str = my_str.replace(\u0026#34;it\u0026#34;, \u0026#34;程序\u0026#34;) print(f\u0026#34;将字符串{my_str}，进行替换后得到：{new_my_str}\u0026#34;) # split方法 my_str = \u0026#34;hello python itmoka itcast\u0026#34; my_str_list = my_str.split(\u0026#34; \u0026#34;) print(f\u0026#34;将字符串{my_str}进行split切分后得到：{my_str_list}, 类型是：{type(my_str_list)}\u0026#34;) # strip方法 my_str = \u0026#34; itmoka and itcast \u0026#34; new_my_str = my_str.strip() # 不传入参数，去除首尾空格 print(f\u0026#34;字符串{my_str}被strip后，结果：{new_my_str}\u0026#34;) my_str = \u0026#34;12itmoka and itcast21\u0026#34; new_my_str = my_str.strip(\u0026#34;12\u0026#34;) print(f\u0026#34;字符串{my_str}被strip(\u0026#39;12\u0026#39;)后，结果：{new_my_str}\u0026#34;) # 统计字符串中某字符串的出现次数, count my_str = \u0026#34;itmoka and itcast\u0026#34; count = my_str.count(\u0026#34;it\u0026#34;) print(f\u0026#34;字符串{my_str}中it出现的次数是：{count}\u0026#34;) # 统计字符串的长度, len() num = len(my_str) print(f\u0026#34;字符串{my_str}的长度是：{num}\u0026#34;) 5.3.3 字符串的特点\n只可以存储字符串 长度任意（取决于内存大小） 支持下标索引 允许重复字符串存在 不可以修改（增加或删除元素等） 支持for循环 5.4 set 集合 5.4.1 集合操作\n编号 操作 说明 1 集合.add(元素) 集合内添加一个元素 2 集合.remove(元素) 移除集合内指定的元素 3 集合.pop() 从集合中随机取出一个元素 4 集合.clear() 将集合清空 5 集合1.difference(集合2) 得到一个新集合，内含2个集合的差集 原有的2个集合内容不变 6 集合1.difference_update(集合2) 在集合1中，删除集合2中存在的元素 集合1被修改，集合2不变 7 集合1.union(集合2) 得到1个新集合，内含2个集合的全部元素 原有的2个集合内容不变 8 len(集合) 得到一个整数，记录了集合的元素数量 5.4.2 示例代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 # 定义集合 my_set = {\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;itmoka\u0026#34;, \u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;itmoka\u0026#34;, \u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;itmoka\u0026#34;} my_set_empty = set() # 定义空集合 print(f\u0026#34;my_set的内容是：{my_set}, 类型是：{type(my_set)}\u0026#34;) print(f\u0026#34;my_set_empty的内容是：{my_set_empty}, 类型是：{type(my_set_empty)}\u0026#34;) # 添加新元素 my_set.add(\u0026#34;Python\u0026#34;) my_set.add(\u0026#34;茂佳科技\u0026#34;) # print(f\u0026#34;my_set添加元素后结果是：{my_set}\u0026#34;) # 移除元素 my_set.remove(\u0026#34;茂佳程序员\u0026#34;) print(f\u0026#34;my_set移除茂佳程序员后，结果是：{my_set}\u0026#34;) # 随机取出一个元素 my_set = {\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;itmoka\u0026#34;} element = my_set.pop() print(f\u0026#34;集合被取出元素是：{element}, 取出元素后：{my_set}\u0026#34;) # 清空集合, clear my_set.clear() print(f\u0026#34;集合被清空啦，结果是：{my_set}\u0026#34;) # 取2个集合的差集 set1 = {1, 2, 3} set2 = {1, 5, 6} set3 = set1.difference(set2) print(f\u0026#34;取出差集后的结果是：{set3}\u0026#34;) print(f\u0026#34;取差集后，原有set1的内容：{set1}\u0026#34;) print(f\u0026#34;取差集后，原有set2的内容：{set2}\u0026#34;) # 消除2个集合的差集 set1 = {1, 2, 3} set2 = {1, 5, 6} set1.difference_update(set2) print(f\u0026#34;消除差集后，集合1结果：{set1}\u0026#34;) print(f\u0026#34;消除差集后，集合2结果：{set2}\u0026#34;) # 2个集合合并为1个 set1 = {1, 2, 3} set2 = {1, 5, 6} set3 = set1.union(set2) print(f\u0026#34;2集合合并结果：{set3}\u0026#34;) print(f\u0026#34;合并后集合1：{set1}\u0026#34;) print(f\u0026#34;合并后集合2：{set2}\u0026#34;) # 统计集合元素数量len() set1 = {1, 2, 3, 4, 5, 1, 2, 3, 4, 5} num = len(set1) print(f\u0026#34;集合内的元素数量有：{num}个\u0026#34;) # 集合的遍历 # 集合不支持下标索引，不能用while循环 # 可以用for循环 set1 = {1, 2, 3, 4, 5,10,7 } for element in set1: print(f\u0026#34;集合的元素有：{element}\u0026#34;) 5.4.3 集合的特点\n可以容纳多个数据 可以容纳不同类型的数据（混装） 数据是无序存储的（不支持下标索引） 不允许重复数据存在 可以修改（增加或删除元素等） 支持for循环 5.5 dict 字典 5.5.1 字典操作\n编号 操作 说明 1 字典[Key] 获取指定Key对应的Value值 2 字典[Key] = Value 添加或更新键值对 3 字典.pop(Key) 取出Key对应的Value并在字典内删除此Key的键值对 4 字典.clear() 清空字典 5 字典.keys() 获取字典的全部Key，可用于for循环遍历字典 6 len(字典) 计算字典内的元素数量 5.5.2 示例代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 ① 定义字典 # 定义字典 my_dict1 = {\u0026#34;王力鸿\u0026#34;: 99, \u0026#34;周杰轮\u0026#34;: 88, \u0026#34;林俊节\u0026#34;: 77} # 定义空字典 my_dict2 = {} my_dict3 = dict() print(f\u0026#34;字典1的内容是：{my_dict1}, 类型：{type(my_dict1)}\u0026#34;) print(f\u0026#34;字典2的内容是：{my_dict2}, 类型：{type(my_dict2)}\u0026#34;) print(f\u0026#34;字典3的内容是：{my_dict3}, 类型：{type(my_dict3)}\u0026#34;) # 定义重复Key的字典 my_dict1 = {\u0026#34;王力鸿\u0026#34;: 99, \u0026#34;王力鸿\u0026#34;: 88, \u0026#34;林俊节\u0026#34;: 77} print(f\u0026#34;重复key的字典的内容是：{my_dict1}\u0026#34;) # 从字典中基于Key获取Value my_dict1 = {\u0026#34;王力鸿\u0026#34;: 99, \u0026#34;周杰轮\u0026#34;: 88, \u0026#34;林俊节\u0026#34;: 77} score = my_dict1[\u0026#34;王力鸿\u0026#34;] print(f\u0026#34;王力鸿的考试分数是：{score}\u0026#34;) score = my_dict1[\u0026#34;周杰轮\u0026#34;] print(f\u0026#34;周杰轮的考试分数是：{score}\u0026#34;) # 定义嵌套字典 stu_score_dict = { \u0026#34;王力鸿\u0026#34;: { \u0026#34;语文\u0026#34;: 77, \u0026#34;数学\u0026#34;: 66, \u0026#34;英语\u0026#34;: 33 }, \u0026#34;周杰轮\u0026#34;: { \u0026#34;语文\u0026#34;: 88, \u0026#34;数学\u0026#34;: 86, \u0026#34;英语\u0026#34;: 55 }, \u0026#34;林俊节\u0026#34;: { \u0026#34;语文\u0026#34;: 99, \u0026#34;数学\u0026#34;: 96, \u0026#34;英语\u0026#34;: 66 } } print(f\u0026#34;学生的考试信息是：{stu_score_dict}\u0026#34;) # 从嵌套字典中获取数据 # 看一下周杰轮的语文信息 score = stu_score_dict[\u0026#34;周杰轮\u0026#34;][\u0026#34;语文\u0026#34;] print(f\u0026#34;周杰轮的语文分数是：{score}\u0026#34;) score = stu_score_dict[\u0026#34;林俊节\u0026#34;][\u0026#34;英语\u0026#34;] print(f\u0026#34;林俊节的英语分数是：{score}\u0026#34;) ②字典操作 my_dict = {\u0026#34;周杰轮\u0026#34;: 99, \u0026#34;林俊节\u0026#34;: 88, \u0026#34;张学油\u0026#34;: 77} # 新增元素 my_dict[\u0026#34;张信哲\u0026#34;] = 66 print(f\u0026#34;字典经过新增元素后，结果：{my_dict}\u0026#34;) # 更新元素 my_dict[\u0026#34;周杰轮\u0026#34;] = 33 print(f\u0026#34;字典经过更新后，结果：{my_dict}\u0026#34;) # 删除元素 score = my_dict.pop(\u0026#34;周杰轮\u0026#34;) print(f\u0026#34;字典中被移除了一个元素，结果：{my_dict}, 周杰轮的考试分数是：{score}\u0026#34;) # 清空元素, clear my_dict.clear() print(f\u0026#34;字典被清空了，内容是：{my_dict}\u0026#34;) # 获取全部的key my_dict = {\u0026#34;周杰轮\u0026#34;: 99, \u0026#34;林俊节\u0026#34;: 88, \u0026#34;张学油\u0026#34;: 77} keys = my_dict.keys() print(f\u0026#34;字典的全部keys是：{keys}\u0026#34;) # 遍历字典 # 方式1：通过获取到全部的key来完成遍历 for key in keys: print(f\u0026#34;字典的key是:{key}\u0026#34;) print(f\u0026#34;字典的value是：{my_dict[key]}\u0026#34;) # 方式2：直接对字典进行for循环，每一次循环都是直接得到key for key in my_dict: print(f\u0026#34;2字典的key是:{key}\u0026#34;) print(f\u0026#34;2字典的value是：{my_dict[key]}\u0026#34;) # 统计字典内的元素数量, len()函数 num = len(my_dict) print(f\u0026#34;字典中的元素数量有：{num}个\u0026#34;) 5.5.3 字典的特点\n可以容纳多个数据 可以容纳不同类型的数据 每一份数据是KeyValue键值对 可以通过Key获取到Value，Key不可重复（重复会覆盖） 不支持下标索引 可以修改（增加或删除更新元素等） 支持for循环，不支持while循环 5.6 数据容器（序列）的切片 5.6.1 什么是序列\n序列是指：内容连续、有序，可使用下标索引的一类数据容器\n列表、元组、字符串，均可以可以视为序列。\n5.6.2 序列切片\n序列支持切片，即：列表、元组、字符串，均支持进行切片操作\n切片：从一个序列中，取出一个子序列\n语法：序列[起始下标:结束下标:步长] 表示从序列中，从指定位置开始，依次取出元素，到指定位置结束，得到一个新序列：\n起始下标表示从何处开始，可以留空，留空视作从头开始 结束下标（不含）表示何处结束，可以留空，留空视作截取到结尾 步长表示，依次取元素的间隔 步长1表示，一个个取元素 步长2表示，每次跳过1个元素取 步长N表示，每次跳过N-1个元素取 步长为负数表示，反向取（注意，起始下标和结束下标也要反向标记） 注意，此操作不会影响序列本身，而是会得到一个新的序列（列表、元组、字符串）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # 对list进行切片，从1开始，4结束，步长1 my_list = [0, 1, 2, 3, 4, 5, 6] result1 = my_list[1:4] # 步长默认是1，所以可以省略不写 print(f\u0026#34;结果1：{result1}\u0026#34;) # 对tuple进行切片，从头开始，到最后结束，步长1 my_tuple = (0, 1, 2, 3, 4, 5, 6) result2 = my_tuple[:] # 起始和结束不写表示从头到尾，步长为1可以省略 print(f\u0026#34;结果2：{result2}\u0026#34;) # 对str进行切片，从头开始，到最后结束，步长2 my_str = \u0026#34;01234567\u0026#34; result3 = my_str[::2] print(f\u0026#34;结果3：{result3}\u0026#34;) # 对str进行切片，从头开始，到最后结束，步长-1 my_str = \u0026#34;01234567\u0026#34; result4 = my_str[::-1] # 等同于将序列反转了 print(f\u0026#34;结果4：{result4}\u0026#34;) # 对列表进行切片，从3开始，到1结束，步长-1 my_list = [0, 1, 2, 3, 4, 5, 6] result5 = my_list[3:1:-1] print(f\u0026#34;结果5：{result5}\u0026#34;) # 对元组进行切片，从头开始，到尾结束，步长-2 my_tuple = (0, 1, 2, 3, 4, 5, 6) result6 = my_tuple[::-2] print(f\u0026#34;结果6：{result6}\u0026#34;) 5.7 不同容器对比 列表 元组 字符串 集合 字典 元素数量 支持多个 支持多个 支持多个 支持多个 支持多个 元素类型 任意 任意 仅字符 任意 Key：Value Key：除字典外任意类型 Value：任意类型 下标索引 支持 支持 支持 不支持 不支持 重复元素 支持 支持 支持 不支持 不支持 可修改性 支持 不支持 不支持 支持 支持 数据有序 是 是 是 否 否 使用场景 可修改、可重复的一批数据记录场景 不可修改、可重复的一批数据记录场景 一串字符的记录场景 不可重复的数据记录场景 以Key检索Value的数据记录场景 是否支持下标索引 支持：列表、元组、字符串 - 序列类型 不支持：集合、字典 - 非序列类型 2 . 是否支持重复元素：\n支持：列表、元组、字符串 - 序列类型 不支持：集合、字典 - 非序列类型 3 . 是否可以修改\n支持：列表、集合、字典 不支持：元组、字符串 容器通用功能\n功能 描述 通用for循环 遍历容器（字典是遍历key） max 容器内最大元素 min() 容器内最小元素 len() 容器元素个数 list() 转换为列表 tuple() 转换为元组 str() 转换为字符串 set() 转换为集合 sorted(序列, [reverse=True]) 排序，reverse=True表示降序 得到一个排好序的列表 六. 异常 基本语法\n基本语法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 try: print(name) except NameError as e: print(\u0026#39;name变量名称未定义错误\u0026#39;) # 完整语法 try: f = open(\u0026#34;D:/123.txt\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;UTF-8\u0026#34;) except Exception as e: print(\u0026#34;出现异常了\u0026#34;) f = open(\u0026#34;D:/123.txt\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;UTF-8\u0026#34;) # else表示的是如果没有异常要执行的代码。 else: print(\u0026#34;好高兴，没有异常。\u0026#34;) # finally表示的是无论是否异常都要执行的代码 finally: print(\u0026#34;我是finally，有没有异常我都要执行\u0026#34;) f.close() 七. Python模块和包 7.1 什么是模块\nPython 模块(Module)，是一个 Python 文件，以 .py 结尾. 模块能定义函数，类和变量，模块里也能包含可执行的代码.\n7.2 模块的作用**:**\npython中有很多各种不同的模块, 每一个模块都可以帮助我们快速的实现一些功能, 比如实现和时间相关的功能就可以使用time模块\n我们可以认为一个模块就是一个工具包, 每一个工具包中都有各种不同的工具供我们使用进而实现各种不同的功能.\n7.3 模块导入\n模块在使用前需要先导入 导入的语法如下:\n常用的组合形式如：\nimport 模块名 from 模块名 import 类、变量、方法等 from 模块名 import * import 模块名 as 别名 from 模块名 import 功能名 as 别名 7.4 __all__变量\n如果一个模块文件中有 __all__变量，当使用 from xxx import * 导入时，只能导入这个列表中的元素\n7.5 什么是包\n从物理上看，包就是一个文件夹，在该文件夹下包含了一个 init.py 文件，该文件夹可用于包含多个模块文件\n**包的作用：**当我们的模块文件越来越多时,包可以帮助我们管理这些模块, 包的作用就是包含多个模块，但包的本质依然是模块\n导入包的语法\nimport 包名.模块名\n包名.模块名.目标\n7.6 python常用包\n科学计算中常用的:numpy包\n数据分析中常用的:pandas包\n大数据计算中常用的:pyspark、apache-flink包\n图形可视化常用的:matplotlib、pyecharts\n人工智能常用的:tensorflow\n","date":"2024-12-27T00:36:30+08:00","permalink":"https://h-yx-blog.github.io/p/python%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","title":"Python基础语法"},{"content":"正文测试 而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用 思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片 1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"2020-09-09T00:00:00Z","image":"https://h-yx-blog.github.io/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu_2307260c751d0e0b.jpg","permalink":"https://h-yx-blog.github.io/p/test-chinese/","title":"Chinese Test"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"https://h-yx-blog.github.io/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu_e95a4276bf860a84.jpg","permalink":"https://h-yx-blog.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2019-03-09T00:00:00Z","image":"https://h-yx-blog.github.io/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu_c1ca39d792aee4ab.jpg","permalink":"https://h-yx-blog.github.io/p/placeholder-text/","title":"Placeholder Text"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$","date":"2019-03-08T00:00:00Z","permalink":"https://h-yx-blog.github.io/p/math-typesetting/","title":"Math Typesetting"},{"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3 .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","date":"2019-03-05T00:00:00Z","image":"https://h-yx-blog.github.io/p/emoji-support/the-creative-exchange-d2zvqp3fpro-unsplash_hu_27b8954607cdb515.jpg","permalink":"https://h-yx-blog.github.io/p/emoji-support/","title":"Emoji Support"}]