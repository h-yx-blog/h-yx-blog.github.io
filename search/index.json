[{"content":"背景 controller 的接口多处使用 @RequestHeader 从请求头中获取 token信息，然后在代码中进行解析\n弊端：\n代码冗余 如果User信息实体发生变化，需要修改多处代码 解决措施 利用自定义的 HandlerMethodArgumentResolver获取系统的用户信息，替代 @RequestHeader\n作用：\n如果我们想要的信息不完全是来自消息体等地方，比如说一部分是消息体，一部分是消息头，甚至一部分从配置中获取。这个时候我们又希望在方法入参进来就将这些信息组装好。\n或者说是需要从消息头里面去进行token解析认证的时候。\n① 顶层接口说明\nHandlerMethodArgumentResolver接口定义了 两个方法\n1 2 3 4 boolean supportsParameter(MethodParameter parameter); @Nullable Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception; boolean supportsParameter(MethodParameter parameter)：判断解析器是否支持给定的方法参数，当返回true时则会进行解析 Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception：解析给定的方法参数，并返回实际的参数值。 ②实现步骤\n创建一个实现HandlerMethodArgumentResolver接口的类，并重写方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Component public class UserLoginInfoArgumentResolver implements HandlerMethodArgumentResolver { private final AiInternalUserService aiInternalUserService; public UserLoginInfoArgumentResolver(AiInternalUserService aiInternalUserService) { this.aiInternalUserService = aiInternalUserService; } @Override public boolean supportsParameter(MethodParameter parameter) { //处理UserLoginInfo类型的参数 return parameter.getParameterType().equals(UserLoginInfo.class); } @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception { // 从请求头中获取 Authorization String loginToken = webRequest.getHeader(\u0026#34;Authorization\u0026#34;); if (loginToken == null || loginToken.isEmpty()) { throw new IllegalArgumentException(\u0026#34;Authorization header is missing\u0026#34;); } // 调用服务获取 UserLoginInfo 对象 return aiInternalUserService.getUserLoginInfoByLoginToken(loginToken); } } 注册解析器，将解析器注册到WebMvcConfigurer\n过实现WebMvcConfigurer接口，并重写addArgumentResolvers方法，在该方法中添加自定义解析器。\n1 2 3 4 5 6 7 8 9 10 11 12 @Configuration public class InterceptorConfig implements WebMvcConfigurer { private final UserLoginInfoArgumentResolver userLoginInfoArgumentResolver; public InterceptorConfig(UserLoginInfoArgumentResolver userLoginInfoArgumentResolver) { this.userLoginInfoArgumentResolver = userLoginInfoArgumentResolver; } @Override public void addArgumentResolvers(List\u0026lt;HandlerMethodArgumentResolver\u0026gt; resolvers) { resolvers.add(userLoginInfoArgumentResolver); } } 其他思路 设置登录拦截器，解析token后把信息放入ThreadLocal\n","date":"2025-04-03T16:42:15+08:00","permalink":"https://h-yx-blog.github.io/p/springboot%E8%87%AA%E5%AE%9A%E4%B9%89handlermethodargumentresolver%E8%A7%A3%E6%9E%90%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0/","title":"SpringBoot自定义HandlerMethodArgumentResolver解析方法参数"},{"content":"一.介绍 Janus 是一种新颖的自回归框架，它统一了多模态理解和生成。它通过将视觉编码解耦为单独的路径来解决以前方法的局限性，同时仍然使用单一、统一的 transformer 架构进行处理。解耦不仅缓解了视觉编码器在理解和生成中的角色冲突，还增强了框架的灵活性。Janus 超越了以前的统一模型，并达到或超过特定于任务的模型的性能。Janus 的简单性、高度灵活性和有效性使其成为下一代统一多模态模型的有力候选者。\n二.关键技术 Janus-Pro 是 DeepSeek 的 Janus 多模态模型的高级版本，设计用于出色地理解和生成涉及文本和图像的内容，可以同时进行多模态理解和图像生成任务。\nJanus-Pro 仍然保持了 Janus 首创的解耦视觉编码这一核心架构原则。这种将不同任务的视觉处理方法分离开来的做法，对于提高模型的整体性能至关重要。\n优化训练策略 ：Janus-Pro 采用更有效的训练策略，注重更好地利用数据和资源。 扩展的训练数据集：该模型结合了真实数据源和合成数据，增强了其稳健性和适应性。 更大的模型规模：Janus-Pro 的参数规模从 10 亿 (1B) 到 70 亿 (7B)，性能和稳定性都得到了提高，尤其是在文本到图像生成和多模态理解等任务中。 三.创新 核心创新是将多模态理解和生成，使用两种不同的任务解耦编码器来完成理解和生成任务。让这两种任务可以在同一模型中高效完成。\n解耦视觉编码器： Janus-Pro 架构的核心是解耦视觉编码的理念，即根据手头的任务使用不同的编码方法处理图像。 这种多任务处理的效果，主要源于 Janus 系列针对不同任务使用的两个视觉编码器：\n理解编码器：用于提取图像中的语义特征，以便进行图像理解任务（如图像问答、视觉分类等）。\n生成编码器：将图像转换为离散表示（例如，使用 VQ 编码器），用于文本到图像生成任务。\n文生图对比\n特性 Janus Pro Flux 训练成本 相对较低的预算 未明确说明，可能更高 社区支持 开源，在 Hugging Face 上可用 拥有强大的社区支持和优化 性能 擅长指令执行，多模态任务 高质量图像且生成速度快 图像分辨率 输入：384 x 384 像素，输出：最高 768 x 768 可生成高达 1024 x 1024 像素 主要关注点 多模态任务，文本-图像交互 高质量图像生成 四.评估结果 ①在 GenEval 中，Janus-Pro-7B 的得分为 0.80，超过了 DALL-E 3 和 Stable Diffusion 3 Medium 等模型。\n②在 DPG-Bench 上，Janus-Pro 获得了 84.19 分，再次超过了 DALL-E 3 和 Stable Diffusion 3 Medium 等竞争对手。 五.局限性 分辨率限制：该模型的输入分辨率上限为 384x384，这可能会妨碍需要精细细节的任务（如光学字符识别 (OCR)）的性能。\n图像质量：同样的分辨率限制和 VQ tokenizer 使用的压缩技术会导致图像缺乏精细度，尤其是面部小区域。\n六. 本地部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #创建conda环境 conda create -n deepseek-janus python=3.10 -y #激活conda环境 conda activate deepseek-janus #克隆Janus项目 git clone https://github.com/deepseek-ai/Janus.git #进入janus目录 cd Janus #安装Janus依赖 pip install -e . #安装Gradio （UI界面） pip install gradio #启动 （代码中默认是Janus pro 7B的模型，可以手动修改） python demo/app_januspro.py 看到以下界面即已经成功部署 测试结果 ①文生图测试如下 文生图功能似乎对中文理解似乎不行，只能使用英文 （使用中文提问时，无论怎么提问，总是生成如下图片） 英文提问如下 ②图片理解测试如下 ","date":"2025-02-09T10:08:24+08:00","permalink":"https://h-yx-blog.github.io/p/deepseek-janus-pro/","title":"DeepSeek Janus Pro"},{"content":"一. 介绍 1.1 DeepSeek-R1 通过强化学习（Reinforcement Learning：简称RL）提升大型语言模型（LLM）的推理能力。这项研究在如何仅依靠强化学习而不是过分依赖监督式微调的情况下，增强LLM解决复杂问题的能力上，取得了重要进展。\n1.2 DeepSeek-R1系列包含两大核心成员：\n①DeepSeek-R1-Zero\n参数规模：6710亿（MoE架构，每个token激活370亿参数） 训练特点：完全基于强化学习的端到端训练 核心优势：展现出自我验证、长链推理等涌现能力 典型表现：AIME 2024基准测试71%准确率 ②DeepSeek-R1\n参数规模：与Zero版保持相同体量 训练创新：多阶段混合训练策略 核心改进：监督微调冷启动 + 强化学习优化 性能提升：AIME 2024准确率提升至79.8% 1.3 对比R1 Zero和R1\n① R1 Zero和R1的主要区别\nDeepSeek-R1-Zero是团队初步尝试仅用纯强化学习而不进行任何监督式微调的实验。他们从基础模型出发，直接运用强化学习，让模型通过不断试错来发展其推理能力。这种方法虽然取得了较好的成果（在 AIME 2024 测试中达到了 71% 的准确率），但在可读性和语言连贯性上存在明显不足。该模型拥有 6710 亿个参数，使用了混合专家（MoE）架构，其中每个词触发的参数约为 370 亿。此模型展现了一些新兴的推理行为，例如自我核查、反思和长链推理（CoT）。\n与之对比，DeepSeek-R1采用了更复杂的多阶段训练方法。它不仅仅采用强化学习，而是先在一小组精心挑选的示例（称为“冷启动数据”）上进行监督式微调，然后再应用强化学习。这种方法克服了 DeepSeek-R1-Zero 的局限，同时取得了更优的表现。这个模型同样维持了 6710 亿的参数数量，但在回答的可读性和条理性上有所提高。\n② R1 Zero和R1的共同点 DeepSeek-R1-Zero 和 DeepSeek-R1 基于 DeepSeek-V3-Base 进行训练。\nModel Total Params Activated Params Context Length DeepSeek-R1-Zero 671B 37B 128K DeepSeek-R1 671B 37B 128K 训练方法概述：\n强化学习 ：不同于传统依赖监督学习的模型，DeepSeek-R1 大规模采用了强化学习。此训练方法利用群体相对策略优化（GRPO），重点提升精度和格式化奖励，以增强推理能力，无需依赖大量标注数据。 蒸馏技术 ：为普及高效能模型，DeepSeek 也推出了 R1 的蒸馏版本，参数规模从15亿到700亿不等。这些模型采用了如Qwen和Llama等架构，表明即使是较小和更高效的模型也能包含复杂的推理能力。蒸馏过程通过使用 DeepSeek-R1 生成的合成推理数据对这些小型模型进行微调，以较低的计算成本保持高性能。 二.优点 性能与 OpenAI-o1 相当 完全开源的模型和技术报告 MIT 许可：自由蒸馏和商业化！ 从 DeepSeek-R1 提炼出来，6 个小模型完全开源（32B \u0026amp; 70B 型号与 OpenAI-o1-mini 相当） 三. 技术亮点 以最少的标记数据显著提高性能 组相对策略优化（GRPO）：兼顾格式与准确性的奖励机制 知识蒸馏技术：支持从1.5B到70B的参数规模适配 多架构兼容：基于Qwen/Llama等主流架构的轻量化版本 四.API 成本优势：缓存命中时输入token成本$0.14/M，较同类产品降低30%\n模型 上下文长度 最大输出长度 输入价格（缓存命中） 输入价格（缓存未命中） 输出价格 deepseek-reasoner（即deppseek R1） 64K 8K 0.14 美元/百万tokens 0.55 美元/百万tokens 2.19 美元/百万tokens 五.本地部署 推荐配置：NVIDIA GPU（推荐使用具有大量视频内存（VRAM）的 GPU，如：RTX 3090或更高） + 32GB内存 + 50GB存储空间 最低配置：CPU（支持AVX2指令集） + 8GB内存 + 12GB存储 （能耗注意：32B+ 模型需高功率电源（1000W+）和散热系统。） 建议在使用 DeepSeek-R1 系列模型时遵循以下配置 ①将temperature 设置在 0.5-0.7 （推荐 0.6） 的范围内，以防止无休止的重复或不连贯的输出。\n②避免添加系统提示符;所有说明都应包含在用户提示符中。\n③对于数学问题，建议在提示中包含一条指令，例如：“请逐步推理，并将您的最终答案放在 \\boxed{} 中。\n④在评估模型性能时，建议进行多次测试并平均结果。\n六. DeepSeek-R1评估结果 DeepSeek-R1各方面的评估结果如下\nDeepSeek-R1在数学、代码和推理任务，性能可与 OpenAI-o1 相媲美 蒸馏小模型32B 和 70B 模型在多项能力上实现了对标 OpenAI o1-mini 的效果。 {\u0026ldquo;code\u0026rdquo;:220000,\u0026ldquo;data\u0026rdquo;:{\u0026ldquo;successData\u0026rdquo;:[{\u0026ldquo;sourceText\u0026rdquo;:\u0026ldquo;Channel coded. (Channel scrambled \\ Content scrambled).\\n Please check if the CI + module and the smart card have been inserted correctly.\u0026rdquo;,\u0026ldquo;targetText\u0026rdquo;:\u0026ldquo;Canale codificato. (Canale criptato \\ Contenuto criptato).\\n Si prega di verificare se il modulo CI+ e la smart card sono stati inseriti correttamente.\u0026rdquo;},{\u0026ldquo;sourceText\u0026rdquo;:\u0026ldquo;The input doesn\\\u0026rsquo;t support auto-scan\u0026rdquo;,\u0026ldquo;targetText\u0026rdquo;:\u0026ldquo;L\u0026rsquo;ingresso non supporta la scansione automatica\u0026rdquo;},{\u0026ldquo;sourceText\u0026rdquo;:\u0026quot;-\u0026quot;,\u0026ldquo;targetText\u0026rdquo;:\u0026quot;-\u0026quot;},{\u0026ldquo;sourceText\u0026rdquo;:\u0026quot;.\u0026quot;,\u0026ldquo;targetText\u0026rdquo;:\u0026quot;.\u0026quot;}],\u0026ldquo;language\u0026rdquo;:\u0026ldquo;Italian\u0026rdquo;,\u0026ldquo;failedData\u0026rdquo;:[]},\u0026ldquo;message\u0026rdquo;:\u0026ldquo;success\u0026rdquo;}七.局限性及未来发展 若干改进领域：\n模型在处理需要特定输出格式的任务时偶尔会遇到困难。 软件工程相关任务的性能还有提升空间。 在多语言环境下，语言混合带来了挑战。 少样本提示通常会导致性能下降。 未来的研究将致力于解决这些问题，并拓展模型在函数调用、多轮交互和复杂角色扮演场景等领域的能力。 ","date":"2025-02-09T10:08:24+08:00","permalink":"https://h-yx-blog.github.io/p/deepseek-r1/","title":"DeepSeek R1"},{"content":"一. 简介 1.1 介绍：DeepSeek 是一家专注于人工智能技术研发的公司，致力于打造高性能、低成本的 AI 模型。它的目标是让 AI 技术更加普惠，让更多人能够用上强大的 AI 工具。\n1.2 为什么DeepSeek-V3重要\n开源精神：DeepSeek-V3 不仅开源了模型权重，还提供了本地部署的支持，让开发者可以自由定制和优化模型。 普惠 AI：DeepSeek-V3 的价格非常亲民，相比国外模型（如 GPT-4o），它的使用成本更低，适合中小企业和个人开发者。 二. 收费情况 2.1 API收费情况 1.如未指定 max_tokens，默认最大输出长度为 4K。请调整 max_tokens 以支持更长的输出。\n2.表格中展示了优惠前与优惠后的价格。即日起至北京时间 2025-02-08 24:00，所有用户均可享受 DeepSeek-V3 API 的价格优惠。 在此之后，模型价格将恢复至原价。\n在大模型 API 的使用场景中，用户的输入有相当比例是重复的。举例说，用户的 prompt 往往有一些重复引用的部分；再举例说，多轮对话中，每一轮都要将前几轮的内容重复输入。\n为此，DeepSeek 启用上下文硬盘缓存技术，把预计未来会重复使用的内容，缓存在分布式的硬盘阵列中。如果输入存在重复，则重复的部分只需要从缓存读取，无需计算。该技术不仅降低服务的延迟，还大幅削减最终的使用成本。 缓存命中的部分，DeepSeek 收费 0.1元 每百万 tokens。至此，大模型的价格再降低一个数量级\nToken 是模型用来表示自然语言文本的基本单位，也是我们的计费单元，可以直观的理解为“字”或“词”；通常 1 个中文词语、1 个英文单词、1 个数字或 1 个符号计为 1 个 token。\n一般情况下模型中 token 和字数的换算比例大致如下：\n1 个英文字符 ≈ 0.3 个 token。 1 个中文字符 ≈ 0.6 个 token。 2.2 并发\nDeepSeek API 不限制用户并发量\n但请注意，当DeepSeek服务器承受高流量压力时，您的请求发出后，可能需要等待一段时间才能获取服务器的响应。在这段时间里，您的 HTTP 请求会保持连接，并持续收到如下格式的返回内容：\n非流式请求：持续返回空行 流式请求：持续返回 SSE keep-alive 注释（: keep-alive）\n这些内容不影响 OpenAI SDK 对响应的 JSON body 的解析。如果使用者自己解析 HTTP 响应，请注意处理这些空行或注释。\n三. 接入方式 3.1 API接入\n对话API ：https://api.deepseek.com/chat/completions\n请求头 Authorization ： Bearer 请求体， messages参数和model参数是必填的，参数示例如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 { \u0026#34;messages\u0026#34;: [ { \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;帮我翻译我是一个机器人，你是一个真人\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; } ], \u0026#34;model\u0026#34;: \u0026#34;deepseek-chat\u0026#34; } 请求参数详情 响应示例 ①非流式 ②流式 3.2 错误码 3.3 与其他大模型的对比 四.对比 知识类任务：MMLU，MMLU-Pro， GPQA, SimpleQA\n长文本：DROP，FRAMES ，LongBench v2\n代码：算法类（Codeforces），工程类（SWE-Bench Verified）\n数学：AIME 2024, MATH DeepSeek-V3 多项评测成绩超越了 Qwen2.5-72B 和 Llama-3.1-405B 等其他开源模型，并在性能上和世界顶尖的闭源模型 GPT-4o 以及 Claude-3.5-Sonnet 不分伯仲。\n百科知识： DeepSeek-V3 在知识类任务的水平接近当前表现最好的模型 Claude-3.5-Sonnet-1022。 长文本： 在长文本测评中，DeepSeek-V3 平均表现超越其他模型。 代码： DeepSeek-V3 在算法类代码场景远远领先于市面上已有的全部非 o1 类模型；并在工程类代码场景（SWE-Bench Verified）逼近 Claude-3.5-Sonnet-1022。 数学： 在美国数学竞赛和全国高中数学联赛上，DeepSeek-V3 大幅超过了所有开源闭源模型。 中文能力： DeepSeek-V3 与 Qwen2.5-72B 在教育类测评 C-Eval 和代词消歧等评测集上表现相近，但在事实知识 C-SimpleQA 上更为领先。 DeepSeek-V3支持本地部署，GPT-4o和Kimi均不支持本地部署 五. 创新点 使用上下文硬盘缓存技术，将预计未来会重复使用的内容进行缓存，如果输入存在重复，则重复的部分只需要从缓存读取，无需计算。该技术不仅降低服务的延迟，还大幅削减最终的使用成本。\n注意，只有当两个请求的前缀内容相同时（从第 0 个 token 开始相同），才算重复。中间开始的重复不能被缓存命中。\n使用场景：\n具有长预设提示词的问答助手类应用\n具有长角色设定与多轮对话的角色扮演类应用\n针对固定文本集合进行频繁询问的数据分析类应用\n代码仓库级别的代码分析与排障工具\n通过 Few-shot 提升模型输出效果 注意：\n缓存系统以 64 tokens 为一个存储单元，不足 64 tokens 的内容不会被缓存\n缓存系统是“尽力而为”，不保证 100% 缓存命中\n缓存不再使用后会自动被清空，时间一般为几个小时到几天\n六. 总结 DeepSeek-V3 是一款性能强大、价格亲民、开源支持的国产 AI 模型。它在知识问答、长文本处理、代码生成、数学能力等方面都展现出了与国际顶尖模型（如 GPT-4o）不相上下的实力。同时，它的低成本和开源特性让它成为普惠 AI 的典范。 未来，随着 DeepSeek-V3 的不断优化和功能扩展，它有望在更多领域发挥重要作用，成为国产 AI 技术的标杆。无论是企业还是个人开发者，都可以通过 DeepSeek-V3 享受到高性能、低成本的 AI 服务。 未来发展方向\n多模态支持 ：DeepSeek 计划在未来为 V3 模型添加多模态功能（如图像、音频处理），进一步提升模型的实用性。 深度思考能力 ：DeepSeek 将继续优化模型的推理和思考能力，使其能够处理更复杂的任务。 ","date":"2025-02-09T09:55:44+08:00","permalink":"https://h-yx-blog.github.io/p/deepseek%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94%E5%8F%8Aapi%E6%8E%A5%E5%85%A5/","title":"DeepSeek技术调研及api接入"},{"content":"本文主要针对Java新应用开发时，数据库设计及使用的一些共识规范，用于团队数据库设计的统一规划和管理。\n以MySQL作为示例介绍，内容分四个方面进行规范描述：建表，索引使用，SQL语句设计，以及ORM对象关系映射。\n一、建表规范 （1）表名、字段名必须使用小写字母或数字，除非数字本身具有共识含义，否则不建议使用，尤其禁止出现数字开头。\n（2）表达是与否的字段，数据类型应设定：unsigned tinyint，即非负数的短字节整型，其中1表示是，0表示否。\n（3）注意禁止使用数据库的保留字段是共识，比如asc,desc,select,match，定义好字段后，应该设置虚拟数据尝试常规的增删改查。\n（4）小数类型为 decimal，当数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储，禁止使用 float 和 double，因为其存在精度丢失的问题。\n（5）字段设置索引时，表示方式应遵循以下命名，主键索引为 pk_字段名，唯一索引为 uk_字段名，普通索引则为 idx_字段名\n（6）表的命名应该富有含义，且呈现分类分层，如factory_produce_order，factory_produce_device\n（7）如果存储的字符串长度确定且相等，可以使用 char 定长字符串类型，而不使用varchar\n（8）表应必备创建时间create_time和更新时间update_time，数据为datetime类型，用来表达数据初次创建和最近更新的时间。\n（9）varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。\n（10）当单表行数超过 500 万行或者单表内容超过 2GB，就应该要考虑业务分表。\n二、索引使用规范 （1）唯一索引的设置，业务上具有唯一特性的字段或多个字段的组合，必须建成唯一索引。在应用层做了非常完善的校验控制，只要没有唯一索引，长久必然有脏数据产生。\n（2）多表关联查询时，需要 join 字段的数据类型必须绝对一致，保证被关联的字段需要有索引。\n（3）在 varchar 字段上建立索引时，当业务没必要对全字段建立索引，可以指定索引长度，根据实际文本区分度决定索引长度即可。\n（4）如果有 order by 的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，例：where a=? and b=? order by c; 索引：a_b_c\n（5）建组合索引的时候，区分度最高的在最左边。例：如果 where a=? and b=? ，a 列的几乎接近于唯一值，那么只需要单建 idx_a 索引即可。\n存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where a\u0026gt;?and b=? 那么即使 a 的区分度更高，也必须把 b 放在索引的最前列。\n三、SQL语句规范 （1）不要使用 count(列名)或 count(常量)来替代 count()，count()是 SQL92 定义的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。\n（2）count(distinct col) 计算该列除 NULL 之外的不重复行数，注意 count(distinctcol1, col2) 如果其中一列全为 NULL，那么即使另一列有不同的值，也返回为 0\n（3）进行数据项的删除和修改时，要先 查询，避免出现误操作，确认无误才能执行更新语句。\n（4）不得使用外键与级联，一切外键概念必须在应用层解决，外键与级联更新适用于单机低并发，不适合分布式、高并发集群，因为级联更新是强阻塞，外键则严重影响数据库的插入速度\n（5）in 业务操作要尽量避免，当要使用时应控制 in 后边的集合元素数量，在 1000 个之内\n四、ORM对象关系映射 （1）在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明\n（2）xml 配置参数使用：#{}，#param# 不要使用${} 此种方式容易出现 SQL 注入\n（3）减少对整个pojo类目标更新，应该只更新改动的字段，若都进行全字段的更新（update table set c1=value1,c2=value2,c3=value3），会容易出错、效率低、增加 binlog 存储\n","date":"2025-01-24T10:59:15+08:00","permalink":"https://h-yx-blog.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/","title":"数据库设计规范"},{"content":"一、PPOCRLabel安装 介绍：PPOCRLabel是一款适用于OCR领域的半自动化图形标注工具，内置PP-OCR模型对数据自动标注和重新识别。使用Python3和PyQT5编写，支持矩形框标注、表格标注、不规则文本标注、关键信息标注模式，导出格式可直接用于PaddleOCR检测和识别模型的训练。\n工具：PPOCRLabel 官方文档：https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.5/PPOCRLabel/README_ch.md\n安装：pip install PPOCRLabel\n启动：\n1 2 3 # 选择标签模式来启动 PPOCRLabel --lang ch # 启动【普通模式】，用于打【检测+识别】场景的标签 PPOCRLabel --lang ch --kie True # 启动 【KIE 模式】，用于打【检测+识别+关键字提取】场景的标签 二、数据标注 将需要进行标注的图片存放在一个文件夹下，在ppocrlabel工具进行导入\n1.打开图片文件夹 2.选择自动标注点击ok等待自动标注完成 3.然后从第一张开始检查，打标文字错误的，点击方框，在右边修改 4.全部打标完成后，点击文件选择导出标记结果、以及导出识别结果\n完成后再文件夹多出四个文件fileState，Label，rec_gt, crop_img。其中crop_img中的图片用来训练文字识别模型，fileState记录图片的打标完成与否，Label为训练文字检测模型的标签，rec_gt为训练文字识别模型的标签。\n5.新建文件夹train_data及子目录drivingData （根据自己需求命名），将上面的数据放于drivingData下 6.打开终端进入PPOCRLabel的文件夹下，输入一下命令进行数据集划分 (注意最后的 ../train_data/drivingData 是我们上面的数据集路径。这里我是拷贝到了 PPOCRLabel所在位置的同级目录)\n1 python gen_ocr_train_val_test.py --trainValTestRatio 6:2:2 --datasetRootPath ../train_data/drivingData 输入指令之后，在train_data文件夹下会出现以下文件，其中det是用来训练文字检测的数据集，rec是用来训练文字识别的数据集。此时可以删去drivingData。 此时文字检测和文字识别的数据集就都制作好了。\n三、数据训练 官方文档：https://github.com/PaddlePaddle/PaddleOCR/blob/bb77fcef6fdfc029f92d7876b714554389053699/doc/doc_ch/recognition.md\n前置步骤：拉取官方PaddleOCR源码到本\n3.1 检测模型训练 前置步骤：拉取官方PaddleOCR源码到本地 步骤一：下载官方模型训练文件（注意：是下载训练模型，而不是推理模型） 此处可根据个人需求选择不同的训练模型\n步骤二：修改paddleocr检测模型配置文件 进入PaddleOcr源码，此处我选择的是ch_det_res18_db_v2.0.yml该配置文件进行修改 修改配置文件，此处我是cpu方式进行的训练，所以use_gpu参数要改为false， pretrained_model的值改为第一步下载好的训练模型的目录下的 best_acuracy所在的位置 继续修改配置文件，修改如下配置，改为上面制作好的数据集所在的位置 以下是我的完整配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 Global: use_gpu: false epoch_num: 200 log_smooth_window: 20 print_batch_step: 2 save_model_dir: ./output/ch_db_res18/ save_epoch_step: 100 # evaluation is run every 5000 iterations after the 4000th iteration eval_batch_step: [3000, 2000] cal_metric_during_train: False # pretrained_model: ./pretrain_models/ch_PP-OCRv4_det_train/best_accuracy pretrained_model: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\pretrain_models\\ch_ppocr_server_v2.0_det_train\\ch_ppocr_server_v2.0_det_train\\best_accuracy #pretrained_model: ./pretrain_models/ResNet18_vd_pretrained checkpoints: save_inference_dir: use_visualdl: False infer_img: doc/imgs_en/img_10.jpg save_res_path: ./output/det_db/predicts_db.txt Architecture: model_type: det algorithm: DB Transform: Backbone: name: ResNet_vd layers: 18 disable_se: True Neck: name: DBFPN out_channels: 256 Head: name: DBHead k: 50 Loss: name: DBLoss balance_loss: true main_loss_type: DiceLoss alpha: 5 beta: 10 ohem_ratio: 3 Optimizer: name: Adam beta1: 0.9 beta2: 0.999 lr: name: Cosine learning_rate: 0.001 warmup_epoch: 2 regularizer: name: \u0026#39;L2\u0026#39; factor: 0 PostProcess: name: DBPostProcess thresh: 0.3 box_thresh: 0.6 max_candidates: 1000 unclip_ratio: 1.5 Metric: name: DetMetric main_indicator: hmean Train: dataset: name: SimpleDataSet data_dir: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data label_file_list: # - ./train_data/det/train.txt - D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data\\det\\train.txt ratio_list: [1.0] transforms: - DecodeImage: # load image img_mode: BGR channel_first: False - DetLabelEncode: # Class handling label - IaaAugment: augmenter_args: - { \u0026#39;type\u0026#39;: Fliplr, \u0026#39;args\u0026#39;: { \u0026#39;p\u0026#39;: 0.5 } } - { \u0026#39;type\u0026#39;: Affine, \u0026#39;args\u0026#39;: { \u0026#39;rotate\u0026#39;: [-10, 10] } } - { \u0026#39;type\u0026#39;: Resize, \u0026#39;args\u0026#39;: { \u0026#39;size\u0026#39;: [0.5, 3] } } - EastRandomCropData: size: [960, 960] max_tries: 50 keep_ratio: true - MakeBorderMap: shrink_ratio: 0.4 thresh_min: 0.3 thresh_max: 0.7 - MakeShrinkMap: shrink_ratio: 0.4 min_text_size: 8 - NormalizeImage: scale: 1./255. mean: [0.485, 0.456, 0.406] std: [0.229, 0.224, 0.225] order: \u0026#39;hwc\u0026#39; - ToCHWImage: - KeepKeys: keep_keys: [\u0026#39;image\u0026#39;, \u0026#39;threshold_map\u0026#39;, \u0026#39;threshold_mask\u0026#39;, \u0026#39;shrink_map\u0026#39;, \u0026#39;shrink_mask\u0026#39;] # the order of the dataloader list loader: shuffle: True drop_last: False batch_size_per_card: 8 num_workers: 4 Eval: dataset: name: SimpleDataSet data_dir: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data label_file_list: # - ./train_data/det/val.txt - D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data\\det\\val.txt transforms: - DecodeImage: # load image img_mode: BGR channel_first: False - DetLabelEncode: # Class handling label - DetResizeForTest: # image_shape: [736, 1280] - NormalizeImage: scale: 1./255. mean: [0.485, 0.456, 0.406] std: [0.229, 0.224, 0.225] order: \u0026#39;hwc\u0026#39; - ToCHWImage: - KeepKeys: keep_keys: [\u0026#39;image\u0026#39;, \u0026#39;shape\u0026#39;, \u0026#39;polys\u0026#39;, \u0026#39;ignore_tags\u0026#39;] loader: shuffle: False drop_last: False batch_size_per_card: 1 # must be 1 num_workers: 2 步骤三：开始训练模型\n进入PaddleOCR源码根目录，打开cmd，输入以下命令,开始训练\n1 python tools/train.py -c configs/det/ch_ppocr_v2.0/ch_det_res18_db_v2.0.yml 如遇报错，可能是需要先安装pyyaml库 pip install pyyaml 训练结果如下 使用best_accuracy.pdparams进行我们的模型测试，没有该文件则说明训练次数少，用latest.pdparams模型测试 步骤四：测试训练模型\n1 2 # pretrained_model参数值为刚刚训练好的模型所在的位置， infre_img为所需要检测的文件（也可以是文件夹） python tools/infer_det.py -c configs/det/ch_ppocr_v2.0/ch_det_res18_db_v2.0.yml -o Global.pretrained_model=output/ch_db_res18/latest.pdparams Global.infer_img=\u0026#34;C:\\Users\\lenovo\\Desktop\\paddle-ocr-data\\demo.png\u0026#34; 文字检测结果如下 3.2 识别模型训练 步骤一：下载官方模型训练文件 此处我选择的是 ch_PP-OCRv3_rec 步骤二：修改padleocr识别模型配置文件 在configs /rec/PP-OCRv3 /找到 ch_PP-OCRv3_rec.yml 配置文件\n识别模型的配置文件有个注意的配置参数为：batch_size_per_card，数据集的图片数量不能小于以下配置的数值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 Global: debug: false #此处我使用的是cpu模式，下面参数需要改为false use_gpu: false epoch_num: 50 log_smooth_window: 20 print_batch_step: 2 #模型训练输出目录 save_model_dir: ./output/rec_ppocr_v3 save_epoch_step: 25 eval_batch_step: [0, 2000] cal_metric_during_train: true #预训练模型所在位置 pretrained_model: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\pretrain_models\\ch_PP-OCRv4_rec_train\\ch_PP-OCRv4_rec_train\\student.pdparams checkpoints: save_inference_dir: use_visualdl: false infer_img: doc/imgs_words/ch/word_1.jpg character_dict_path: ppocr/utils/ppocr_keys_v1.txt max_text_length: \u0026amp;max_text_length 25 infer_mode: false use_space_char: true distributed: true #识别结果输出目录 save_res_path: ./output/rec/predicts_ppocrv3.txt Optimizer: name: Adam beta1: 0.9 beta2: 0.999 lr: name: Cosine learning_rate: 0.001 warmup_epoch: 5 regularizer: name: L2 factor: 3.0e-05 Architecture: model_type: rec algorithm: SVTR_LCNet Transform: Backbone: name: MobileNetV1Enhance scale: 0.5 last_conv_stride: [1, 2] last_pool_type: avg last_pool_kernel_size: [2, 2] Head: name: MultiHead head_list: - CTCHead: Neck: name: svtr dims: 64 depth: 2 hidden_dims: 120 use_guide: True Head: fc_decay: 0.00001 - SARHead: enc_dim: 512 max_text_length: *max_text_length Loss: name: MultiLoss loss_config_list: - CTCLoss: - SARLoss: PostProcess: name: CTCLabelDecode Metric: name: RecMetric main_indicator: acc ignore_space: False Train: dataset: name: SimpleDataSet #修改为训练数据集所在的目录 data_dir: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data ext_op_transform_idx: 1 label_file_list: #修改为训练数据集所在的位置 - D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data\\rec\\train.txt transforms: - DecodeImage: img_mode: BGR channel_first: false - RecConAug: prob: 0.5 ext_data_num: 2 image_shape: [48, 320, 3] max_text_length: *max_text_length - RecAug: - MultiLabelEncode: - RecResizeImg: image_shape: [3, 48, 320] - KeepKeys: keep_keys: - image - label_ctc - label_sar - length - valid_ratio loader: shuffle: true #以下配置记得修改，数据集的图片数量不能小于以下配置的数值 batch_size_per_card: 4 drop_last: true num_workers: 4 Eval: dataset: name: SimpleDataSet #修改为训练数据集所在的目录 data_dir: D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data label_file_list: #修改为训练数据集所在的位置 - D:\\devlop_study\\python_wordspace\\paddleocr_test\\PaddleOCR\\train_data\\rec\\val.txt transforms: - DecodeImage: img_mode: BGR channel_first: false - MultiLabelEncode: - RecResizeImg: image_shape: [3, 48, 320] - KeepKeys: keep_keys: - image - label_ctc - label_sar - length - valid_ratio loader: shuffle: false drop_last: false #以下配置记得修改，数据集的图片数量不能小于以下配置的数值 batch_size_per_card: 4 num_workers: 4 步骤三：开始训练模型\n进入paddleOCR源码的根目录，打开cmd，输入以下命令\n1 python tools/train.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml 训练结果 步骤四：模型测试\n1 python tools/infer_rec.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml -o Global.pretrained_model=output/rec_ppocr_v3/latest.pdparams Global.infer_img=\u0026#34;C:\\Users\\lenovo\\Desktop\\paddle-ocr-data\\test\\res1.png\u0026#34; 识别结果（由于训练的图片数量较少且训练次数少，以下的识别结果并不好） 识别为了 0E0E，但原图却是很长一串 原图 四、配置文件参详解 参考教程：\nhttps://blog.csdn.net/qq_52852432/article/details/131817619 https://blog.csdn.net/m0_60657960/article/details/144725182 https://blog.csdn.net/m0_60657960/article/details/137072289\nhttps://blog.csdn.net/weixin_41819299/article/details/127914305\nhttps://blog.csdn.net/qq_43479628/article/details/141400126\nhttps://cloud.baidu.com/article/3360301\n可能遇到的问题\nhttps://github.com/PaddlePaddle/PaddleOCR/issues/13437\nhttps://github.com/PaddlePaddle/PaddleOCR/issues/6684\nhttps://github.com/PaddlePaddle/PaddleOCR/issues/2470\n","date":"2025-01-10T15:19:17+08:00","permalink":"https://h-yx-blog.github.io/p/paddleocr%E8%AE%AD%E7%BB%83%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE/","title":"PaddleOcr训练自定义数据"},{"content":" # 一、ocr识别函数\n注意 1. 如果角度分类器未初始化 （use_angle_cls=False），则在正向过程中不会使用它。 2. 对于 PDF 文件，如果输入是图像列表并且指定了 page_num，则只会处理前 page_num 张图像。 3. 源码中preprocess_image 函数用于通过应用 Alpha 颜色替换、反转和二值化（如果指定）来预处理输入图像。如下为preprocess_image函数\n形参: 参数名\t含义\nimg：OCR 图像。它可以是一个 ndarray、img_path 或 ndarray 列表。\ndet：是否使用文本检测。如果为 False，则仅执行文本识别。默认值为 True。\nrec：使用文本识别与否。如果为 False，则仅执行文本检测。默认值为 True。\ncls：是否使用角度分类器。默认值为 True。如果为 True，则可以识别旋转 180 度的文本。如果没有文本旋转 180 度，请使用 cls=False 以获得更好的性能。\nbin：将图像二值化为黑白。默认值为 False。\ninv：反转图像颜色。默认值为 False\nalpha_color：设置 RGB 颜色元组以进行透明零件更换。默认值为纯白色。\nslice：\t对大图像使用滑动窗口推理。det 和 rec 都必须为 True。需要 slice[“horizontal_stride”]、slice[“vertical_stride”]、slice[“merge_x_thres”]、slice[“merge_y_thres”] 的 int 值（参见 doc/ doc_en/ slice_en. md）。默认值为 {}。\n返回值: 如果 det 和 rec 均为 True，则返回每个图像的 OCR 结果列表。每个 OCR 结果都是每个检测到的文本区域的边界框和已识别文本的列表。 如果 det 为 True 且 rec 为 False，则返回每个图像检测到的边界框列表。 如果 det 为 False 且 rec 为 True，则返回每个图像的已识别文本列表。 如果 det 和 rec 均为 False，则返回每个图像的角度分类结果列表。 异常: AssertionError – 如果输入图像不是 ndarray、list、str 或 bytes 类型。 SystemExit – 如果 det 为 True，并且输入是图像列表\n二、PaddleOCR构造函数 PaddleOCR继承的父类如下 PaddleOCR构造函数可传入的参数详情见：https://paddlepaddle.github.io/PaddleOCR/latest/ppocr/blog/inference_args.html\n主要有以下类型的参数，每一种类型都有若干参数\n全局信息 预测引擎相关 文本检测模型相关 文本识别模型相关 端到端文本检测与识别模型相关 方向分类器模型相关 算法相关 ","date":"2025-01-06T16:50:51+08:00","permalink":"https://h-yx-blog.github.io/p/paddleocr%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/","title":"PaddleOCR参数详解"},{"content":"","date":"2025-01-05T21:31:55+08:00","permalink":"https://h-yx-blog.github.io/p/kafka%E5%85%A5%E9%97%A8%E5%8F%8A%E5%BA%94%E7%94%A8/","title":"Kafka入门及应用"},{"content":"一、基本概念 大数据生态系统里很多组件的命名都是某种动物，例如Hadoop是🐘，hive是🐝，zookeeper就是动物园管理者，是管理大数据生态系统各组件的管理员。\nzookeeper是经典的分布式数据一致性解决方案，致力于为分布式应用提供一个高性能，高可用，且具有严格顺序访问控制能力的分布式协调存储服务。\n1.1 应用场景 维护配置信息 Java编程经常会遇到配置项，例如数据库的user、password等，通常配置信息会放在配置文件中，再把配置文件放在服务器上。当需要修改配置信息时，要去服务器上修改对应的配置文件，但在分布式系统中很多服务器都需要使用该配置文件，因此必须保证该配置服务的高可用性和各台服务器上配置的一致性。通常会将配置文件部署在一个集群上，但一个集群涉及的服务器数量是很庞大的，如果一台台服务器逐个修改配置文件是效率很低且危险的，因此需要一种服务可以高效快速且可靠地完成配置项的更改工作。 zookeeper就可以提供这种服务，使用Zab一致性协议保证一致性。hbase中客户端就是连接zookeeper获得必要的hbase集群的配置信息才可以进一步操作。在开源消息队列Kafka中，也使用zookeeper来维护broker的信息。在dubbo中也广泛使用zookeeper管理一些配置来实现服务治理。\n分布式锁服务 一个集群是一个分布式系统，由多台服务器组成。为了提高并发度和可靠性，在多台服务器运行着同一种服务。当多个服务在运行时就需要协调各服务的进度，有时候需要保证当某个服务在进行某个操作时，其他的服务都不能进行该操作，即对该操作进行加锁，如果当前机器故障，释放锁并fall over到其他机器继续执行。\n集群管理 zookeeper会将服务器加入/移除的情况通知给集群中其他正常工作的服务器，以及即使调整存储和计算等任务的分配和执行等，此外zookeeper还会对故障的服务器做出诊断并尝试修复。\n生成分布式唯一ID 在过去的单库单表系统中，通常使用数据库字段自带的auto_increment熟悉自动为每条记录生成一个唯一的id。但分库分表后就无法依靠该属性来标识一个唯一的记录。此时可以使用zookeeper在分布式环境下生成全局唯一性id。每次要生成一个新id时，创建一个持久顺序结点，创建操作返回的结点序号，即为新id，然后把比自己结点小的删除。\n1.2 设计目标 高性能 将数据存储在内存中，直接服务于客户端的所有非事务请求，尤其适合读为主的应用场景 高可用 一般以集群方式对外提供服务，每台机器都会在内存中维护当前的服务状态，每台机器之间都保持通信。只要集群中超过一半机器都能正常工作，那么整个集群就能够正常对外服务。 严格顺序访问 对于客户端的每个更新请求，zookeeper都会生成全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序。 1.3 数据结构 zookeeper的数据结点可以视为树状结构（或者目录），树中各节点成为znode，一个znode可以有多个子结点。zookeeper结点在结构上表现为树状，使用路径来定位某个znode。 znode兼具文件和目录两种特点，既像文件一样维护着数据、元信息、ACL、时间戳等数据结构，又像目录一样可以作为路径标识的一部分。\nznode大体上分为三部分（使用get命令查看）\n结点的数据 结点的子结点 结点的状态 结点类型（在创建时被确定且不能更改）\n临时结点：生命周期依赖于创建它的会话，会话结束结点将被自动删除。临时结点不允许拥有子结点。 持久化结点：生命周期不依赖于会话，只有在客户端显式执行删除操作时才被删除。 1.4 ACL权限控制 此处暂作了解，可参考：https://blog.csdn.net/qq_41112238/article/details/105240421\n二、基本命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #1.连接zooker服务端 ip和port记得换为具体的ip和端口，zk默认端口是2181 ./zkCli.sh –server ip:port #2.断开连接 quit #3.查看命令帮助 help #4.显示指定目录下节点 ls 目录 #5.创建节点 create /节点具体路径 value #6.获取节点的值 get /节点具体路径 #7.设置节点的值 set /节点具体路径 value #8.删除单个节点 delete /节点具体路径 #9.删除带有子节点的节点 deleteall /节点具体路径 #10.创建临时节点 create -e /节点具体路径 value #11.创建顺序节点 create -s /节点具体路径 value #12.查询节点详细信息 ls –s /节点具体路径 节点信息：\nczxid：节点被创建的事务ID ctime: 创建时间 mzxid: 最后一次被更新的事务ID mtime: 修改时间 pzxid：子节点列表最后一次被更新的事务ID cversion：子节点的版本号 dataversion：数据版本号 aclversion：权限版本号 ephemeralOwner：用于临时节点，代表临时节点的事务ID，如果为持久节点则为0 dataLength：节点存储的数据的长度 numChildren：当前节点的子节点个数 三、SpringBoot集成zk客户端 常见的ZooKeeper Java API ：\n原生Java API ZkClient Curator 下面以Curator来进行集成 引入依赖\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-framework\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 3.1 创建、修改、查询、删除节点操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.framework.api.BackgroundCallback; import org.apache.curator.framework.api.CuratorEvent; import org.apache.curator.retry.ExponentialBackoffRetry; import org.apache.zookeeper.CreateMode; import org.apache.zookeeper.data.Stat; import org.junit.After; import org.junit.Before; import org.junit.Test; import java.util.List; public class CuratorTest { private CuratorFramework client; /** * 建立连接 */ @Before public void testConnect() { /* * * @param connectString 连接字符串。zk server 地址和端口 \u0026#34;192.168.149.135:2181,192.168.149.136:2181\u0026#34; * @param sessionTimeoutMs 会话超时时间 单位ms * @param connectionTimeoutMs 连接超时时间 单位ms * @param retryPolicy 重试策略 */ /* //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000,10); //1.第一种方式 CuratorFramework client = CuratorFrameworkFactory.newClient(\u0026#34;192.168.149.135:2181\u0026#34;, 60 * 1000, 15 * 1000, retryPolicy);*/ //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000, 10); //2.第二种方式 //CuratorFrameworkFactory.builder(); client = CuratorFrameworkFactory.builder() .connectString(\u0026#34;ip地址:2181\u0026#34;) //此处一定要修改为具体的zookeeper所在的服务器ip .sessionTimeoutMs(60 * 1000) .connectionTimeoutMs(15 * 1000) .retryPolicy(retryPolicy) .namespace(\u0026#34;mydemo\u0026#34;) .build(); //开启连接 client.start(); } //==============================create============================================================================= /** * 创建节点：create 持久 临时 顺序 数据 * 1. 基本创建 ：create().forPath(\u0026#34;\u0026#34;) * 2. 创建节点 带有数据:create().forPath(\u0026#34;\u0026#34;,data) * 3. 设置节点的类型：create().withMode().forPath(\u0026#34;\u0026#34;,data) * 4. 创建多级节点 /app1/p1 ：create().creatingParentsIfNeeded().forPath(\u0026#34;\u0026#34;,data) */ @Test public void testCreate() throws Exception { //2. 创建节点 带有数据 //如果创建节点，没有指定数据，则默认将当前客户端的ip作为数据存储 String path = client.create().forPath(\u0026#34;/app2\u0026#34;, \u0026#34;hehe\u0026#34;.getBytes()); System.out.println(path); } @Test public void testCreate2() throws Exception { //1. 基本创建 //如果创建节点，没有指定数据，则默认将当前客户端的ip作为数据存储 String path = client.create().forPath(\u0026#34;/app1\u0026#34;); System.out.println(path); } @Test public void testCreate3() throws Exception { //3. 设置节点的类型 //默认类型：持久化 String path = client.create().withMode(CreateMode.EPHEMERAL).forPath(\u0026#34;/app3\u0026#34;); System.out.println(path); } @Test public void testCreate4() throws Exception { //4. 创建多级节点 /app1/p1 //creatingParentsIfNeeded():如果父节点不存在，则创建父节点 String path = client.create().creatingParentsIfNeeded().forPath(\u0026#34;/app4/p1\u0026#34;); System.out.println(path); } //===========================get================================================================================ /** * 查询节点： * 1. 查询数据：get: getData().forPath() * 2. 查询子节点： ls: getChildren().forPath() * 3. 查询节点状态信息：ls -s:getData().storingStatIn(状态对象).forPath() */ @Test public void testGet1() throws Exception { //1. 查询数据：get byte[] data = client.getData().forPath(\u0026#34;/app1\u0026#34;); System.out.println(new String(data)); } @Test public void testGet2() throws Exception { // 2. 查询子节点： ls List\u0026lt;String\u0026gt; path = client.getChildren().forPath(\u0026#34;/\u0026#34;); System.out.println(path); } @Test public void testGet3() throws Exception { Stat status = new Stat(); System.out.println(status); //3. 查询节点状态信息：ls -s client.getData().storingStatIn(status).forPath(\u0026#34;/app1\u0026#34;); System.out.println(status); } //===========================set================================================================================ /** * 修改数据 * 1. 基本修改数据：setData().forPath() * 2. 根据版本修改: setData().withVersion().forPath() * * version 是通过查询出来的。目的就是为了让其他客户端或者线程不干扰我。 * * @throws Exception */ @Test public void testSet() throws Exception { client.setData().forPath(\u0026#34;/app1\u0026#34;, \u0026#34;itcast\u0026#34;.getBytes()); } @Test public void testSetForVersion() throws Exception { Stat status = new Stat(); //3. 查询节点状态信息：ls -s client.getData().storingStatIn(status).forPath(\u0026#34;/app1\u0026#34;); int version = status.getVersion();//查询出来的 3 System.out.println(version); client.setData().withVersion(version).forPath(\u0026#34;/app1\u0026#34;, \u0026#34;hehe\u0026#34;.getBytes()); } //===========================delete================================================================================ /** * 删除节点： delete deleteall * 1. 删除单个节点:delete().forPath(\u0026#34;/app1\u0026#34;); * 2. 删除带有子节点的节点:delete().deletingChildrenIfNeeded().forPath(\u0026#34;/app1\u0026#34;); * 3. 必须成功的删除:为了防止网络抖动。本质就是重试。 client.delete().guaranteed().forPath(\u0026#34;/app2\u0026#34;); * 4. 回调：inBackground * @throws Exception */ @Test public void testDelete() throws Exception { // 1. 删除单个节点 client.delete().forPath(\u0026#34;/app1\u0026#34;); } @Test public void testDelete2() throws Exception { //2. 删除带有子节点的节点 client.delete().deletingChildrenIfNeeded().forPath(\u0026#34;/app4\u0026#34;); } @Test public void testDelete3() throws Exception { //3. 必须成功的删除 client.delete().guaranteed().forPath(\u0026#34;/app2\u0026#34;); } @Test public void testDelete4() throws Exception { //4. 回调 client.delete().guaranteed().inBackground(new BackgroundCallback(){ @Override public void processResult(CuratorFramework client, CuratorEvent event) throws Exception { System.out.println(\u0026#34;我被删除了~\u0026#34;); System.out.println(event); } }).forPath(\u0026#34;/app1\u0026#34;); } @After public void close() { if (client != null) { client.close(); } } } 3.2 监听器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 package com.itheima.curator; import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.framework.api.BackgroundCallback; import org.apache.curator.framework.api.CuratorEvent; import org.apache.curator.framework.recipes.cache.*; import org.apache.curator.retry.ExponentialBackoffRetry; import org.apache.zookeeper.CreateMode; import org.apache.zookeeper.data.Stat; import org.junit.After; import org.junit.Before; import org.junit.Test; import java.util.List; public class CuratorWatcherTest { private CuratorFramework client; /** * 建立连接 */ @Before public void testConnect() { /* * * @param connectString 连接字符串。zk server 地址和端口 \u0026#34;192.168.149.135:2181,192.168.149.136:2181\u0026#34; * @param sessionTimeoutMs 会话超时时间 单位ms * @param connectionTimeoutMs 连接超时时间 单位ms * @param retryPolicy 重试策略 */ /* //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000,10); //1.第一种方式 CuratorFramework client = CuratorFrameworkFactory.newClient(\u0026#34;192.168.149.135:2181\u0026#34;, 60 * 1000, 15 * 1000, retryPolicy);*/ //重试策略 RetryPolicy retryPolicy = new ExponentialBackoffRetry(3000, 10); //2.第二种方式 //CuratorFrameworkFactory.builder(); client = CuratorFrameworkFactory.builder() .connectString(\u0026#34;ip地址:2181\u0026#34;) //此处ip地址修改为zk所在服务器的ip .sessionTimeoutMs(60 * 1000) .connectionTimeoutMs(15 * 1000) .retryPolicy(retryPolicy) //在这种策略下，如何itheima这个节点下没有子节点了，过一会就会自动把itheima这个节点删除了 .namespace(\u0026#34;itheima\u0026#34;) .build(); //开启连接 client.start(); } @After public void close() { if (client != null) { client.close(); } } /** * 演示 NodeCache：给指定一个节点注册监听器 */ @Test public void testNodeCache() throws Exception { //1. 创建NodeCache对象 final NodeCache nodeCache = new NodeCache(client,\u0026#34;/app1\u0026#34;); //2. 注册监听 nodeCache.getListenable().addListener(new NodeCacheListener() { @Override public void nodeChanged() throws Exception { System.out.println(\u0026#34;节点变化了~\u0026#34;); //获取修改节点后的数据 byte[] data = nodeCache.getCurrentData().getData(); System.out.println(new String(data)); } }); //3. 开启监听.如果设置为true，则开启监听是，加载缓冲数据 nodeCache.start(true); while (true){ } } /** * 演示 PathChildrenCache：监听某个节点的所有子节点们 */ @Test public void testPathChildrenCache() throws Exception { //1.创建监听对象 PathChildrenCache pathChildrenCache = new PathChildrenCache(client,\u0026#34;/app2\u0026#34;,true); //2. 绑定监听器 pathChildrenCache.getListenable().addListener(new PathChildrenCacheListener() { @Override public void childEvent(CuratorFramework client, PathChildrenCacheEvent event) throws Exception { System.out.println(\u0026#34;子节点变化了~\u0026#34;); System.out.println(event); //监听子节点的数据变更，并且拿到变更后的数据 //1.获取类型 PathChildrenCacheEvent.Type type = event.getType(); //2.判断类型是否是update if(type.equals(PathChildrenCacheEvent.Type.CHILD_UPDATED)){ System.out.println(\u0026#34;数据变了！！！\u0026#34;); byte[] data = event.getData().getData(); System.out.println(new String(data)); } } }); //3. 开启 pathChildrenCache.start(); while (true){ } } /** * 演示 TreeCache：监听某个节点自己和所有子节点们 */ @Test public void testTreeCache() throws Exception { //1. 创建监听器 TreeCache treeCache = new TreeCache(client,\u0026#34;/app2\u0026#34;); //2. 注册监听 treeCache.getListenable().addListener(new TreeCacheListener() { @Override public void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception { System.out.println(\u0026#34;节点变化了\u0026#34;); System.out.println(event); } }); //3. 开启 treeCache.start(); while (true){ } } } 参考文章 https://blog.csdn.net/qq_41112238/article/details/105240421\n","date":"2025-01-04T21:10:52+08:00","permalink":"https://h-yx-blog.github.io/p/zookeeper%E5%85%A5%E9%97%A8/","title":"Zookeeper入门"},{"content":"1.1 下载安装 1、环境准备\nZooKeeper服务器是用Java创建的，它运行在JVM之上。需要安装JDK 7或更高版本。\n2、上传\n将下载的ZooKeeper放到/opt/ZooKeeper目录下\n1 2 3 4 5 6 7 8 #上传zookeeper alt+p put f:/setup/apache-zookeeper-3.5.6-bin.tar.gz #打开 opt目录 cd /opt #创建zooKeeper目录 mkdir zooKeeper #将zookeeper安装包移动到 /opt/zooKeeper mv apache-zookeeper-3.5.6-bin.tar.gz /opt/zookeeper/ 3、解压\n将tar包解压到/opt/zookeeper目录下\n1 tar -zxvf apache-ZooKeeper-3.5.6-bin.tar.gz 1.2 配置启动 1、配置zoo.cfg\n进入到conf目录拷贝一个zoo_sample.cfg并完成配置\n1 2 3 4 #进入到conf目录 cd /opt/zooKeeper/apache-zooKeeper-3.5.6-bin/conf/ #拷贝 cp zoo_sample.cfg zoo.cfg 修改zoo.cfg\n1 2 3 4 5 6 #打开目录 cd /opt/zooKeeper/ #创建zooKeeper存储目录 mkdir zkdata #修改zoo.cfg vim /opt/zooKeeper/apache-zooKeeper-3.5.6-bin/conf/zoo.cfg 修改存储目录：dataDir=/opt/zookeeper/zkdata\n2、启动ZooKeeper\n1 2 3 cd /opt/zooKeeper/apache-zooKeeper-3.5.6-bin/bin/ #启动 ./zkServer.sh start 看到上图表示ZooKeeper成功启动\n3、查看ZooKeeper状态\n1 ./zkServer.sh status zookeeper启动成功。standalone代表zk没有搭建集群，现在是单节点\nzookeeper没有启动\n","date":"2025-01-04T13:28:19+08:00","permalink":"https://h-yx-blog.github.io/p/zookeeper%E6%90%AD%E5%BB%BA/","title":"Zookeeper搭建"},{"content":"一、概念 1. 大数据处理流程 上图是一个简化的大数据处理流程图，大数据处理的主要流程包括数据收集、数据存储、数据处理、数据应用等主要环节。下面我们逐一对各个环节所需要的技术栈进行讲解：\n1.1 数据收集 大数据处理的第一步，第一种是通过 Sqoop 或者 Cannal 等工具进行定时抽取或者实时同步；第二种是各种埋点日志，通过 Flume 进行实时收集。\n大数据处理的第一步是数据的收集。现在的中大型项目通常采用微服务架构进行分布式部署，所以数据的采集需要在多台服务器上进行，且采集过程不能影响正常业务的开展。基于这种需求，就衍生了多种日志收集工具，如 Flume 、Logstash、Kibana 等，它们都能通过简单的配置完成复杂的数据收集和数据聚合。\n1.2 数据存储 大数据处理的第二步，将数据存储到 HDFS 中，实时日志流情况下通过 Kafka 输出给后面的流式计算引擎。\n收集到数据后，下一个问题就是：数据该如何进行存储？通常最为熟知是 MySQL、Oracle 等传统的关系型数据库，它们的优点是能够快速存储结构化的数据，并支持随机访问。但大数据的数据结构通常是半结构化（如日志数据）、甚至是非结构化的（如视频、音频数据），为了解决海量半结构化和非结构化数据的存储，衍生了 Hadoop HDFS 、KFS、GFS 等分布式文件系统，它们都能够支持结构化、半结构和非结构化数据的存储，并可以通过增加机器进行横向扩展。\n分布式文件系统完美地解决了海量数据存储的问题，但是一个优秀的数据存储系统需要同时考虑数据存储和访问两方面的问题，比如你希望能够对数据进行随机访问，这是传统的关系型数据库所擅长的，但却不是分布式文件系统所擅长的，那么有没有一种存储方案能够同时兼具分布式文件系统和关系型数据库的优点，基于这种需求，就产生了 HBase、MongoDB。\n1.3 数据分析 大数据的核心环节，包括离线处理和流处理两种方式，对应的计算引擎包括 MapReduce、Spark、Flink 等，处理完的结果会保存到已经提前设计好的数据仓库中，或者 HBase、Redis、RDBMS 等各种存储系统上。\n大数据处理最重要的环节就是数据分析，数据分析通常分为两种：批处理和流处理。\n批处理：对一段时间内海量的离线数据进行统一的处理，对应的处理框架有 Hadoop MapReduce、Spark、Flink 等； 流处理：对运动中的数据进行处理，即在接收数据的同时就对其进行处理，对应的处理框架有 Storm、Spark Streaming、Flink Streaming 等。 批处理和流处理各有其适用的场景，时间不敏感或者硬件资源有限，可以采用批处理；时间敏感和及时性要求高就可以采用流处理。随着服务器硬件的价格越来越低和大家对及时性的要求越来越高，流处理越来越普遍，如股票价格预测和电商运营数据分析等。\n上面的框架都是需要通过编程来进行数据分析，那么如果你不是一个后台工程师，是不是就不能进行数据的分析了？当然不是，大数据是一个非常完善的生态圈，有需求就有解决方案。为了能够让熟悉 SQL 的人员也能够进行数据的分析，查询分析框架应运而生，常用的有 Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix 等。这些框架都能够使用标准的 SQL 或者 类 SQL 语法灵活地进行数据的查询分析。这些 SQL 经过解析优化后转换为对应的作业程序来运行，如 Hive 本质上就是将 SQL 转换为 MapReduce 作业，Spark SQL 将 SQL 转换为一系列的 RDDs 和转换关系（transformations），Phoenix 将 SQL 查询转换为一个或多个 HBase Scan。\n1.4 数据应用 应用场景：数据可视化、业务决策、推荐算法优化、机器学习\u0026hellip;\n数据分析完成后，接下来就是数据应用的范畴，这取决于你实际的业务需求。比如你可以将数据进行可视化展现，或者将数据用于优化你的推荐算法，这种运用现在很普遍，比如短视频个性化推荐、电商商品推荐、头条新闻推荐等。当然你也可以将数据用于训练你的机器学习模型，这些都属于其他领域的范畴，都有着对应的框架和技术栈进行处理，这里就不一一赘述。\n1.5 其他框架 上面是一个标准的大数据处理流程所用到的技术框架。但是实际的大数据处理流程比上面复杂很多，针对大数据处理中的各种复杂问题分别衍生了各类框架：\n单机的处理能力都是存在瓶颈的，所以大数据框架都是采用集群模式进行部署，为了更方便的进行集群的部署、监控和管理，衍生了 Ambari、Cloudera Manager 等集群管理工具； 想要保证集群高可用，需要用到 ZooKeeper ，ZooKeeper 是最常用的分布式协调服务，它能够解决大多数集群问题，包括首领选举、失败恢复、元数据存储及其一致性保证。同时针对集群资源管理的需求，又衍生了 Hadoop YARN ; 复杂大数据处理的另外一个显著的问题是，如何调度多个复杂的并且彼此之间存在依赖关系的作业？基于这种需求，产生了 Azkaban 和 Oozie 等工作流调度框架； 大数据流处理中使用的比较多的另外一个框架是 Kafka，它可以用于消峰，避免在秒杀等场景下并发数据对流处理程序造成冲击； 另一个常用的框架是 Sqoop ，主要是解决了数据迁移的问题，它能够通过简单的命令将关系型数据库中的数据导入到 HDFS 、Hive 或 HBase 中，或者从 HDFS 、Hive 导出到关系型数据库上。\n1.6 框架分类 日志收集框架：Flume、Logstash、Filebeat\n分布式文件存储系统：Hadoop HDFS\n数据库系统：Mongodb、HBase\n分布式计算框架：\n批处理框架：Hadoop MapReduce 流处理框架：Storm 混合处理框架：Spark、Flink 查询分析框架：Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix\n集群资源管理器：Hadoop YARN\n分布式协调服务：Zookeeper\n数据迁移工具：Sqoop\n任务调度框架：Azkaban、Oozie\n集群部署和监控：Ambari、Cloudera Manager\n2. 数据仓库 2.1 什么是数据仓库？ 在计算中，数据仓库（DW或DWH）也称为企业数据仓库（EDW），是用于报告和数据分析的系统，被视为商业智能的核心组件。DWs从一个或多个不同源的综合数据的中央储存库。他们将当前和历史数据存储在一个地方，用于为整个企业的工作人员创建分析报告。\n3. OLTP与OLAP的区别 OLTP与OLAP是数据仓库的两种操作方式。 当今的数据处理大致可分为两大类，联机事务处理OLTP（on-line transaction processing） 和联机分析处理OLAP（on-line analytical processing)。\nOLTP是传统关系型数据库的主要应用，用来执行一些基本的、日常的事务处理，比如数据库记录的增、删、改、查等等。而OLAP则是分布式数据库的主要应用，它对实时性要求不高，但处理的数据量大，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果，通常应用于复杂的动态报表系统上。\n4. ETL与DM的区别 ETL/Extraction-Transformation-Loading——用于完成DB到DW的数据转存，它将DB中的某一个时间点的状态，“抽取”出来，根据DW的存储模型要求，“转换”一下数据格式，然后再“加载”到DW的一个过程，这里需要强调的是，DB的模型是ER模型，遵从范式化设计原则，而DW的数据模型是雪花型结构或者星型结构，用的是面向主题，面向问题的设计思路，所以DB和DW的模型结构不同，需要进行转换。\nDM/Data Mining/数据挖掘——这个挖掘，不是简单的统计了，他是根据概率论的或者其他的统计学原理，将DW中的大数据量进行分析，找出我们不能直观发现的规律。\n5. 行式存储与列式存储 列式存储是指一列中的数据在存储介质中是连续存储的；\n行式存储是指一行中的数据在存储介质中是连续存储的。 什么时候使用列式存储，什么时候使用行式存储？\n如果一个OLPA类型查询，在海量数据行中，只关心几列数据，效率就比较低了。这种情况列存储就有很大优势。同样如果每次查询设计的数据量较小，或者大部分查询都需要整行数据，行存储就有优势。\n如果需要关注整张表或者大部分数据，不是单独几列而且关注内容不需要聚集运算，推荐行式存储；\n如果主要关注大量数据中某几列内容，或者要频繁聚集，然后对聚集后数据进行数据分析，推荐列式存储。\n6. HDFS（分布式文件系统） HDFS(Hadoop Distribute File System)，是适用于大的数据集的支持高吞吐和高容错的运行在通用机器上的分布式系统。Hapoop就是使用HDFS来存储海量数据，使用MapReduce来处理数据。但是hdfs主要是实现批量数据的处理，并且通过顺序方式访问数据，如果要查找数据必须搜索整个数据集，如果要随机读取数据，效率很低。\n7. MapReduce 上文多次提出，以MapReduce提供计算能力。MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集\nMapReduce擅长处理大数据。MapReduce的思想就是“分而治之”。Mapper负责“分”，即把复杂的任务分解为若干个“简单的任务”来处理。“简单的任务”包含三层含义：一是数据或计算的规模相对原任务要大大缩小；二是就近计算原则，即任务会分配到存放着所需数据的节点上进行计算；三是这些小任务可以并行计算，彼此间几乎没有依赖关系。Reducer负责对map阶段的结果进行汇总。\n二、特点 大数据特点\n①Volume：数据量大，包括采集、存储和计算的量都非常大。大数据的起始计量单位至少是P（1000个T）、E（100万个T）或Z（10亿个T）。\n②Variety：种类和来源多样化。包括结构化、半结构化和非结构化数据，具体表现为网络日志、音频、视频、图片、地理位置信息等等，多类型的数据对数据的处理能力提出了更高的要求。\n③Value：数据价值密度相对较低，或者说是浪里淘沙却又弥足珍贵。随着互联网以及物联网的广泛应用，信息感知无处不在，信息海量，但价值密度较低，如何结合业务逻辑并通过强大的机器算法来挖掘数据价值，是大数据时代最需要解决的问题。\n④Velocity：数据增长速度快，处理速度也快，时效性要求高。比如搜索引擎要求几分钟前的新闻能够被用户查询到，个性化推荐算法尽可能要求实时完成推荐。这是大数据区别于传统数据挖掘的显著特征。\n⑤Veracity：数据的准确性和可信赖度，即数据的质量。\n参考：\nhttps://github.com/heibaiying https://javabetter.cn/xuexiluxian/bigdata.html#%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE\n","date":"2025-01-01T11:17:11+08:00","permalink":"https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/","title":"大数据基础"},{"content":"Anaconda是一个环境管理工具，每一个环境可以理解为一个房间，每个环境存放着不同的包，互不干扰\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 创建环境：conda create -n 环境名字 python=3.10 复制虚拟环境：conda create -n 副本虚拟环境名 --clone 虚拟环境名 进入环境：activate 环境名字 （Linux环境下要用：conda activate 环境名字） 查看有哪些环境： conda env list 查看conda信息：conda info -v 安装包：conda install django=2.0 最后django=2.0是指包名和版本号 查看都有哪些包 conda list 更新包：conda update 包名 删除包：conda remove 包名 搜索包：conda search package-name，可以模糊搜索 环境切换： activate 环境名 删除环境：conda remove -n 环境名 --all 最后表示把环境里面的包也一起删除 ","date":"2024-12-28T11:20:54+08:00","permalink":"https://h-yx-blog.github.io/p/anaconda%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/","title":"Anaconda基础使用"},{"content":"Hugo语法 1、本地启动Hugo博客 进入博客根目录 比如我的是：D:\\blog\\hugo_extended_withdeploy_0.140.1_windows-amd64\\yuta-blog\n1 hugo server -D 2、创建文章 同样进入 D:\\blog\\hugo_extended_withdeploy_0.140.1_windows-amd64\\yuta-blog\n1 hugo new content post/文件名称/index.md 文件名称后面就是博客的文章名称，最后一定是要 index.md\n3、提交代码 同样 进入 D:\\blog\\hugo_extended_withdeploy_0.140.1_windows-amd64\\yuta-blog\n1 2 3 git add . git commit -m \u0026#34;本次提交的变更\u0026#34; git push ","date":"2024-12-27T17:16:55+08:00","permalink":"https://h-yx-blog.github.io/p/hugo-grammar/","title":"Hugo Grammar"},{"content":" 1 netstat -nlpt #查看运行的进程及其占用的端口 ","date":"2024-12-27T02:04:07+08:00","permalink":"https://h-yx-blog.github.io/p/linux/","title":"Linux"},{"content":"","date":"2024-12-27T01:50:08+08:00","permalink":"https://h-yx-blog.github.io/p/java/","title":"Java"},{"content":"Python入门语法 一、数据类型 常见数据类型 类型 描述 说明 数字（Number） 支持 •整数（int） •浮点数（float） •复数（complex） •布尔（bool） 整数（int），如：10、-10 浮点数（float），如：13.14、-13.14 复数（complex），如：4+3j，以j结尾表示复 数\n布尔（bool）表达现实生活中的逻辑，即真和假，True表示真，False表示假。 True本质上是一个数字记作1，False记作0 字符串（String） 描述文本的一种数据类型 字符串（string）由任意数量的字符组成 列表（List） 有序的可变序列 Python中使用最频繁的数据类型，可有序记录一堆数据 元组（Tuple） 有序的不可变序列 可有序记录一堆不可变的Python数据集合 集合（Set） 无序不重复集合 可无序记录一堆不重复的Python数据集合 字典（Dictionary） 无序Key-Value集合 可无序记录一堆Key-Value型的Python数据集合 type() 使用type()方法可以查看当前变量的数据类型\n数据类型转换 语句(函数) 说明 int(x) 将x转换为一个整数 float(x) 将x转换为一个浮点数 str(x) 将对象 x 转换为字符串 注意：浮点数转整数会丢失精度，即会丢失小数部分\n命名规范 见名知意 下划线命名法 （由于历史原因，python更推荐使用下划线命名） 英文字母全小写 在命名时不允许与关键字相同，python关键字如下\n运算符 运算符 描述 实例 + 加 两个对象相加 a + b 输出结果 30 - 减 得到负数或是一个数减去另一个数 a - b 输出结果 -10 * 乘 两个数相乘或是返回一个被重复若干次的字符串 a * b 输出结果 200 / 除 b / a 输出结果 2 // 取整除 返回商的整数部分 9//2 输出结果 4 , 9.0//2.0 输出结果 4.0 % 取余 返回除法的余数 b % a 输出结果 0 * * 指数 a * *b 为10的20次方， 输出结果 100000000000000000000 常见数据类型的格式化 格式符号 转化 %s 将内容转换成字符串，放入占位位置 %d 将内容转换成整数，放入占位位置 %f 将内容转换成浮点型，放入占位位置 格式化的精度控制\n可以使用辅助符号\u0026quot;m.n\u0026quot;来控制数据的宽度和精度\nm，控制宽度，要求是数字（很少使用）,设置的宽度小于数字自身，不生效 .n，控制小数点精度，要求是数字，会进行小数的四舍五入 示例：\n%5d：表示将整数的宽度控制在5位，如数字11，被设置为5d，就会变成：[空格][空格][空格]11，用三个空格补足宽度。 %5.2f：表示将宽度控制为5，将小数点精度设置为2 小数点和小数部分也算入宽度计算。如，对11.345设置了%7.2f 后，结果是：[空格][空格]11.35。2个空格补足宽度，小数部分限制2位精度后，四舍五入为 .35\n%.2f：表示不限制宽度，只设置小数点精度为2，如11.345设置%.2f后，结果是11.35 例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 name = \u0026#34;黄永禧\u0026#34; setup_year = 2024 stock_price = 19.99 message = \u0026#34;%s，成立于：%d，我今天的股价是：%f\u0026#34; % (name, setup_year, stock_price) print(message) num1 = 11 num2 = 11.345 print(\u0026#34;数字11宽度限制5，结果是：%5d\u0026#34; % num1) print(\u0026#34;数字11宽度限制1，结果是：%1d\u0026#34; % num1) print(\u0026#34;数字11.345宽度限制7，小数精度2，结果是：%7.2f\u0026#34; % num2) print(\u0026#34;数字11.345不限制，小数精度2，结果是：%.2f\u0026#34; % num2) 字符串格式化常用的方法：**f\u0026#34;{占位}\u0026#34;** name = \u0026#34;黄永禧\u0026#34; set_up_year = 2024 stock_price = 19.99 print(f\u0026#34;我是{name}，我成立于：{set_up_year}年，我今天的股价是：{stock_price}\u0026#34;) 二、判断语句 1.写法 if 条件1:\n条件1满足应做的事情\n条件1满足应做的事情\nelif 条件2:\n条件2满足应做的事情\n条件2满足应做的事情\nelif 条件N:\n条件N满足应做的事情\n条件N满足应做的事情\nelse:\n所有条件都不满足应做的事情\n所有条件都不满足应做的事情\n注意：① if elif else的结尾都要有分号 : 来结尾\n② python是使用缩进来控制代码块的归属\n③elif可以写多个\n④if语句可以嵌套，嵌套时注意缩进来表示代码块的归属\n三、循环语句 1.while循环 while 条件:\n条件满足时，执行的逻辑1\n条件满足时，执行的逻辑2\n条件满足时，执行的逻辑N\n2.for循环 for 临时变量 in 待处理数据集:\n满足循环条件时进行的逻辑处理\n3.range语句 range(num) # 获取一个从0开始，到num结束的数字序列（不含num本身）。如range(5)取得的数据是：[0, 1, 2, 3, 4]\nrange(num1,num2) # 获得一个从num1开始，到num2结束的数字序列（不含num2本身）。如，range(5, 10)取得的数据是：[5, 6, 7, 8, 9]\nrange(num1,num2,step) # 获得一个从num1开始，到num2结束的数字序列（不含num2本身），数字之间的步长，以step为准（step默认为1）。如，range(5, 10, 2)取得的数据是：[5, 7, 9]\n4.变量作用域 第二个print语句中，是可以访问到i变量的。但是：出于规范，不建议这样访问\n1 2 3 4 5 6 for i in range(5) print(i) print(i) 5.continue 和break python在循环中与java一样，可以使用continue跳过当次循环，或使用break跳出整个循环\n四.Python函数 1.函数定义 def 函数名(传入参数1,传入参数2):\n函数体\nreturn 返回值\n注意：\n① 参数如不需要，可以省略\n② 返回值如不需要，可以省略\n③ 函数必须先定义后使用\n如果函数没有返回值，其实是返回None类型\n在if判断中，None等同于False\n2.函数说明文档 当要对函数做注释说明时，一般规范如下\ndef add(x, y):\n\u0026quot;\u0026quot;\u0026quot;\nadd函数可以接收2个参数，进行2数相加的功能\n:param x: 形参x表示相加的其中一个数字\n:param y: 形参y表示相加的另一个数字\n:return: 返回值是2数相加的结果\n\u0026quot;\u0026quot;\u0026quot;\nresult = x + y\nprint(f\u0026quot;2数相加的结果是：{result}\u0026quot;)\nreturn result\n3.函数多个返回值 返回多个返回值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def test_return(): return 1, \u0026#34;hello\u0026#34;, True mylist = test_return() print(mylist) x, y, z = test_return() print(x) print(y) print(z) 注意：\n① 按照返回值的顺序，写对应顺序的多个变量接收即可\n② 变量之间用逗号隔开\n③ 支持不同类型的数据return\n4.函数多种传参方式 4.1 位置参数 1 2 3 4 5 6 7 8 9 10 11 调用函数时根据函数定义的参数位置来传递参数。传递的参数和定义的参数的顺序及个数必须一致 def user_info(name, age, gender): print(f\u0026#34;姓名是:{name}, 年龄是:{age}, 性别是:{gender}\u0026#34;) # 位置参数 - 默认使用形式 user_info(\u0026#39;小明\u0026#39;, 20, \u0026#39;男\u0026#39;) 4.2 关键字参数 函数调用时通过“键=值”形式传递参数，可以让函数更加清晰、容易使用，同时也清除了参数的顺序需求.\n函数调用时，如果有位置参数时，位置参数必须在关键字参数的前面，但关键字参数之间不存在先后顺序\n1 2 3 4 5 6 7 8 9 10 def user_info(name, age, gender): print(f\u0026#34;姓名是:{name}, 年龄是:{age}, 性别是:{gender}\u0026#34;) user_info(name=\u0026#39;小王\u0026#39;, age=11, gender=\u0026#39;女\u0026#39;) user_info(age=10, gender=\u0026#39;女\u0026#39;, name=\u0026#39;肖肖\u0026#39;) # 可以不按照参数的定义顺序传参 user_info(\u0026#39;甜甜\u0026#39;, gender=\u0026#39;女\u0026#39;, age=9) 4.3 不定长参数 不定长参数也叫可变参数. 用于不确定调用的时候会传递多少个参数(不传参也可以)的场景.\n类型一：位置传递\n如下代码，传进的所有参数都会被args变量收集，它会根据传进参数的位置合并为一个元组(tuple)，args是元组类型，这就是位置传递\n1 2 3 4 5 6 7 8 9 10 # 不定长 - 位置不定长, *号 # 不定长定义的形式参数会作为元组存在，接收不定长数量的参数传入 def user_info( *args): print(f\u0026#34;args参数的类型是：{type(args)}，内容是:{args}\u0026#34;) user_info(1, 2, 3, \u0026#39;小明\u0026#39;, \u0026#39;男孩\u0026#39;) 类型二：关键字传递\n参数是“键=值”形式的情况下, 所有的“键=值”都会被kwargs接受, 同时会根据“键=值”组成字典.\n1 2 3 4 5 6 7 8 # 不定长 - 关键字不定长, * *号 ，可理解为字典的不定长 def user_info( * *kwargs): print(f\u0026#34;args参数的类型是：{type(kwargs)}，内容是:{kwargs}\u0026#34;) user_info(name=\u0026#39;小王\u0026#39;, age=11, gender=\u0026#39;男孩\u0026#39;) 4.4. 缺省参数 缺省参数也叫默认参数，用于定义函数，为参数提供默认值，调用函数时可不传该默认参数的值（注意：所有位置参数必须出现在默认参数前，包括函数定义和调用）.\n函数调用时，如果为缺省参数传值则修改默认参数值, 否则使用这个默认值\n1 2 3 4 5 6 7 8 def user_info(name, age, gender=\u0026#39;女\u0026#39;): print(f\u0026#34;姓名是:{name}, 年龄是:{age}, 性别是:{gender}\u0026#34;) user_info(\u0026#39;小天\u0026#39;, 13) user_info(\u0026#39;小天\u0026#39;, 13, \u0026#39;男\u0026#39;) 5.global关键字 如下所示， testB 函数内部的 num = 200 是定义了一个局部变量，并没有真正修改到全局变量num的值，所以最好的print语句结果为200\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 num = 200 def test_a(): print(f\u0026#34;test_a: {num}\u0026#34;) def test_b(): num = 500 # 局部变量 print(f\u0026#34;test_b: {num}\u0026#34;) test_a() # 结果为200 test_b() # 结果为500 print(num) #结果为200 如果想修改全局变量num的值，可以用global关键字来声明 num = 200 def test_a(): print(f\u0026#34;test_a: {num}\u0026#34;) def test_b(): global num # 设置内部定义的变量为全局变量 num = 500 print(f\u0026#34;test_b: {num}\u0026#34;) test_a() #结果为200 test_b() #结果为500 print(num) #结果为500 6.匿名函数 6.1 函数作为参数传递\n定义一个函数，接收另一个函数作为传入参数 1 2 3 4 5 6 7 8 def test_func(compute): result = compute(1, 2) # 确定compute是函数 print(f\u0026#34;compute参数的类型是:{type(compute)}\u0026#34;) print(f\u0026#34;计算结果：{result}\u0026#34;) 定义一个函数，准备作为参数传入另一个函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def compute(x, y): return x + y # 调用，并传入函数 test_func(compute) 6.2 lambda匿名函数 定义语法 lambda 传入参数 : 函数体 # 定义一个函数，接受其它函数输入 def test_func(compute): result = compute(1, 2) print(f\u0026#34;结果是:{result}\u0026#34;) # 通过lambda匿名函数的形式，将匿名函数作为参数传入 def add(x, y): return x + y test_func(add) test_func(lambda x, y: x + y) 五、数据容器 5.1 list列表 5.1.1 列表的定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 普通列表 my_list = [\u0026#34;我是字符串\u0026#34;, 666, True] # 嵌套列表 my_list = [ [1, 2, 3], [4, 5, 6]] #空列表 my_list = [] my_list = list() 5.1.2 列表的下标索引\n用下标进行元素索引\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 my_list = [\u0026#34;Tom\u0026#34;, \u0026#34;Lily\u0026#34;, \u0026#34;Rose\u0026#34;] # 列表[下标索引], 从前向后从0开始，每次+1， 从后向前从-1开始，每次-1 print(my_list[0]) print(my_list[1]) print(my_list[2]) # 取出嵌套列表的元素 my_list = [ [1, 2, 3], [4, 5, 6]] print(my_list[1][1]) 5.1.3 list常用操作\n编号 使用方式 作用 1 列表.append(元素) 向列表中追加一个元素 2 列表.extend(容器) 将数据容器的内容依次取出，追加到列表尾部 3 列表.insert(下标, 元素) 在指定下标处，插入指定的元素 4 del 列表[下标] 删除列表指定下标元素 5 列表.pop(下标) 删除列表指定下标元素 6 列表.remove(元素) 从前向后，删除此元素第一个匹配项 7 列表.clear() 清空列表 8 列表.count(元素) 统计此元素在列表中出现的次数 9 列表.index(元素) 查找指定元素在列表的下标 找不到报错ValueError 10 len(列表) 统计容器内有多少元素 5.1.4 列表的特点\n可以容纳多个元素（上限为2 * *63-1、9223372036854775807个） 可以容纳不同类型的元素（混装） 数据是有序存储的（有下标序号） 允许重复数据存在 可以修改（增加或删除元素等） 5.2 tuple元祖 元组一旦定义完成，就不可修改；当元组只有一个数据，这个数据后面要添加逗号 如 ： my_tuple = (\u0026lsquo;hello\u0026rsquo;, )\n元组可以如下三种定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 t1 = (1, \u0026#34;Hello\u0026#34;, True) t2 = () t3 = tuple() # 定义单个元素的元素 t4 = (\u0026#34;hello\u0026#34;, ) # 元组的嵌套 t5 = ( (1, 2, 3), (4, 5, 6) ) # 下标索引去取出内容 num = t5[1][2] # 元组的操作：index查找方法 t6 = (\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;Python\u0026#34;) index = t6.index(\u0026#34;茂佳程序员\u0026#34;) print(f\u0026#34;在元组t6中查找茂佳程序员，的下标是：{index}\u0026#34;) # 元组的操作：count统计方法 t7 = (\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;Python\u0026#34;) num = t7.count(\u0026#34;茂佳程序员\u0026#34;) print(f\u0026#34;在元组t7中统计茂佳程序员的数量有：{num}个\u0026#34;) # 元组的操作：len函数统计元组元素数量 t8 = (\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;Python\u0026#34;) num = len(t8) print(f\u0026#34;t8元组中的元素有：{num}个\u0026#34;) # 元组的遍历：while index = 0 while index \u0026lt; len(t8): print(f\u0026#34;元组的元素有：{t8[index]}\u0026#34;) # 至关重要 index += 1 # 元组的遍历：for for element in t8: print(f\u0026#34;2元组的元素有：{element}\u0026#34;) # 定义一个元组,里面有list元素，list元素是可以修改的 t9 = (1, 2, [\u0026#34;itmoka\u0026#34;, \u0026#34;itcast\u0026#34;]) print(f\u0026#34;t9的内容是：{t9}\u0026#34;) t9[2][0] = \u0026#34;茂佳程序员\u0026#34; t9[2][1] = \u0026#34;茂佳科技\u0026#34; print(f\u0026#34;t9的内容是：{t9}\u0026#34;) 元祖操作\n编号 方法 作用 1 index() 查找某个数据，如果数据存在返回对应的下标，否则报错 2 count() 统计某个数据在当前元组出现的次数 3 len(元组) 统计元组内的元素个数 元祖的特点\n可以容纳多个数据 可以容纳不同类型的数据（混装） 数据是有序存储的（下标索引） 允许重复数据存在 不可以修改（增加或删除元素等） 支持for循环 5.3 str 字符串 5.3.1 字符串操作\n编号 操作 说明 1 字符串[下标] 根据下标索引取出特定位置字符 2 字符串.index(字符串） 查找给定字符的第一个匹配项的下标 3 字符串.replace(字符串1, 字符串2) 将字符串内的全部字符串1，替换为字符串2 不会修改原字符串，而是得到一个新的 4 字符串.split(字符串) 按照给定字符串，对字符串进行分隔 不会修改原字符串，而是得到一个新的列表 5 字符串.strip() 字符串.strip(字符串) 移除首尾的空格和换行符或指定字符串 6 字符串.count(字符串) 统计字符串内某字符串的出现次数 7 len(字符串) 统计字符串的字符个数 5.3.2 示例代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 my_str = \u0026#34;itmoka and itcast\u0026#34; # 通过下标索引取值 value = my_str[2] value2 = my_str[-16] print(f\u0026#34;从字符串{my_str}取下标为2的元素，值是：{value},取下标为-16的元素。值是：{value2}\u0026#34;) # 不允许修改 # my_str[2] = \u0026#34;H\u0026#34; # index方法 value = my_str.index(\u0026#34;and\u0026#34;) print(f\u0026#34;在字符串{my_str}中查找and，其起始下标是：{value}\u0026#34;) # replace方法，得到的是个新的字符串，老的字符串还是没变的 new_my_str = my_str.replace(\u0026#34;it\u0026#34;, \u0026#34;程序\u0026#34;) print(f\u0026#34;将字符串{my_str}，进行替换后得到：{new_my_str}\u0026#34;) # split方法 my_str = \u0026#34;hello python itmoka itcast\u0026#34; my_str_list = my_str.split(\u0026#34; \u0026#34;) print(f\u0026#34;将字符串{my_str}进行split切分后得到：{my_str_list}, 类型是：{type(my_str_list)}\u0026#34;) # strip方法 my_str = \u0026#34; itmoka and itcast \u0026#34; new_my_str = my_str.strip() # 不传入参数，去除首尾空格 print(f\u0026#34;字符串{my_str}被strip后，结果：{new_my_str}\u0026#34;) my_str = \u0026#34;12itmoka and itcast21\u0026#34; new_my_str = my_str.strip(\u0026#34;12\u0026#34;) print(f\u0026#34;字符串{my_str}被strip(\u0026#39;12\u0026#39;)后，结果：{new_my_str}\u0026#34;) # 统计字符串中某字符串的出现次数, count my_str = \u0026#34;itmoka and itcast\u0026#34; count = my_str.count(\u0026#34;it\u0026#34;) print(f\u0026#34;字符串{my_str}中it出现的次数是：{count}\u0026#34;) # 统计字符串的长度, len() num = len(my_str) print(f\u0026#34;字符串{my_str}的长度是：{num}\u0026#34;) 5.3.3 字符串的特点\n只可以存储字符串 长度任意（取决于内存大小） 支持下标索引 允许重复字符串存在 不可以修改（增加或删除元素等） 支持for循环 5.4 set 集合 5.4.1 集合操作\n编号 操作 说明 1 集合.add(元素) 集合内添加一个元素 2 集合.remove(元素) 移除集合内指定的元素 3 集合.pop() 从集合中随机取出一个元素 4 集合.clear() 将集合清空 5 集合1.difference(集合2) 得到一个新集合，内含2个集合的差集 原有的2个集合内容不变 6 集合1.difference_update(集合2) 在集合1中，删除集合2中存在的元素 集合1被修改，集合2不变 7 集合1.union(集合2) 得到1个新集合，内含2个集合的全部元素 原有的2个集合内容不变 8 len(集合) 得到一个整数，记录了集合的元素数量 5.4.2 示例代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 # 定义集合 my_set = {\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;itmoka\u0026#34;, \u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;itmoka\u0026#34;, \u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;itmoka\u0026#34;} my_set_empty = set() # 定义空集合 print(f\u0026#34;my_set的内容是：{my_set}, 类型是：{type(my_set)}\u0026#34;) print(f\u0026#34;my_set_empty的内容是：{my_set_empty}, 类型是：{type(my_set_empty)}\u0026#34;) # 添加新元素 my_set.add(\u0026#34;Python\u0026#34;) my_set.add(\u0026#34;茂佳科技\u0026#34;) # print(f\u0026#34;my_set添加元素后结果是：{my_set}\u0026#34;) # 移除元素 my_set.remove(\u0026#34;茂佳程序员\u0026#34;) print(f\u0026#34;my_set移除茂佳程序员后，结果是：{my_set}\u0026#34;) # 随机取出一个元素 my_set = {\u0026#34;茂佳科技\u0026#34;, \u0026#34;茂佳程序员\u0026#34;, \u0026#34;itmoka\u0026#34;} element = my_set.pop() print(f\u0026#34;集合被取出元素是：{element}, 取出元素后：{my_set}\u0026#34;) # 清空集合, clear my_set.clear() print(f\u0026#34;集合被清空啦，结果是：{my_set}\u0026#34;) # 取2个集合的差集 set1 = {1, 2, 3} set2 = {1, 5, 6} set3 = set1.difference(set2) print(f\u0026#34;取出差集后的结果是：{set3}\u0026#34;) print(f\u0026#34;取差集后，原有set1的内容：{set1}\u0026#34;) print(f\u0026#34;取差集后，原有set2的内容：{set2}\u0026#34;) # 消除2个集合的差集 set1 = {1, 2, 3} set2 = {1, 5, 6} set1.difference_update(set2) print(f\u0026#34;消除差集后，集合1结果：{set1}\u0026#34;) print(f\u0026#34;消除差集后，集合2结果：{set2}\u0026#34;) # 2个集合合并为1个 set1 = {1, 2, 3} set2 = {1, 5, 6} set3 = set1.union(set2) print(f\u0026#34;2集合合并结果：{set3}\u0026#34;) print(f\u0026#34;合并后集合1：{set1}\u0026#34;) print(f\u0026#34;合并后集合2：{set2}\u0026#34;) # 统计集合元素数量len() set1 = {1, 2, 3, 4, 5, 1, 2, 3, 4, 5} num = len(set1) print(f\u0026#34;集合内的元素数量有：{num}个\u0026#34;) # 集合的遍历 # 集合不支持下标索引，不能用while循环 # 可以用for循环 set1 = {1, 2, 3, 4, 5,10,7 } for element in set1: print(f\u0026#34;集合的元素有：{element}\u0026#34;) 5.4.3 集合的特点\n可以容纳多个数据 可以容纳不同类型的数据（混装） 数据是无序存储的（不支持下标索引） 不允许重复数据存在 可以修改（增加或删除元素等） 支持for循环 5.5 dict 字典 5.5.1 字典操作\n编号 操作 说明 1 字典[Key] 获取指定Key对应的Value值 2 字典[Key] = Value 添加或更新键值对 3 字典.pop(Key) 取出Key对应的Value并在字典内删除此Key的键值对 4 字典.clear() 清空字典 5 字典.keys() 获取字典的全部Key，可用于for循环遍历字典 6 len(字典) 计算字典内的元素数量 5.5.2 示例代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 ① 定义字典 # 定义字典 my_dict1 = {\u0026#34;王力鸿\u0026#34;: 99, \u0026#34;周杰轮\u0026#34;: 88, \u0026#34;林俊节\u0026#34;: 77} # 定义空字典 my_dict2 = {} my_dict3 = dict() print(f\u0026#34;字典1的内容是：{my_dict1}, 类型：{type(my_dict1)}\u0026#34;) print(f\u0026#34;字典2的内容是：{my_dict2}, 类型：{type(my_dict2)}\u0026#34;) print(f\u0026#34;字典3的内容是：{my_dict3}, 类型：{type(my_dict3)}\u0026#34;) # 定义重复Key的字典 my_dict1 = {\u0026#34;王力鸿\u0026#34;: 99, \u0026#34;王力鸿\u0026#34;: 88, \u0026#34;林俊节\u0026#34;: 77} print(f\u0026#34;重复key的字典的内容是：{my_dict1}\u0026#34;) # 从字典中基于Key获取Value my_dict1 = {\u0026#34;王力鸿\u0026#34;: 99, \u0026#34;周杰轮\u0026#34;: 88, \u0026#34;林俊节\u0026#34;: 77} score = my_dict1[\u0026#34;王力鸿\u0026#34;] print(f\u0026#34;王力鸿的考试分数是：{score}\u0026#34;) score = my_dict1[\u0026#34;周杰轮\u0026#34;] print(f\u0026#34;周杰轮的考试分数是：{score}\u0026#34;) # 定义嵌套字典 stu_score_dict = { \u0026#34;王力鸿\u0026#34;: { \u0026#34;语文\u0026#34;: 77, \u0026#34;数学\u0026#34;: 66, \u0026#34;英语\u0026#34;: 33 }, \u0026#34;周杰轮\u0026#34;: { \u0026#34;语文\u0026#34;: 88, \u0026#34;数学\u0026#34;: 86, \u0026#34;英语\u0026#34;: 55 }, \u0026#34;林俊节\u0026#34;: { \u0026#34;语文\u0026#34;: 99, \u0026#34;数学\u0026#34;: 96, \u0026#34;英语\u0026#34;: 66 } } print(f\u0026#34;学生的考试信息是：{stu_score_dict}\u0026#34;) # 从嵌套字典中获取数据 # 看一下周杰轮的语文信息 score = stu_score_dict[\u0026#34;周杰轮\u0026#34;][\u0026#34;语文\u0026#34;] print(f\u0026#34;周杰轮的语文分数是：{score}\u0026#34;) score = stu_score_dict[\u0026#34;林俊节\u0026#34;][\u0026#34;英语\u0026#34;] print(f\u0026#34;林俊节的英语分数是：{score}\u0026#34;) ②字典操作 my_dict = {\u0026#34;周杰轮\u0026#34;: 99, \u0026#34;林俊节\u0026#34;: 88, \u0026#34;张学油\u0026#34;: 77} # 新增元素 my_dict[\u0026#34;张信哲\u0026#34;] = 66 print(f\u0026#34;字典经过新增元素后，结果：{my_dict}\u0026#34;) # 更新元素 my_dict[\u0026#34;周杰轮\u0026#34;] = 33 print(f\u0026#34;字典经过更新后，结果：{my_dict}\u0026#34;) # 删除元素 score = my_dict.pop(\u0026#34;周杰轮\u0026#34;) print(f\u0026#34;字典中被移除了一个元素，结果：{my_dict}, 周杰轮的考试分数是：{score}\u0026#34;) # 清空元素, clear my_dict.clear() print(f\u0026#34;字典被清空了，内容是：{my_dict}\u0026#34;) # 获取全部的key my_dict = {\u0026#34;周杰轮\u0026#34;: 99, \u0026#34;林俊节\u0026#34;: 88, \u0026#34;张学油\u0026#34;: 77} keys = my_dict.keys() print(f\u0026#34;字典的全部keys是：{keys}\u0026#34;) # 遍历字典 # 方式1：通过获取到全部的key来完成遍历 for key in keys: print(f\u0026#34;字典的key是:{key}\u0026#34;) print(f\u0026#34;字典的value是：{my_dict[key]}\u0026#34;) # 方式2：直接对字典进行for循环，每一次循环都是直接得到key for key in my_dict: print(f\u0026#34;2字典的key是:{key}\u0026#34;) print(f\u0026#34;2字典的value是：{my_dict[key]}\u0026#34;) # 统计字典内的元素数量, len()函数 num = len(my_dict) print(f\u0026#34;字典中的元素数量有：{num}个\u0026#34;) 5.5.3 字典的特点\n可以容纳多个数据 可以容纳不同类型的数据 每一份数据是KeyValue键值对 可以通过Key获取到Value，Key不可重复（重复会覆盖） 不支持下标索引 可以修改（增加或删除更新元素等） 支持for循环，不支持while循环 5.6 数据容器（序列）的切片 5.6.1 什么是序列\n序列是指：内容连续、有序，可使用下标索引的一类数据容器\n列表、元组、字符串，均可以可以视为序列。\n5.6.2 序列切片\n序列支持切片，即：列表、元组、字符串，均支持进行切片操作\n切片：从一个序列中，取出一个子序列\n语法：序列[起始下标:结束下标:步长] 表示从序列中，从指定位置开始，依次取出元素，到指定位置结束，得到一个新序列：\n起始下标表示从何处开始，可以留空，留空视作从头开始 结束下标（不含）表示何处结束，可以留空，留空视作截取到结尾 步长表示，依次取元素的间隔 步长1表示，一个个取元素 步长2表示，每次跳过1个元素取 步长N表示，每次跳过N-1个元素取 步长为负数表示，反向取（注意，起始下标和结束下标也要反向标记） 注意，此操作不会影响序列本身，而是会得到一个新的序列（列表、元组、字符串）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # 对list进行切片，从1开始，4结束，步长1 my_list = [0, 1, 2, 3, 4, 5, 6] result1 = my_list[1:4] # 步长默认是1，所以可以省略不写 print(f\u0026#34;结果1：{result1}\u0026#34;) # 对tuple进行切片，从头开始，到最后结束，步长1 my_tuple = (0, 1, 2, 3, 4, 5, 6) result2 = my_tuple[:] # 起始和结束不写表示从头到尾，步长为1可以省略 print(f\u0026#34;结果2：{result2}\u0026#34;) # 对str进行切片，从头开始，到最后结束，步长2 my_str = \u0026#34;01234567\u0026#34; result3 = my_str[::2] print(f\u0026#34;结果3：{result3}\u0026#34;) # 对str进行切片，从头开始，到最后结束，步长-1 my_str = \u0026#34;01234567\u0026#34; result4 = my_str[::-1] # 等同于将序列反转了 print(f\u0026#34;结果4：{result4}\u0026#34;) # 对列表进行切片，从3开始，到1结束，步长-1 my_list = [0, 1, 2, 3, 4, 5, 6] result5 = my_list[3:1:-1] print(f\u0026#34;结果5：{result5}\u0026#34;) # 对元组进行切片，从头开始，到尾结束，步长-2 my_tuple = (0, 1, 2, 3, 4, 5, 6) result6 = my_tuple[::-2] print(f\u0026#34;结果6：{result6}\u0026#34;) 5.7 不同容器对比 列表 元组 字符串 集合 字典 元素数量 支持多个 支持多个 支持多个 支持多个 支持多个 元素类型 任意 任意 仅字符 任意 Key：Value Key：除字典外任意类型 Value：任意类型 下标索引 支持 支持 支持 不支持 不支持 重复元素 支持 支持 支持 不支持 不支持 可修改性 支持 不支持 不支持 支持 支持 数据有序 是 是 是 否 否 使用场景 可修改、可重复的一批数据记录场景 不可修改、可重复的一批数据记录场景 一串字符的记录场景 不可重复的数据记录场景 以Key检索Value的数据记录场景 是否支持下标索引 支持：列表、元组、字符串 - 序列类型 不支持：集合、字典 - 非序列类型 2 . 是否支持重复元素：\n支持：列表、元组、字符串 - 序列类型 不支持：集合、字典 - 非序列类型 3 . 是否可以修改\n支持：列表、集合、字典 不支持：元组、字符串 容器通用功能\n功能 描述 通用for循环 遍历容器（字典是遍历key） max 容器内最大元素 min() 容器内最小元素 len() 容器元素个数 list() 转换为列表 tuple() 转换为元组 str() 转换为字符串 set() 转换为集合 sorted(序列, [reverse=True]) 排序，reverse=True表示降序 得到一个排好序的列表 六. 异常 基本语法\n基本语法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 try: print(name) except NameError as e: print(\u0026#39;name变量名称未定义错误\u0026#39;) # 完整语法 try: f = open(\u0026#34;D:/123.txt\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;UTF-8\u0026#34;) except Exception as e: print(\u0026#34;出现异常了\u0026#34;) f = open(\u0026#34;D:/123.txt\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;UTF-8\u0026#34;) # else表示的是如果没有异常要执行的代码。 else: print(\u0026#34;好高兴，没有异常。\u0026#34;) # finally表示的是无论是否异常都要执行的代码 finally: print(\u0026#34;我是finally，有没有异常我都要执行\u0026#34;) f.close() 七. Python模块和包 7.1 什么是模块\nPython 模块(Module)，是一个 Python 文件，以 .py 结尾. 模块能定义函数，类和变量，模块里也能包含可执行的代码.\n7.2 模块的作用**:**\npython中有很多各种不同的模块, 每一个模块都可以帮助我们快速的实现一些功能, 比如实现和时间相关的功能就可以使用time模块\n我们可以认为一个模块就是一个工具包, 每一个工具包中都有各种不同的工具供我们使用进而实现各种不同的功能.\n7.3 模块导入\n模块在使用前需要先导入 导入的语法如下:\n常用的组合形式如：\nimport 模块名 from 模块名 import 类、变量、方法等 from 模块名 import * import 模块名 as 别名 from 模块名 import 功能名 as 别名 7.4 __all__变量\n如果一个模块文件中有 __all__变量，当使用 from xxx import * 导入时，只能导入这个列表中的元素\n7.5 什么是包\n从物理上看，包就是一个文件夹，在该文件夹下包含了一个 init.py 文件，该文件夹可用于包含多个模块文件\n**包的作用：**当我们的模块文件越来越多时,包可以帮助我们管理这些模块, 包的作用就是包含多个模块，但包的本质依然是模块\n导入包的语法\nimport 包名.模块名\n包名.模块名.目标\n7.6 python常用包\n科学计算中常用的:numpy包\n数据分析中常用的:pandas包\n大数据计算中常用的:pyspark、apache-flink包\n图形可视化常用的:matplotlib、pyecharts\n人工智能常用的:tensorflow\n","date":"2024-12-27T00:36:30+08:00","permalink":"https://h-yx-blog.github.io/p/python%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","title":"Python基础语法"},{"content":"正文测试 而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用 思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片 1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"2020-09-09T00:00:00Z","image":"https://h-yx-blog.github.io/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu_2307260c751d0e0b.jpg","permalink":"https://h-yx-blog.github.io/p/test-chinese/","title":"Chinese Test"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"https://h-yx-blog.github.io/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu_e95a4276bf860a84.jpg","permalink":"https://h-yx-blog.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2019-03-09T00:00:00Z","image":"https://h-yx-blog.github.io/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu_c1ca39d792aee4ab.jpg","permalink":"https://h-yx-blog.github.io/p/placeholder-text/","title":"Placeholder Text"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$","date":"2019-03-08T00:00:00Z","permalink":"https://h-yx-blog.github.io/p/math-typesetting/","title":"Math Typesetting"},{"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3 .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","date":"2019-03-05T00:00:00Z","image":"https://h-yx-blog.github.io/p/emoji-support/the-creative-exchange-d2zvqp3fpro-unsplash_hu_27b8954607cdb515.jpg","permalink":"https://h-yx-blog.github.io/p/emoji-support/","title":"Emoji Support"}]