<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>大数据 on Yuta&#39;s blog</title>
        <link>https://h-yx-blog.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/</link>
        <description>Recent content in 大数据 on Yuta&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Yuta Huang</copyright>
        <lastBuildDate>Wed, 01 Jan 2025 11:17:11 +0800</lastBuildDate><atom:link href="https://h-yx-blog.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>大数据基础</title>
        <link>https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/</link>
        <pubDate>Wed, 01 Jan 2025 11:17:11 +0800</pubDate>
        
        <guid>https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/</guid>
        <description>&lt;h1 id=&#34;概念&#34;&gt;概念
&lt;/h1&gt;&lt;h2 id=&#34;大数据处理流程&#34;&gt;大数据处理流程
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/process.jpg&#34;
	width=&#34;1089&#34;
	height=&#34;617&#34;
	srcset=&#34;https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/process_hu7440470465267177649.jpg 480w, https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/process_hu12102598982732704565.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;大数据处理流程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;423px&#34;
	
&gt;
上图是一个简化的大数据处理流程图，大数据处理的主要流程包括数据收集、数据存储、数据处理、数据应用等主要环节。下面我们逐一对各个环节所需要的技术栈进行讲解：&lt;/p&gt;
&lt;h3 id=&#34;数据收集&#34;&gt;数据收集
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;大数据处理的第一步，第一种是通过 Sqoop 或者 Cannal 等工具进行定时抽取或者实时同步；第二种是各种埋点日志，通过 Flume 进行实时收集。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大数据处理的第一步是数据的收集。现在的中大型项目通常采用微服务架构进行分布式部署，所以数据的采集需要在多台服务器上进行，且采集过程不能影响正常业务的开展。基于这种需求，就衍生了多种日志收集工具，如 Flume 、Logstash、Kibana 等，它们都能通过简单的配置完成复杂的数据收集和数据聚合。&lt;/p&gt;
&lt;h3 id=&#34;数据存储&#34;&gt;数据存储
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;大数据处理的第二步，将数据存储到 HDFS 中，实时日志流情况下通过 Kafka 输出给后面的流式计算引擎。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;收集到数据后，下一个问题就是：数据该如何进行存储？通常最为熟知是 MySQL、Oracle 等传统的关系型数据库，它们的优点是能够快速存储结构化的数据，并支持随机访问。但大数据的数据结构通常是半结构化（如日志数据）、甚至是非结构化的（如视频、音频数据），为了解决海量半结构化和非结构化数据的存储，衍生了 Hadoop HDFS 、KFS、GFS 等分布式文件系统，它们都能够支持结构化、半结构和非结构化数据的存储，并可以通过增加机器进行横向扩展。&lt;/p&gt;
&lt;p&gt;分布式文件系统完美地解决了海量数据存储的问题，但是一个优秀的数据存储系统需要同时考虑数据存储和访问两方面的问题，比如你希望能够对数据进行随机访问，这是传统的关系型数据库所擅长的，但却不是分布式文件系统所擅长的，那么有没有一种存储方案能够同时兼具分布式文件系统和关系型数据库的优点，基于这种需求，就产生了 HBase、MongoDB。&lt;/p&gt;
&lt;h3 id=&#34;数据分析&#34;&gt;数据分析
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;大数据的核心环节，包括离线处理和流处理两种方式，对应的计算引擎包括 MapReduce、Spark、Flink 等，处理完的结果会保存到已经提前设计好的数据仓库中，或者 HBase、Redis、RDBMS 等各种存储系统上。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大数据处理最重要的环节就是数据分析，数据分析通常分为两种：批处理和流处理。&lt;/p&gt;
&lt;p&gt;批处理：对一段时间内海量的离线数据进行统一的处理，对应的处理框架有 Hadoop MapReduce、Spark、Flink 等；
流处理：对运动中的数据进行处理，即在接收数据的同时就对其进行处理，对应的处理框架有 Storm、Spark Streaming、Flink Streaming 等。
批处理和流处理各有其适用的场景，时间不敏感或者硬件资源有限，可以采用批处理；时间敏感和及时性要求高就可以采用流处理。随着服务器硬件的价格越来越低和大家对及时性的要求越来越高，流处理越来越普遍，如股票价格预测和电商运营数据分析等。&lt;/p&gt;
&lt;p&gt;上面的框架都是需要通过编程来进行数据分析，那么如果你不是一个后台工程师，是不是就不能进行数据的分析了？当然不是，大数据是一个非常完善的生态圈，有需求就有解决方案。为了能够让熟悉 SQL 的人员也能够进行数据的分析，查询分析框架应运而生，常用的有 Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix 等。这些框架都能够使用标准的 SQL 或者 类 SQL 语法灵活地进行数据的查询分析。这些 SQL 经过解析优化后转换为对应的作业程序来运行，如 Hive 本质上就是将 SQL 转换为 MapReduce 作业，Spark SQL 将 SQL 转换为一系列的 RDDs 和转换关系（transformations），Phoenix 将 SQL 查询转换为一个或多个 HBase Scan。&lt;/p&gt;
&lt;h3 id=&#34;数据应用&#34;&gt;数据应用
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;应用场景：数据可视化、业务决策、推荐算法优化、机器学习&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;数据分析完成后，接下来就是数据应用的范畴，这取决于你实际的业务需求。比如你可以将数据进行可视化展现，或者将数据用于优化你的推荐算法，这种运用现在很普遍，比如短视频个性化推荐、电商商品推荐、头条新闻推荐等。当然你也可以将数据用于训练你的机器学习模型，这些都属于其他领域的范畴，都有着对应的框架和技术栈进行处理，这里就不一一赘述。&lt;/p&gt;
&lt;h3 id=&#34;其他框架&#34;&gt;其他框架
&lt;/h3&gt;&lt;p&gt;上面是一个标准的大数据处理流程所用到的技术框架。但是实际的大数据处理流程比上面复杂很多，针对大数据处理中的各种复杂问题分别衍生了各类框架：&lt;/p&gt;
&lt;p&gt;单机的处理能力都是存在瓶颈的，所以大数据框架都是采用集群模式进行部署，为了更方便的进行集群的部署、监控和管理，衍生了 Ambari、Cloudera Manager 等集群管理工具；
想要保证集群高可用，需要用到 ZooKeeper ，ZooKeeper 是最常用的分布式协调服务，它能够解决大多数集群问题，包括首领选举、失败恢复、元数据存储及其一致性保证。同时针对集群资源管理的需求，又衍生了 Hadoop YARN ;
复杂大数据处理的另外一个显著的问题是，如何调度多个复杂的并且彼此之间存在依赖关系的作业？基于这种需求，产生了 Azkaban 和 Oozie 等工作流调度框架；
大数据流处理中使用的比较多的另外一个框架是 Kafka，它可以用于消峰，避免在秒杀等场景下并发数据对流处理程序造成冲击；
另一个常用的框架是 Sqoop ，主要是解决了数据迁移的问题，它能够通过简单的命令将关系型数据库中的数据导入到 HDFS 、Hive 或 HBase 中，或者从 HDFS 、Hive 导出到关系型数据库上。&lt;/p&gt;
&lt;h3 id=&#34;框架分类&#34;&gt;框架分类
&lt;/h3&gt;&lt;p&gt;日志收集框架：Flume、Logstash、Filebeat&lt;/p&gt;
&lt;p&gt;分布式文件存储系统：Hadoop HDFS&lt;/p&gt;
&lt;p&gt;数据库系统：Mongodb、HBase&lt;/p&gt;
&lt;p&gt;分布式计算框架：&lt;/p&gt;
&lt;p&gt;批处理框架：Hadoop MapReduce
流处理框架：Storm
混合处理框架：Spark、Flink
查询分析框架：Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix&lt;/p&gt;
&lt;p&gt;集群资源管理器：Hadoop YARN&lt;/p&gt;
&lt;p&gt;分布式协调服务：Zookeeper&lt;/p&gt;
&lt;p&gt;数据迁移工具：Sqoop&lt;/p&gt;
&lt;p&gt;任务调度框架：Azkaban、Oozie&lt;/p&gt;
&lt;p&gt;集群部署和监控：Ambari、Cloudera Manager&lt;/p&gt;
&lt;h2 id=&#34;数据仓库&#34;&gt;数据仓库
&lt;/h2&gt;&lt;h3 id=&#34;什么是数据仓库&#34;&gt;什么是数据仓库？
&lt;/h3&gt;&lt;p&gt;在计算中，数据仓库（DW或DWH）也称为企业数据仓库（EDW），是用于报告和数据分析的系统，被视为商业智能的核心组件。DWs从一个或多个不同源的综合数据的中央储存库。他们将当前和历史数据存储在一个地方，用于为整个企业的工作人员创建分析报告。&lt;/p&gt;
&lt;h2 id=&#34;oltp与olap的区别&#34;&gt;OLTP与OLAP的区别
&lt;/h2&gt;&lt;p&gt;OLTP与OLAP是数据仓库的两种操作方式。
当今的数据处理大致可分为两大类，联机事务处理OLTP（on-line transaction processing） 和联机分析处理OLAP（on-line analytical processing)。&lt;/p&gt;
&lt;p&gt;OLTP是传统关系型数据库的主要应用，用来执行一些基本的、日常的事务处理，比如数据库记录的增、删、改、查等等。而OLAP则是分布式数据库的主要应用，它对实时性要求不高，但处理的数据量大，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果，通常应用于复杂的动态报表系统上。&lt;/p&gt;
&lt;h2 id=&#34;etl与dm的区别&#34;&gt;ETL与DM的区别
&lt;/h2&gt;&lt;p&gt;ETL/Extraction-Transformation-Loading——用于完成DB到DW的数据转存，它将DB中的某一个时间点的状态，“抽取”出来，根据DW的存储模型要求，“转换”一下数据格式，然后再“加载”到DW的一个过程，这里需要强调的是，DB的模型是ER模型，遵从范式化设计原则，而DW的数据模型是雪花型结构或者星型结构，用的是面向主题，面向问题的设计思路，所以DB和DW的模型结构不同，需要进行转换。&lt;/p&gt;
&lt;p&gt;DM/Data Mining/数据挖掘——这个挖掘，不是简单的统计了，他是根据概率论的或者其他的统计学原理，将DW中的大数据量进行分析，找出我们不能直观发现的规律。&lt;/p&gt;
&lt;h2 id=&#34;行式存储与列式存储&#34;&gt;行式存储与列式存储
&lt;/h2&gt;&lt;p&gt;列式存储是指一列中的数据在存储介质中是连续存储的；&lt;/p&gt;
&lt;p&gt;行式存储是指一行中的数据在存储介质中是连续存储的。
&lt;img src=&#34;https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/storage.jpg&#34;
	width=&#34;1647&#34;
	height=&#34;973&#34;
	srcset=&#34;https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/storage_hu12367426843831453899.jpg 480w, https://h-yx-blog.github.io/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/storage_hu10270789870229935134.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;行式存储和列式存储&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;406px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;什么时候使用列式存储，什么时候使用行式存储？&lt;/p&gt;
&lt;p&gt;如果一个OLPA类型查询，在海量数据行中，只关心几列数据，效率就比较低了。这种情况列存储就有很大优势。同样如果每次查询设计的数据量较小，或者大部分查询都需要整行数据，行存储就有优势。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果需要关注整张表或者大部分数据，不是单独几列而且关注内容不需要聚集运算，推荐行式存储；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果主要关注大量数据中某几列内容，或者要频繁聚集，然后对聚集后数据进行数据分析，推荐列式存储。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hdfs分布式文件系统&#34;&gt;HDFS（分布式文件系统）
&lt;/h2&gt;&lt;p&gt;HDFS(Hadoop Distribute File System)，是适用于大的数据集的支持高吞吐和高容错的运行在通用机器上的分布式系统。Hapoop就是使用HDFS来存储海量数据，使用MapReduce来处理数据。但是hdfs主要是实现批量数据的处理，并且通过顺序方式访问数据，如果要查找数据必须搜索整个数据集，如果要随机读取数据，效率很低。&lt;/p&gt;
&lt;h2 id=&#34;mapreduce&#34;&gt;MapReduce
&lt;/h2&gt;&lt;p&gt;上文多次提出，以MapReduce提供计算能力。MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集&lt;/p&gt;
&lt;p&gt;MapReduce擅长处理大数据。MapReduce的思想就是“分而治之”。Mapper负责“分”，即把复杂的任务分解为若干个“简单的任务”来处理。“简单的任务”包含三层含义：一是数据或计算的规模相对原任务要大大缩小；二是就近计算原则，即任务会分配到存放着所需数据的节点上进行计算；三是这些小任务可以并行计算，彼此间几乎没有依赖关系。Reducer负责对map阶段的结果进行汇总。&lt;/p&gt;
&lt;h1 id=&#34;特点&#34;&gt;特点
&lt;/h1&gt;&lt;p&gt;大数据特点&lt;br&gt;
①Volume：数据量大，包括采集、存储和计算的量都非常大。大数据的起始计量单位至少是P（1000个T）、E（100万个T）或Z（10亿个T）。&lt;/p&gt;
&lt;p&gt;②Variety：种类和来源多样化。包括结构化、半结构化和非结构化数据，具体表现为网络日志、音频、视频、图片、地理位置信息等等，多类型的数据对数据的处理能力提出了更高的要求。&lt;/p&gt;
&lt;p&gt;③Value：数据价值密度相对较低，或者说是浪里淘沙却又弥足珍贵。随着互联网以及物联网的广泛应用，信息感知无处不在，信息海量，但价值密度较低，如何结合业务逻辑并通过强大的机器算法来挖掘数据价值，是大数据时代最需要解决的问题。&lt;/p&gt;
&lt;p&gt;④Velocity：数据增长速度快，处理速度也快，时效性要求高。比如搜索引擎要求几分钟前的新闻能够被用户查询到，个性化推荐算法尽可能要求实时完成推荐。这是大数据区别于传统数据挖掘的显著特征。&lt;/p&gt;
&lt;p&gt;⑤Veracity：数据的准确性和可信赖度，即数据的质量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;参考：&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/heibaiying&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/heibaiying&lt;/a&gt;
&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://javabetter.cn/xuexiluxian/bigdata.html#%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://javabetter.cn/xuexiluxian/bigdata.html#%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        
    </channel>
</rss>
